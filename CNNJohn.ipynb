{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy.io\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, LambdaLR, SequentialLR\n",
    "from DataHandlers.DiagEnum import DiagEnum\n",
    "import DataHandlers.DiagEnum\n",
    "import DataHandlers.SAFERDataset as SAFERDataset\n",
    "\n",
    "sys.modules[\"SAFERDataset\"] = SAFERDataset\n",
    "sys.modules[\"DiagEnum\"] = DataHandlers.DiagEnum"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the SAFER dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:\\\\2022_23_DSiromani\\\\Feas2\\\\ECGs/filtered_dataframe_reload.pk'\n",
      "Failed to load from pickle, regenerating files\n",
      "Reading file ECGs/000000/saferF2_000002\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\DataHandlers\\SAFERDataset.py:32: DtypeWarning: Columns (11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ecg_data = pd.read_csv(os.path.join(dataset_path, \"rec_data_anon.csv\"))\n",
      "C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\DataHandlers\\SAFERDataset.py:55: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for ind, file_path in ecg_data[\"file_path\"].iteritems():\n",
      "C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\DataHandlers\\SAFERDataset.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_data[\"data\"].loc[ind] = record.p_signal[:, 0]\n",
      "C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\DataHandlers\\SAFERDataset.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_data[\"adc_gain\"].loc[ind] = record.adc_gain[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file ECGs/023000/saferF2_023259\r"
     ]
    }
   ],
   "source": [
    "feas2_pt_data, feas2_ecg_data = SAFERDataset.load_feas_dataset(2, \"dataframe_reload\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fill in the undecided data with zenicor labels - doesnt seem to help\n",
    "feas2_ecg_data[\"class_index\"] = feas2_ecg_data[\"class_index\"].where(feas2_ecg_data[\"measDiag\"] != DiagEnum.Undecided, feas2_ecg_data[\"tag_orig_Poor_Quality\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "feas2_pt_data[\"noRecs\"] = feas2_ecg_data[\"ptID\"].value_counts()\n",
    "feas2_pt_data[\"noHQrecs\"] = feas2_ecg_data[feas2_ecg_data[\"class_index\"] == 0][\"ptID\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0    22794\n1      465\nName: class_index, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feas2_ecg_data[\"class_index\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "465.0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feas2_pt_data[\"noRecs\"] - feas2_pt_data[\"noHQrecs\"]).sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialise the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision.ops import sigmoid_focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check cuda\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot encoding\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dataset.index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.dataset.iloc[index]\n",
    "\n",
    "        X = row[\"data\"]\n",
    "        y = row[\"class_index\"]\n",
    "        ind = row.name\n",
    "\n",
    "        return X, y, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0.0\n",
      "number of patients 211\n",
      "processing 1.0\n",
      "number of patients 23\n",
      "processing 2.0\n",
      "number of patients 10\n",
      "processing 3.0\n",
      "number of patients 6\n",
      "processing 4.0\n",
      "number of patients 6\n",
      "processing 5.0\n",
      "number of patients 7\n",
      "processing 6.0\n",
      "number of patients 4\n",
      "processing 7.0\n",
      "number of patients 3\n",
      "processing 9.0\n",
      "number of patients 4\n",
      "processing 10.0\n",
      "number of patients 1\n",
      "processing 11.0\n",
      "number of patients 1\n",
      "processing 12.0\n",
      "number of patients 1\n",
      "processing 13.0\n",
      "number of patients 1\n",
      "processing 14.0\n",
      "number of patients 1\n",
      "processing 15.0\n",
      "number of patients 1\n",
      "processing 17.0\n",
      "number of patients 1\n",
      "processing 18.0\n",
      "number of patients 1\n",
      "processing 22.0\n",
      "number of patients 1\n",
      "processing 27.0\n",
      "number of patients 1\n",
      "processing 28.0\n",
      "number of patients 1\n",
      "processing 34.0\n",
      "number of patients 1\n",
      "processing 43.0\n",
      "number of patients 1\n",
      "Test high quality: 2112.0 low quality: 16.0 \n",
      "Train high quality: 20610.0 low quality: 449.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_52616\\3445361895.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_52616\\3445361895.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset[\"data\"] = (test_dataset[\"data\"] - test_dataset[\"data\"].map(lambda x: x.mean()))/test_dataset[\"data\"].map(lambda x: x.std())\n"
     ]
    }
   ],
   "source": [
    "# For SAFER data\n",
    "# Split train and test data according to each patient\n",
    "def make_SAFER_dataloaders(pt_data, ecg_data, test_frac, val_frac, only_clean_training=True):\n",
    "    pt_data[\"noLQrecs\"] = pt_data[\"noRecs\"] - pt_data[\"noHQrecs\"]  # for Feas1 this might include stuff flagged by zenicor as noisy?\n",
    "    train_patients = []\n",
    "    test_patients = []\n",
    "    val_patients = []\n",
    "\n",
    "    test_val_frac = test_frac + val_frac\n",
    "    val_second_frac = val_frac/test_val_frac\n",
    "\n",
    "    for val, df in pt_data.groupby(\"noLQrecs\"):\n",
    "        print(f\"processing {val}\")\n",
    "        print(f\"number of patients {len(df.index)}\")\n",
    "\n",
    "        n = math.floor(len(df.index) * test_val_frac)\n",
    "        res = ((len(df.index) * test_val_frac) - n)/test_val_frac\n",
    "        n += np.random.binomial(res, test_val_frac)\n",
    "        test_val = df.sample(n)\n",
    "\n",
    "        n = math.floor(len(test_val.index) * val_second_frac)\n",
    "        res = ((len(test_val.index) * val_second_frac) - n)/val_second_frac\n",
    "        n += np.random.binomial(res, val_second_frac)\n",
    "\n",
    "        val = test_val.sample(n)\n",
    "        val_patients.append(val)\n",
    "        test_patients.append(test_val[~test_val[\"ptID\"].isin(val[\"ptID\"])])\n",
    "        train_patients.append(df[~df[\"ptID\"].isin(test_val[\"ptID\"])])\n",
    "\n",
    "\n",
    "    train_pt_df = pd.concat(train_patients)\n",
    "    test_pt_df = pd.concat(test_patients)\n",
    "    val_pt_df = pd.concat(val_patients) if len(val_patients) > 0 else pd.DataFrame()\n",
    "\n",
    "    print(f\"Test high quality: {test_pt_df['noHQrecs'].sum()} low quality: {test_pt_df['noLQrecs'].sum()} \")\n",
    "    print(f\"Train high quality: {train_pt_df['noHQrecs'].sum()} low quality: {train_pt_df['noLQrecs'].sum()} \")\n",
    "    print(f\"Validation high quality: {val_pt_df['noHQrecs'].sum()} low quality: {val_pt_df['noLQrecs'].sum()} \")\n",
    "\n",
    "    train_dataloader = None\n",
    "    test_dataloader = None\n",
    "    val_dataloader = None\n",
    "\n",
    "    train_dataset = None\n",
    "    test_dataset = None\n",
    "    val_dataset = None\n",
    "\n",
    "    if not train_pt_df.empty:\n",
    "        # get ECG datasets\n",
    "        train_dataset = ecg_data[(ecg_data[\"ptID\"].isin(train_pt_df[\"ptID\"]))] # & (ecg_data[\"measDiag\"] != DiagEnum.Undecided)]\n",
    "        # Normalise\n",
    "        train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "\n",
    "        class_counts = torch.tensor(train_dataset[\"class_index\"].value_counts().values.astype(np.float32))\n",
    "        a = class_counts[0]/(class_counts[0] + class_counts[1])\n",
    "\n",
    "        sampler = WeightedRandomSampler(torch.tensor([a, 1-a]), 2)\n",
    "\n",
    "        if only_clean_training:\n",
    "            torch_dataset_train = Dataset(train_dataset[train_dataset[\"class_index\"] == 0])\n",
    "        else:\n",
    "            torch_dataset_train = Dataset(train_dataset)\n",
    "\n",
    "        train_dataloader = DataLoader(torch_dataset_train, batch_size=32, pin_memory=True, sampler=sampler)\n",
    "\n",
    "    if not test_pt_df.empty:\n",
    "        test_dataset = ecg_data[(ecg_data[\"ptID\"].isin(test_pt_df[\"ptID\"])) & (ecg_data[\"measDiag\"] != DiagEnum.Undecided)]\n",
    "        test_dataset[\"data\"] = (test_dataset[\"data\"] - test_dataset[\"data\"].map(lambda x: x.mean()))/test_dataset[\"data\"].map(lambda x: x.std())\n",
    "        torch_dataset_test = Dataset(test_dataset)\n",
    "        test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "    if not val_pt_df.empty:\n",
    "        val_dataset = ecg_data[(ecg_data[\"ptID\"].isin(val_pt_df[\"ptID\"])) & (ecg_data[\"measDiag\"] != DiagEnum.Undecided)]\n",
    "        val_dataset[\"data\"] = (val_dataset[\"data\"] - val_dataset[\"data\"].map(lambda x: x.mean()))/val_dataset[\"data\"].map(lambda x: x.std())\n",
    "        torch_dataset_val = Dataset(val_dataset)\n",
    "        val_dataloader = DataLoader(torch_dataset_val, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader, val_dataloader, train_dataset, test_dataset, val_dataset\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader, train_dataset, test_dataset, val_dataset = make_SAFER_dataloaders(feas2_pt_data, feas2_ecg_data, test_frac=0.15, val_frac=0.25)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "0    20551\n1      443\nName: class_index, dtype: int64"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"class_index\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "0    2157\n1      22\nName: class_index, dtype: int64"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[\"class_index\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Use only the labelled portions of feas2 data for training and testing\n",
    "\n",
    "feas2_ecg_data_no_undecided = feas2_ecg_data[feas2_ecg_data[\"measDiag\"] != DiagEnum.Undecided]\n",
    "\n",
    "feas2_pt_data_no_undecided = feas2_pt_data.copy()\n",
    "feas2_pt_data_no_undecided[\"noRecs\"] = feas2_ecg_data_no_undecided[\"ptID\"].value_counts()\n",
    "feas2_pt_data_no_undecided[\"noHQRecs\"] = feas2_ecg_data_no_undecided[feas2_ecg_data_no_undecided[\"measDiag\"] != DiagEnum.PoorQuality][\"ptID\"].value_counts()\n",
    "\n",
    "train_dataloader, test_dataloader, train_dataset, test_dataset = make_SAFER_dataloaders(feas2_pt_data_no_undecided, feas2_ecg_data_no_undecided, test_frac=0.2, only_clean_training=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feas2_ecg_data_unbalanced = feas2_ecg_data_unbalanced.drop(train_ecgs.index)\n",
    "feas2_ecg_data_unbalanced[\"class_index\"] = feas2_ecg_data_unbalanced[\"measDiag\"].map(lambda x: int(x == DiagEnum.PoorQuality))\n",
    "\n",
    "torch_dataset_test_unbalanced = Dataset(feas2_ecg_data_unbalanced)\n",
    "test_unbalanced_dataloader = DataLoader(torch_dataset_test_unbalanced, batch_size=32, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare for training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# Now import a model\n",
    "import Models.NoiseCNN\n",
    "import importlib\n",
    "importlib.reload(Models.NoiseCNN)\n",
    "from Models.NoiseCNN import CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using Cuda\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Use weightings to handle class imbalance\n",
    "\n",
    "class_counts = torch.tensor(train_dataset[\"class_index\"].value_counts().values.astype(np.float32))\n",
    "a = class_counts[0]/(class_counts[0] + class_counts[1])\n",
    "\n",
    "class binary_focal_loss(nn.Module):\n",
    "\n",
    "    def __init__(self, _alpha, _gamma):\n",
    "        super(binary_focal_loss, self).__init__()\n",
    "        self.BCE_loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        self.alpha = _alpha\n",
    "        self.gamma = _gamma\n",
    "\n",
    "    def forward(self, pred, targets):\n",
    "        bce = self.BCE_loss(pred, targets)\n",
    "        prob_correct = torch.exp(-bce)\n",
    "        loss_unweighted = (1.0 - prob_correct)**self.gamma * bce\n",
    "        loss_weighted = torch.where(targets == 1,\n",
    "                           loss_unweighted * self.alpha,\n",
    "                           loss_unweighted * (1-self.alpha))\n",
    "        return torch.mean(loss_weighted)\n",
    "\n",
    "loss_func = binary_focal_loss(0.5, 0)\n",
    "\n",
    "sampler = WeightedRandomSampler(torch.tensor([a, 1-a]), 2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = StepLR(optimizer, step_size=6, gamma=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0 ...\n",
      "Epoch 0 finished with average loss 0.31923335790634155\n",
      "Testing ...\n",
      "Average test loss: 0.3471134379506111\n",
      "starting epoch 1 ...\n",
      "Epoch 1 finished with average loss 0.3120512366294861\n",
      "Testing ...\n",
      "Average test loss: 0.3470748960971832\n",
      "starting epoch 2 ...\n",
      "Epoch 2 finished with average loss 0.31248217821121216\n",
      "Testing ...\n",
      "Average test loss: 0.34730226546525955\n",
      "starting epoch 3 ...\n",
      "Epoch 3 finished with average loss 0.3066568076610565\n",
      "Testing ...\n",
      "Average test loss: 0.3472636640071869\n",
      "starting epoch 4 ...\n",
      "Epoch 4 finished with average loss 0.30651408433914185\n",
      "Testing ...\n",
      "Average test loss: 0.34794066846370697\n",
      "starting epoch 5 ...\n",
      "Epoch 5 finished with average loss 0.3015957772731781\n",
      "Testing ...\n",
      "Average test loss: 0.34653452783823013\n",
      "starting epoch 6 ...\n",
      "Epoch 6 finished with average loss 0.3187685012817383\n",
      "Testing ...\n",
      "Average test loss: 0.347627155482769\n",
      "starting epoch 7 ...\n",
      "Epoch 7 finished with average loss 0.308758407831192\n",
      "Testing ...\n",
      "Average test loss: 0.34675197303295135\n",
      "starting epoch 8 ...\n",
      "Epoch 8 finished with average loss 0.2837445139884949\n",
      "Testing ...\n",
      "Average test loss: 0.34755268692970276\n",
      "starting epoch 9 ...\n",
      "Epoch 9 finished with average loss 0.30376574397087097\n",
      "Testing ...\n",
      "Average test loss: 0.34632474929094315\n",
      "starting epoch 10 ...\n",
      "Epoch 10 finished with average loss 0.2956256866455078\n",
      "Testing ...\n",
      "Average test loss: 0.3469058573246002\n",
      "starting epoch 11 ...\n",
      "Epoch 11 finished with average loss 0.3203478753566742\n",
      "Testing ...\n",
      "Average test loss: 0.34727390855550766\n",
      "starting epoch 12 ...\n",
      "Epoch 12 finished with average loss 0.28793537616729736\n",
      "Testing ...\n",
      "Average test loss: 0.346914641559124\n",
      "starting epoch 13 ...\n",
      "Epoch 13 finished with average loss 0.2636699080467224\n",
      "Testing ...\n",
      "Average test loss: 0.3472588509321213\n",
      "starting epoch 14 ...\n",
      "Epoch 14 finished with average loss 0.26574110984802246\n",
      "Testing ...\n",
      "Average test loss: 0.34742239117622375\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "model = model.to(device)\n",
    "\n",
    "def train(model):\n",
    "    best_test_loss = 100\n",
    "    best_epoch = -1\n",
    "    best_model = copy.deepcopy(model).cpu()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        print(f\"starting epoch {epoch} ...\")\n",
    "        # Train\n",
    "        num_batches = 0\n",
    "        model.train()\n",
    "        for i, (signals, labels, _) in enumerate(train_dataloader):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "            labels = labels.float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(signals).to(\"cpu\")[:, 0]\n",
    "            # print(\"Output and labels\")\n",
    "            # print(output)\n",
    "            # print(labels)\n",
    "            loss = loss_func(output, labels)\n",
    "            # print(f\"Loss: {loss}\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            num_batches += 1\n",
    "            total_loss += float(loss)\n",
    "\n",
    "        print(f\"Epoch {epoch} finished with average loss {total_loss/num_batches}\")\n",
    "        print(\"Testing ...\")\n",
    "        # Test\n",
    "        num_test_batches = 0\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, (signals, labels, _) in enumerate(test_dataloader):\n",
    "                signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "                labels = labels.float()\n",
    "                output = model(signals).to(\"cpu\")[:, 0]\n",
    "                # print(\"Output and labels\")\n",
    "                # print(output)\n",
    "                # print(labels)\n",
    "                loss = loss_func(output, labels)\n",
    "                # print(f\"Loss: {loss}\")\n",
    "                test_loss += float(loss)\n",
    "                num_test_batches += 1\n",
    "\n",
    "        print(f\"Average test loss: {test_loss/num_test_batches}\")\n",
    "        losses.append([total_loss/num_batches, test_loss/num_test_batches])\n",
    "\n",
    "        if test_loss/num_test_batches < best_test_loss:\n",
    "            best_model = copy.deepcopy(model).cpu()\n",
    "            best_test_loss = test_loss/num_test_batches\n",
    "            best_epoch = epoch\n",
    "        else:\n",
    "            if best_epoch + 10 <= epoch:\n",
    "                return best_model, losses\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    return best_model, losses\n",
    "\n",
    "model, losses = train(model)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "torch.save(model.state_dict(), \"TrainedModels/CNN_AlexNet_LSTM_Bidirectional_Final_States.pt\")\n",
    "train_dataset.to_pickle(\"TrainedModels/CNN_AlexNet_LSTM_Bidirectional_Final_States_feas2_train_set.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load(\"TrainedModels/CNN_AlexNet_LSTM_Bidirectional_Final_States.pt\", map_location=device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a training set and get a test set from its exclusion\n",
    "train_dataset = pd.read_pickle(\"TrainedModels/CNN_AlexNet_LSTM_Bidirectional_Final_States_feas2_train_set.pk\")\n",
    "\n",
    "train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "torch_dataset_train = Dataset(train_dataset)\n",
    "train_dataloader = DataLoader(torch_dataset_train, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_pt_df = feas2_pt_data[~feas2_pt_data[\"ptID\"].isin(train_dataset[\"ptID\"])]\n",
    "\n",
    "if not test_pt_df.empty:\n",
    "    test_dataset = test_dataset[test_dataset[\"measDiag\"] != DiagEnum.Undecided]\n",
    "    test_dataset[\"data\"] = (test_dataset[\"data\"] - test_dataset[\"data\"].map(lambda x: x.mean()))/test_dataset[\"data\"].map(lambda x: x.std())\n",
    "    torch_dataset_test = Dataset(test_dataset)\n",
    "    test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garbage collection - in case of CUDA out of memory error\n",
    "import gc\n",
    "model = None\n",
    "signals = None\n",
    "labels = None\n",
    "gc.collect() # Python thing\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_52616\\2488921067.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_dataset[\"prediction\"] = None\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_52616\\2488921067.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    }
   ],
   "source": [
    "test_dataset[\"prediction\"] = None\n",
    "\n",
    "def get_predictions(model, dataloader, dataset):\n",
    "    model.eval()\n",
    "\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    outputs = []\n",
    "    inds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (signals, labels, ind) in enumerate(dataloader):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "            labels = labels.detach().numpy()\n",
    "            true_labels.append(labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(signals).detach().to(\"cpu\").numpy()\n",
    "\n",
    "            prediction = output # np.argmax(output, axis=-1)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "            for i, o in zip(ind, output):\n",
    "                outputs.append(o[0])\n",
    "                inds.append(int(i))\n",
    "\n",
    "    dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    true_labels = np.concatenate(true_labels)\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "predictions, true_labels = get_predictions(model, test_dataloader, test_dataset)\n",
    "conf_mat = confusion_matrix(true_labels, predictions > 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[34 22]\n",
      " [35 23]]\n",
      "Sensitivity: 0.39655172413793105\n",
      "Specificity: 0.6071428571428571\n",
      "Normal F1: 0.544\n",
      "Noisy F1: 0.44660194174757284\n"
     ]
    }
   ],
   "source": [
    "#ConfusionMatrixDisplay.from_predictions(true_labels, predictions, display_labels=[\"sufficint quality\", \"insufficient quality\"], cmap=\"inferno\")\n",
    "\n",
    "# Same as the below function (as described in CinC)\n",
    "def F1_ind(conf_mat, ind):\n",
    "    return (2 * conf_mat[ind, ind])/(np.sum(conf_mat[ind]) + np.sum(conf_mat[:, ind]))\n",
    "\n",
    "\"\"\"\n",
    "def bin_F1_score(conf_mat, ind):\n",
    "    return conf_mat[ind, ind]/(conf_mat[ind, ind] + 0.5 * (conf_mat[0, 1] + conf_mat[1, 0]))\n",
    "\n",
    "print(f\"Normal F1: {bin_F1_score(conf_mat, 0)}\")\n",
    "print(f\"Noisy F1: {bin_F1_score(conf_mat, 1)}\")\n",
    "\"\"\"\n",
    "print(\"Confusion matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "print(f\"Sensitivity: {conf_mat[1, 1]/np.sum(conf_mat[1])}\")\n",
    "print(f\"Specificity: {conf_mat[0, 0]/np.sum(conf_mat[0])}\")\n",
    "\n",
    "print(f\"Normal F1: {F1_ind(conf_mat, 0)}\")\n",
    "print(f\"Noisy F1: {F1_ind(conf_mat, 1)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "p, r, d = precision_recall_curve(true_labels, predictions)\n",
    "\n",
    "point = np.argmin(np.abs(d - 0.5))\n",
    "p_point = p[point]\n",
    "r_point = r[point]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=r, y=p, hovertext=[f\"decision boundary: {x:.2f}\" for x in d]))\n",
    "\n",
    "fig.update_xaxes(title=\"Recall\")\n",
    "fig.update_yaxes(title=\"Precision\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_dataset = test_dataset[(test_dataset[\"prediction\"] > 0) & (test_dataset[\"class_index\"] == 0)]\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "def plot_ecg(x, fs=500):\n",
    "    sample_len = x.shape[0]\n",
    "    time_axis = np.arange(sample_len)/fs\n",
    "\n",
    "    y_step = 2\n",
    "\n",
    "    cuts = [0, sample_len//3, (sample_len*2)//3, sample_len-1]\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(8, 6))\n",
    "    for j in range(3):\n",
    "        ax[j].plot(time_axis[cuts[j]:cuts[j+1]], x[cuts[j]:cuts[j+1]])\n",
    "        ax[j].set_xlabel(\"Time\")\n",
    "        ax[j].set_xlim((time_axis[cuts[j]], time_axis[cuts[j+1]]))\n",
    "\n",
    "        t_s = time_axis[cuts[j]]\n",
    "        t_f = time_axis[cuts[j+1]]\n",
    "        time_ticks = np.arange(t_s - t_s%0.2, t_f + (0.2 - t_f%0.2), 0.2)\n",
    "        decimal_labels = ~np.isclose(time_ticks, np.round(time_ticks))\n",
    "        time_labels = np.round(time_ticks).astype(int).astype(str)\n",
    "        time_labels[decimal_labels] = \"\"\n",
    "\n",
    "        ax[j].set_xticks(time_ticks, labels=time_labels)\n",
    "        ax[j].set_yticks(np.arange(x.min()-y_step, x.max()+y_step, y_step))\n",
    "\n",
    "        # ax[j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        # ax[j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "        ax[j].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "        ax[j].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "        ax[j].set_ylim((x.min()-y_step, x.max()+y_step))\n",
    "        ax[j].set_xlim((t_s, t_f))\n",
    "\n",
    "        ax[j].grid(which='major', linestyle='-', linewidth='0.2', color='black')\n",
    "        ax[j].grid(which='minor', linestyle='-', linewidth='0.2', color='lightgray')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # plt.savefig(\"test_ecg_plot.png\", dpi=300)\n",
    "    # plt.show()\n",
    "\n",
    "c = DiagEnum.CannotExcludePathology\n",
    "\n",
    "for _, ecg in plot_dataset[plot_dataset[\"measDiag\"].map(lambda x: x.value) == 3].sample(frac=1).iterrows():\n",
    "    print(ecg[[\"ptDiag\", \"tag_orig_Poor_Quality\", \"poss_AF_tag\", \"measDiag\", \"prediction\"]])\n",
    "    plot_ecg(ecg[\"data\"], 300)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Used to generate figures for the report\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/ (1 + np.exp(-x))\n",
    "\n",
    "def plot_ecg_section_examples(xs, ranges, titles, fs=300):\n",
    "    fig, ax = plt.subplots(len(xs), 1, figsize=(6, 4))\n",
    "\n",
    "    for j, (x, r, t) in enumerate(zip(xs, ranges, titles)):\n",
    "        sample_len = r[1] - r[0]\n",
    "        time_axis = np.arange(sample_len)/fs\n",
    "\n",
    "        ax[j].plot(time_axis, x[r[0]:r[1]])\n",
    "        ax[j].set_xlabel(\"Time\")\n",
    "        ax[j].set_xlim((time_axis[0], time_axis[-1]))\n",
    "\n",
    "        t_s = time_axis[0]\n",
    "        t_f = time_axis[-1]\n",
    "        time_ticks = np.arange(t_s - t_s%0.2, t_f + (0.2 - t_f%0.2), 0.2)\n",
    "        decimal_labels = ~np.isclose(time_ticks, np.round(time_ticks))\n",
    "        time_labels = np.round(time_ticks).astype(int).astype(str)\n",
    "        time_labels[decimal_labels] = \"\"\n",
    "        ax[j].set_xticks(time_ticks, time_labels)\n",
    "\n",
    "        ax[j].set_title(t)\n",
    "\n",
    "        ax[j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "        ax[j].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "        ax[j].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "        ax[j].grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "        ax[j].grid(which='minor', linestyle='-', linewidth='0.5', color='lightgray')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(\"TMRFigures/cnn_false_positive_examples.png\")\n",
    "\n",
    "ecg_ind_list = [1248, 12804]\n",
    "ranges = [(0, 3010), (3000, 6010)]\n",
    "\n",
    "xs = plot_dataset.loc[ecg_ind_list][\"data\"].tolist()\n",
    "\n",
    "titles = plot_dataset.loc[ecg_ind_list].apply(lambda x: f\"{x['measDiag'].name}, p(noisy) = {sigmoid(x['prediction']):.3f}\", axis=1)   # [\"measDiag\"].map(lambda x: x.name).tolist()\n",
    "print(len(titles))\n",
    "\n",
    "plot_ecg_section_examples(xs, ranges, titles)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform cross validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "0    18243\n",
      "1      364\n",
      "Name: class_index, dtype: int64\n",
      "1    101\n",
      "0     96\n",
      "Name: class_index, dtype: int64\n",
      "starting epoch 0 ...\n",
      "Epoch 0 finished with average loss 0.0072191464426668035\n",
      "Testing ...\n",
      "Average test loss: 0.04729761076825006\n",
      "starting epoch 1 ...\n",
      "Epoch 1 finished with average loss 0.006027607661687939\n",
      "Testing ...\n",
      "Average test loss: 0.04210886039904186\n",
      "starting epoch 2 ...\n",
      "Epoch 2 finished with average loss 0.004987984370437044\n",
      "Testing ...\n",
      "Average test loss: 0.036189168957727294\n",
      "starting epoch 3 ...\n",
      "Epoch 3 finished with average loss 0.0042832474935563004\n",
      "Testing ...\n",
      "Average test loss: 0.035378552973270416\n",
      "starting epoch 4 ...\n",
      "Epoch 4 finished with average loss 0.003657153038079194\n",
      "Testing ...\n",
      "Average test loss: 0.03588196182889598\n",
      "starting epoch 5 ...\n",
      "Epoch 5 finished with average loss 0.0034248441484951994\n",
      "Testing ...\n",
      "Average test loss: 0.0334846382694585\n",
      "starting epoch 6 ...\n",
      "Epoch 6 finished with average loss 0.0029262187092603405\n",
      "Testing ...\n",
      "Average test loss: 0.03897738962301186\n",
      "starting epoch 7 ...\n",
      "Epoch 7 finished with average loss 0.0025889304721779176\n",
      "Testing ...\n",
      "Average test loss: 0.036938706412911415\n",
      "starting epoch 8 ...\n",
      "Epoch 8 finished with average loss 0.0021366468156468685\n",
      "Testing ...\n",
      "Average test loss: 0.05949308457119124\n",
      "starting epoch 9 ...\n",
      "Epoch 9 finished with average loss 0.0019957264996821036\n",
      "Testing ...\n",
      "Average test loss: 0.06268871282892567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_52616\\2488921067.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77 19]\n",
      " [ 4 97]]\n",
      "Fold 1\n",
      "0    18128\n",
      "1      429\n",
      "Name: class_index, dtype: int64\n",
      "0    83\n",
      "1    36\n",
      "Name: class_index, dtype: int64\n",
      "starting epoch 0 ...\n",
      "Epoch 0 finished with average loss 0.007020425285887102\n",
      "Testing ...\n",
      "Average test loss: 0.03930687624961138\n",
      "starting epoch 1 ...\n",
      "Epoch 1 finished with average loss 0.0061765740693803745\n",
      "Testing ...\n",
      "Average test loss: 0.030746130738407373\n",
      "starting epoch 2 ...\n",
      "Epoch 2 finished with average loss 0.005350805167108774\n",
      "Testing ...\n",
      "Average test loss: 0.027397357393056154\n",
      "starting epoch 3 ...\n",
      "Epoch 3 finished with average loss 0.004753655232970827\n",
      "Testing ...\n",
      "Average test loss: 0.03136730333790183\n",
      "starting epoch 4 ...\n",
      "Epoch 4 finished with average loss 0.004179629686103877\n",
      "Testing ...\n",
      "Average test loss: 0.0219472695607692\n",
      "starting epoch 5 ...\n",
      "Epoch 5 finished with average loss 0.0036557715970236037\n",
      "Testing ...\n",
      "Average test loss: 0.0299018993973732\n",
      "starting epoch 6 ...\n",
      "Epoch 6 finished with average loss 0.003486844927979762\n",
      "Testing ...\n",
      "Average test loss: 0.026640621479600668\n",
      "starting epoch 7 ...\n",
      "Epoch 7 finished with average loss 0.00313880412712902\n",
      "Testing ...\n",
      "Average test loss: 0.034035010263323784\n",
      "starting epoch 8 ...\n",
      "Epoch 8 finished with average loss 0.0028030529848083146\n",
      "Testing ...\n",
      "Average test loss: 0.046807863749563694\n",
      "starting epoch 9 ...\n",
      "Epoch 9 finished with average loss 0.002597128656132805\n",
      "Testing ...\n",
      "Average test loss: 0.05121712572872639\n",
      "[[73 10]\n",
      " [ 2 34]]\n",
      "Fold 2\n",
      "0    18252\n",
      "1      381\n",
      "Name: class_index, dtype: int64\n",
      "0    297\n",
      "1     84\n",
      "Name: class_index, dtype: int64\n",
      "starting epoch 0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_52616\\2488921067.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finished with average loss 0.006556240876890578\n",
      "Testing ...\n",
      "Average test loss: 0.036216942593455315\n",
      "starting epoch 1 ...\n",
      "Epoch 1 finished with average loss 0.0053969075340988505\n",
      "Testing ...\n",
      "Average test loss: 0.02984806173481047\n",
      "starting epoch 2 ...\n",
      "Epoch 2 finished with average loss 0.0045434621463834885\n",
      "Testing ...\n",
      "Average test loss: 0.02626833397274216\n",
      "starting epoch 3 ...\n",
      "Epoch 3 finished with average loss 0.004010197097087346\n",
      "Testing ...\n",
      "Average test loss: 0.03198685341825088\n",
      "starting epoch 4 ...\n",
      "Epoch 4 finished with average loss 0.003633790676430903\n",
      "Testing ...\n",
      "Average test loss: 0.02926559226276974\n",
      "starting epoch 5 ...\n",
      "Epoch 5 finished with average loss 0.003087441179155345\n",
      "Testing ...\n",
      "Average test loss: 0.04695548536255956\n",
      "starting epoch 6 ...\n",
      "Epoch 6 finished with average loss 0.0029179069779072067\n",
      "Testing ...\n",
      "Average test loss: 0.03300327931841215\n",
      "starting epoch 7 ...\n",
      "Epoch 7 finished with average loss 0.0027218349579494847\n",
      "Testing ...\n",
      "Average test loss: 0.0344175873324275\n",
      "starting epoch 8 ...\n",
      "Epoch 8 finished with average loss 0.002405488336074212\n",
      "Testing ...\n",
      "Average test loss: 0.0432020272128284\n",
      "starting epoch 9 ...\n",
      "Epoch 9 finished with average loss 0.0022203065928209117\n",
      "Testing ...\n",
      "Average test loss: 0.07939969018722574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_52616\\2488921067.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[212  85]\n",
      " [  7  77]]\n",
      "Fold 3\n",
      "0    18352\n",
      "1      254\n",
      "Name: class_index, dtype: int64\n",
      "1    211\n",
      "0    171\n",
      "Name: class_index, dtype: int64\n",
      "starting epoch 0 ...\n",
      "Epoch 0 finished with average loss 0.005953045097448546\n",
      "Testing ...\n",
      "Average test loss: 0.06884775155534346\n",
      "starting epoch 1 ...\n",
      "Epoch 1 finished with average loss 0.00497480205266618\n",
      "Testing ...\n",
      "Average test loss: 0.06763351957003276\n",
      "starting epoch 2 ...\n",
      "Epoch 2 finished with average loss 0.00417460449267166\n",
      "Testing ...\n",
      "Average test loss: 0.07970229256898165\n",
      "starting epoch 3 ...\n",
      "Epoch 3 finished with average loss 0.00354773373362253\n",
      "Testing ...\n",
      "Average test loss: 0.08476139542957146\n",
      "starting epoch 4 ...\n",
      "Epoch 4 finished with average loss 0.0029527926729524773\n",
      "Testing ...\n",
      "Average test loss: 0.1131293053428332\n",
      "starting epoch 5 ...\n",
      "Epoch 5 finished with average loss 0.0027213863631601596\n",
      "Testing ...\n",
      "Average test loss: 0.09249040391296148\n",
      "starting epoch 6 ...\n",
      "Epoch 6 finished with average loss 0.0025322476861585584\n",
      "Testing ...\n",
      "Average test loss: 0.09662674802045028\n",
      "starting epoch 7 ...\n",
      "Epoch 7 finished with average loss 0.0021999769092915914\n",
      "Testing ...\n",
      "Average test loss: 0.16024882532656193\n",
      "starting epoch 8 ...\n",
      "Epoch 8 finished with average loss 0.0021187387100985765\n",
      "Testing ...\n",
      "Average test loss: 0.13227947304646173\n",
      "starting epoch 9 ...\n",
      "Epoch 9 finished with average loss 0.001794495001952148\n",
      "Testing ...\n",
      "Average test loss: 0.20794097458322844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_52616\\2488921067.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108  63]\n",
      " [ 30 181]]\n",
      "Fold 4\n",
      "0    18201\n",
      "1      432\n",
      "Name: class_index, dtype: int64\n",
      "0    129\n",
      "1     33\n",
      "Name: class_index, dtype: int64\n",
      "starting epoch 0 ...\n",
      "Epoch 0 finished with average loss 0.007128834956857547\n",
      "Testing ...\n",
      "Average test loss: 0.022524835697064798\n",
      "starting epoch 1 ...\n",
      "Epoch 1 finished with average loss 0.006142732488809355\n",
      "Testing ...\n",
      "Average test loss: 0.02084058220498264\n",
      "starting epoch 2 ...\n",
      "Epoch 2 finished with average loss 0.005095461859107401\n",
      "Testing ...\n",
      "Average test loss: 0.020143028581514955\n",
      "starting epoch 3 ...\n",
      "Epoch 3 finished with average loss 0.004315795180408562\n",
      "Testing ...\n",
      "Average test loss: 0.022115352874000866\n",
      "starting epoch 4 ...\n",
      "Epoch 4 finished with average loss 0.0038698757585301025\n",
      "Testing ...\n",
      "Average test loss: 0.02639660966815427\n",
      "starting epoch 5 ...\n",
      "Epoch 5 finished with average loss 0.0035194192068910106\n",
      "Testing ...\n",
      "Average test loss: 0.022788536657268803\n",
      "starting epoch 6 ...\n",
      "Epoch 6 finished with average loss 0.003065909781492448\n",
      "Testing ...\n",
      "Average test loss: 0.03330061056961616\n",
      "starting epoch 7 ...\n",
      "Epoch 7 finished with average loss 0.0028663482976275436\n",
      "Testing ...\n",
      "Average test loss: 0.04615320482601722\n",
      "starting epoch 8 ...\n",
      "Epoch 8 finished with average loss 0.002414488016869745\n",
      "Testing ...\n",
      "Average test loss: 0.04404483461015237\n",
      "starting epoch 9 ...\n",
      "Epoch 9 finished with average loss 0.0023384256724517404\n",
      "Testing ...\n",
      "Average test loss: 0.05538370025654634\n",
      "[[98 31]\n",
      " [ 6 27]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_52616\\2488921067.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation dataset construction for SAFER data\n",
    "# Split train and test data according to each patient\n",
    "feas2_pt_data[\"noLQrecs\"] = feas2_pt_data[\"noRecs\"] - feas2_pt_data[\"noHQrecs\"]\n",
    "\n",
    "num_folds = 5\n",
    "test_pt_folds = [[] for _ in range(num_folds)]\n",
    "\n",
    "sorted_pts = feas2_pt_data.sort_values(\"noLQrecs\", axis=0)\n",
    "group_num = 0\n",
    "\n",
    "# Go around the folds and assign patients to each\n",
    "for _, pt in sorted_pts.iterrows():\n",
    "    test_pt_folds[group_num].append(pt)\n",
    "    group_num = (group_num + 1) % num_folds\n",
    "\n",
    "test_pt_folds = [pd.DataFrame(fold) for fold in test_pt_folds]\n",
    "train_pt_folds = [feas2_pt_data[~feas2_pt_data[\"ptID\"].isin(fold[\"ptID\"])] for fold in test_pt_folds]\n",
    "\n",
    "conf_mats = []\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for i, (train_pt_df, test_pt_df) in enumerate(zip(train_pt_folds, test_pt_folds)):\n",
    "    print(f\"Fold {i}\")\n",
    "    train_df = feas2_ecg_data[feas2_ecg_data[\"ptID\"].isin(train_pt_df[\"ptID\"])]\n",
    "    test_df = feas2_ecg_data[(feas2_ecg_data[\"ptID\"].isin(test_pt_df[\"ptID\"])) & (feas2_ecg_data[\"measDiag\"] != DiagEnum.Undecided)]\n",
    "\n",
    "    torch_dataset_train = Dataset(train_df)\n",
    "    torch_dataset_test = Dataset(test_df)\n",
    "\n",
    "    print(train_df[\"class_index\"].value_counts())\n",
    "    print(test_df[\"class_index\"].value_counts())\n",
    "\n",
    "    train_dataloader = DataLoader(torch_dataset_train, batch_size=32, shuffle=True, pin_memory=True)\n",
    "    test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "    model = CNN().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00002)\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.5)\n",
    "\n",
    "    num_batches = len(train_dataloader)\n",
    "    num_test_batches = len(test_dataloader)\n",
    "\n",
    "    model, losses = train(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    predictions, true_labels = get_predictions(model, test_dataloader, test_df)\n",
    "    conf_mat = confusion_matrix(true_labels, predictions > 0)\n",
    "\n",
    "    print(conf_mat)\n",
    "\n",
    "    conf_mats.append(conf_mat)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 normal: 0.8312086798789824\n",
      "Mean F1 noisy: 0.7518072931526905\n",
      "Individual F1 scores (noisy): [0.8940092165898618, 0.85, 0.6260162601626016, 0.7956043956043956, 0.5934065934065934]\n"
     ]
    }
   ],
   "source": [
    "f1_scores_normal = [F1_ind(c, 0) for c in conf_mats]\n",
    "f1_scores_noisy = [F1_ind(c, 1) for c in conf_mats]\n",
    "\n",
    "print(f\"Mean F1 normal: {np.mean(f1_scores_normal)}\")\n",
    "print(f\"Mean F1 noisy: {np.mean(f1_scores_noisy)}\")\n",
    "print(f\"Individual F1 scores (noisy): {f1_scores_noisy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for c in conf_mats:\n",
    "    print(c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on the noise stress test database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stress test noise data\n",
    "import wfdb\n",
    "import os\n",
    "import scipy.signal\n",
    "\n",
    "noise_stress_test_db = \"mit-bih-noise-stress-test-database\"\n",
    "stress_test_files = [\"118e24\", \"119e24\", \"118e06\", \"118e00\", \"118e_6\", \"119e06\", \"119e00\", \"119e_6\"]\n",
    "\n",
    "labels = []\n",
    "noise_level = []\n",
    "samples = []\n",
    "\n",
    "# Additionally band pass filter\n",
    "def filter_ecg(x, fs):\n",
    "    b, a = scipy.signal.butter(3, [0.66, 50], 'band', fs=fs)\n",
    "    x = scipy.signal.filtfilt(b, a, x, padlen=150)\n",
    "    x = (x - min(x)) / (max(x) - min(x))\n",
    "    return x\n",
    "\n",
    "for file in stress_test_files:\n",
    "    try:\n",
    "        print(f\"Reading file: {file}\")\n",
    "        data = wfdb.io.rdrecord(os.path.join(noise_stress_test_db, file))\n",
    "        all_data_v1 = data.p_signal[:,1]\n",
    "        # Resample to 300Hz\n",
    "        all_data_v1 = scipy.signal.resample(all_data_v1, int(all_data_v1.shape[0] * 300/data.fs))\n",
    "        # all_data_v1 = filter_ecg(all_data_v1, data.fs)\n",
    "        # all_data_v1 = adaptive_gain_norm(all_data_v1, 501)\n",
    "\n",
    "        sec_len = 300 * 30  # 30s segments\n",
    "        i = 1\n",
    "        while i * sec_len < all_data_v1.shape[0]:\n",
    "            s = all_data_v1[(i-1)*sec_len:i*sec_len]\n",
    "            samples.append(s)\n",
    "            noise_level.append(file.split(\"e\")[-1])\n",
    "\n",
    "            if i * 30 < 300:\n",
    "                labels.append(\"N\")\n",
    "            elif (i * 30 - 300) % 240 > 120 or (i * 30 - 300) % 240 == 0:\n",
    "                labels.append(\"N\")\n",
    "            elif (i * 30 - 300) % 240 <= 120:\n",
    "                labels.append(\"~\")\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"error, scipping file\")\n",
    "        continue\n",
    "\n",
    "\n",
    "nst_df = pd.DataFrame({\"data\": samples, \"class\": labels, \"noise_level\": noise_level})\n",
    "pk_path = \"mit-bih-noise-stress-test-database/database.pk\"\n",
    "nst_df.to_pickle(pk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nst_df[\"class_index\"] = (nst_df[\"class\"] == \"~\").astype(int)\n",
    "\n",
    "class NSTDataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dataset.index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.dataset.iloc[index]\n",
    "\n",
    "        X = row[\"data\"]  # The only dataset and nst dataset difference is in this line!\n",
    "        y = row[\"class_index\"]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "# Normalise the data\n",
    "nst_df[\"data\"] = (nst_df[\"data\"] - nst_df[\"data\"].map(lambda x: x.mean()))/nst_df[\"data\"].map(lambda x: x.std())\n",
    "\n",
    "torch_dataset_nst = NSTDataset(nst_df)\n",
    "nst_dataloader = DataLoader(torch_dataset_nst, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "false_positives = []\n",
    "true_negatives = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (signals, labels) in enumerate(nst_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        labels = labels.detach().numpy()\n",
    "        true_labels.append(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(signals).detach().to(\"cpu\").numpy()\n",
    "\n",
    "        prediction = np.argmax(output, axis=-1)\n",
    "        false_positive = np.logical_and(labels == 0, prediction == 1)\n",
    "        false_positives.append(signals[false_positive, 0, :].cpu().detach().numpy())\n",
    "\n",
    "        true_negative = np.logical_and(labels == 1, prediction == 0)\n",
    "        true_negatives.append(signals[true_negative, 0, :].cpu().detach().numpy())\n",
    "\n",
    "        predictions.append(np.argmax(output, axis=-1))\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "true_labels = np.concatenate(true_labels)\n",
    "false_positives = np.concatenate(false_positives, axis=0)\n",
    "true_negatives = np.concatenate(true_negatives, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(true_labels, predictions, display_labels=[\"sufficint quality\", \"insufficient quality\"], cmap=\"inferno\")\n",
    "\n",
    "conf_mat = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "def F1_ind(conf_mat, ind):\n",
    "    return (2 * conf_mat[ind, ind])/(np.sum(conf_mat[ind]) + np.sum(conf_mat[:, ind]))\n",
    "\n",
    "print(f\"Normal F1: {F1_ind(conf_mat, 0)}\")\n",
    "print(f\"Other F1: {F1_ind(conf_mat, 1)}\")\n",
    "# print(f\"AF F1: {F1_ind(conf_mat, 2)}\")\n",
    "# print(f\"Noisy F1: {F1_ind(conf_mat, 3)}\")\n",
    "\n",
    "print(f\"Average F1 score: {sum([F1_ind(conf_mat, i) for i in range(2)])/2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 40\n",
    "print(false_positives.shape)\n",
    "\n",
    "fig = go.Figure(go.Scatter(y=false_positives[index]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 15\n",
    "print(true_negatives.shape)\n",
    "\n",
    "fig = go.Figure(go.Scatter(y=true_negatives[index]))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
