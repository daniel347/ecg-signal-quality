{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import DataHandlers.CinCDataset as CinCDataset\n",
    "import DataHandlers.SAFERDataset as SAFERDataset\n",
    "\n",
    "import importlib\n",
    "importlib.reload(SAFERDataset)\n",
    "importlib.reload(CinCDataset)\n",
    "\n",
    "from DataHandlers.DiagEnum import DiagEnum, feas1DiagToEnum\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"text.usetex\"] = False\n",
    "\n",
    "# A fudge because I moved the files\n",
    "sys.modules[\"SAFERDataset\"] = SAFERDataset\n",
    "sys.modules[\"CinCDataset\"] = CinCDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "feas2_pt_data, feas2_ecg_data = SAFERDataset.load_feas_dataset(2, \"dataframe\")\n",
    "feas2_ecg_data = feas2_ecg_data[feas2_ecg_data[\"length\"] == 9120]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feas1_pt_data, feas1_ecg_data = SAFERDataset.load_feas_dataset(1, ecg_meas_diag=[d for d in DiagEnum if d != DiagEnum.Undecided])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load specially cleaned data\n",
    "\n",
    "feas2_ecg_data = pd.read_pickle(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas2\\ECGs\\filtered_dataframe.pk\")\n",
    "feas2_pt_data = pd.read_csv(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas2\\pt_data_anon.csv\")\n",
    "feas2_pt_data[\"ptID\"] += 10000\n",
    "feas2_ecg_data[\"ptID\"] += 10000\n",
    "\n",
    "feas1_ecg_data_clean = pd.read_pickle(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas1\\ECGs\\clean_ecg_dataset.pk\")\n",
    "feas1_pt_data = pd.read_csv(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas1\\pt_data_anon.csv\")\n",
    "print(len(feas1_ecg_data_clean.index))\n",
    "\n",
    "feas2_ecg_data_clean = pd.read_pickle(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas2\\ECGs\\clean_ecg_dataset.pk\")\n",
    "feas2_ecg_data_clean[\"ptID\"] += 10000\n",
    "print(len(feas2_ecg_data_clean.index))\n",
    "\n",
    "all_clean_data = pd.concat([feas2_ecg_data_clean, feas1_ecg_data_clean], ignore_index=True)\n",
    "all_clean_pt = pd.concat([feas2_pt_data[feas2_pt_data[\"ptID\"].isin(feas2_ecg_data_clean[\"ptID\"])], feas1_pt_data[feas1_pt_data[\"ptID\"].isin(feas1_ecg_data_clean[\"ptID\"])]])\n",
    "\n",
    "all_clean_pt.set_index(\"ptID\", drop=False, inplace=True)\n",
    "all_clean_pt[\"noRecs\"] = all_clean_data[\"ptID\"].value_counts()\n",
    "all_clean_pt[\"noHQrecs\"] = all_clean_pt[\"noRecs\"]\n",
    "all_clean_pt.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.conv_section1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Conv1d(16, 16, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "\n",
    "        self.conv_section2 = nn.Sequential(\n",
    "            nn.Conv1d(16, 16, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Conv1d(16, 16, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "\n",
    "        self.conv_section3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 9, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, 9, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "\n",
    "        self.conv_section4 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, 9, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, 9, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "\n",
    "        self.conv_section5 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 64, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        self.conv_section6 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 64, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv_section7 = nn.Sequential(\n",
    "            nn.Conv1d(64, 80, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(80),\n",
    "            nn.Conv1d(80, 80, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(80)\n",
    "        )\n",
    "\n",
    "        self.encoder_linear = nn.Linear(5120, z_dim*2)\n",
    "        self.decoder_linear = nn.Linear(z_dim, 5120)\n",
    "\n",
    "        self.decoder_batchnorm = nn.BatchNorm1d(5120)\n",
    "\n",
    "        self.transconv_section1 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(16, 1, 19, padding=9, stride=1),\n",
    "        )\n",
    "\n",
    "        self.transconv_section2 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(16, 16, 20, padding=9, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "        )\n",
    "\n",
    "        self.transconv_section3 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(32, 16, 20, padding=9, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "        )\n",
    "\n",
    "        self.transconv_section4 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(48, 32, 10, padding=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "        )\n",
    "\n",
    "        self.transconv_section5 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 48, 10, padding=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(48),\n",
    "        )\n",
    "\n",
    "        self.transconv_section6 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 64, 8, padding=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        self.transconv_section7 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(80, 64, 7, padding=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def encode(self, x):\n",
    "        # [1, 2048]\n",
    "        x = self.conv_section1(x)\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [16, 1024]\n",
    "        x = self.conv_section2(x) + x\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [32, 512]\n",
    "        x = self.conv_section3(x)\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [32, 256]\n",
    "        x = self.conv_section4(x) + x\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [64, 128]\n",
    "        x = self.conv_section5(x)\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [64, 64]\n",
    "        # x = self.conv_section6(x)\n",
    "\n",
    "        # [64, 64]\n",
    "        x = self.conv_section7(x)\n",
    "\n",
    "        # [80, 64]\n",
    "        x = torch.flatten(x, -2)\n",
    "\n",
    "        # [5120]\n",
    "        x = self.encoder_linear(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z):\n",
    "        # [z_dim]\n",
    "        z = self.decoder_linear(z)\n",
    "        z = self.decoder_batchnorm(z)\n",
    "        z = torch.nn.functional.relu(z)\n",
    "\n",
    "        # [5120]\n",
    "        z = torch.reshape(z, (-1, 80, 64))\n",
    "        # [80, 64]\n",
    "        z = self.transconv_section7(z)\n",
    "        # print(z.shape)\n",
    "        # [64, 64]\n",
    "        z = self.transconv_section6(z)\n",
    "        # print(z.shape)\n",
    "        # [64, 64]\n",
    "        z = self.transconv_section5(z)\n",
    "        # print(z.shape)\n",
    "        # [64, 128]\n",
    "        z = self.transconv_section4(z)\n",
    "        # print(z.shape)\n",
    "        # [48, 256]\n",
    "        z = self.transconv_section3(z)\n",
    "        # print(z.shape)\n",
    "        # [32, 512]\n",
    "        z = self.transconv_section2(z)\n",
    "        # print(z.shape)\n",
    "        # [16, 1024]\n",
    "        z = self.transconv_section1(z)\n",
    "        # print(z.shape)\n",
    "        # [1, 2048]\n",
    "        return z\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        device = x.device\n",
    "\n",
    "        z_dist = self.encode(x)\n",
    "\n",
    "        z = torch.randn((batch_size, self.z_dim)).to(device) * torch.abs(z_dist[:, self.z_dim:]) + z_dist[:, :self.z_dim]\n",
    "\n",
    "        x = self.decode(z)\n",
    "\n",
    "        return x, z_dist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Onehot encoding\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dataset.index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.dataset.iloc[index]\n",
    "\n",
    "        X = row[\"data\"]\n",
    "        y = row[\"class_index\"]\n",
    "        ind = row.name\n",
    "\n",
    "        return X, y, ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def split_to_segments(dataset, new_len, orig_len, overlap=0):\n",
    "    sections = []\n",
    "\n",
    "    step = int(round(new_len * (1 - overlap)))\n",
    "    num_sections = (orig_len - (new_len - step)) // step\n",
    "    for _, series in dataset.iterrows():\n",
    "        for i in range(num_sections):\n",
    "            section_series = series.copy()\n",
    "            section_series[\"data\"] = section_series[\"data\"][i*step: i*step + new_len]\n",
    "            section_series[\"rec_ind\"] = series.name\n",
    "            section_series[\"rec_pos\"] = i\n",
    "            # Keep all other data (ptid, measDiag etc the same for each section as the source ECG)\n",
    "            sections.append(section_series)\n",
    "\n",
    "    return pd.DataFrame(sections).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: {}e24\n",
      "Reading file: {}e18\n",
      "Reading file: {}e12\n",
      "Reading file: {}e06\n",
      "Reading file: {}e00\n",
      "Reading file: {}e_6\n",
      "(80, 36000, 2)\n",
      "(80,)\n",
      "                                                data noise_level\n",
      "0  [[0.3312468686967197, 0.3311064649390682], [0....          18\n",
      "1  [[0.24693839443213594, 0.2469337171289498], [0...          18\n",
      "2  [[0.31591256523135075, 0.3157968018720345], [0...          18\n",
      "3  [[0.3151409111582182, 0.3150263905779494], [0....          18\n",
      "4  [[0.3116020534473094, 0.31149323235514687], [0...          18\n"
     ]
    }
   ],
   "source": [
    "# For MIT noise stress test database\n",
    "import wfdb\n",
    "import os\n",
    "import scipy.signal\n",
    "\n",
    "noise_stress_test_db = \"mit-bih-noise-stress-test-database\"\n",
    "records = [\"118\", \"119\"]\n",
    "stress_test_files = [\"{}e24\", \"{}e18\", \"{}e12\", \"{}e06\", \"{}e00\", \"{}e_6\"]\n",
    "\n",
    "noise_level = []\n",
    "segments_lists = []\n",
    "\n",
    "# Additionally band pass filter\n",
    "def filter_ecg(x, fs):\n",
    "    b, a = scipy.signal.butter(3, [0.66, 30], 'band', fs=fs)\n",
    "    x = scipy.signal.filtfilt(b, a, x, padlen=150)\n",
    "    x = (x - min(x)) / (max(x) - min(x))\n",
    "    return x\n",
    "\n",
    "for file in stress_test_files:\n",
    "    try:\n",
    "        print(f\"Reading file: {file}\")\n",
    "        data = wfdb.io.rdrecord(os.path.join(noise_stress_test_db, file.format(records[0])))\n",
    "        all_data_v1 = data.p_signal[:,1]\n",
    "        # Resample to 300Hz\n",
    "        fs = 300\n",
    "        all_data_v1 = scipy.signal.resample(all_data_v1, int(all_data_v1.shape[0] * fs/data.fs))\n",
    "        all_data_v1 = filter_ecg(all_data_v1, 300)\n",
    "        # all_data_v1 = adaptive_gain_norm(all_data_v1, 501)\n",
    "\n",
    "        data = wfdb.io.rdrecord(os.path.join(noise_stress_test_db, file.format(records[1])))\n",
    "        all_data_v2 = data.p_signal[:,1]\n",
    "        # Resample to 300Hz\n",
    "        fs = 300\n",
    "        all_data_v2 = scipy.signal.resample(all_data_v2, int(all_data_v2.shape[0] * fs/data.fs))\n",
    "        all_data_v2 = filter_ecg(all_data_v2, 300)\n",
    "\n",
    "        segments = []\n",
    "        noise_boundaries = np.arange(5 * fs, all_data_v1.shape[-1], 240 * fs)\n",
    "        for bound in noise_boundaries:\n",
    "            segments.append(all_data_v1[bound: bound + 120 * fs])\n",
    "\n",
    "        noise_boundaries_2 = np.arange(5 * fs, all_data_v2.shape[-1], 240 * fs)\n",
    "        for bound in noise_boundaries:\n",
    "            segments.append(all_data_v2[bound: bound + 120 * fs])\n",
    "\n",
    "        noise_level.append(file.split(\"e\")[-1])\n",
    "        segments_lists.append(segments)\n",
    "    except ValueError:\n",
    "        print(\"error, scipping file\")\n",
    "        continue\n",
    "\n",
    "segments_lists = np.array(segments_lists)\n",
    "\n",
    "data = np.concatenate([segments_lists[[0, i]].copy() for i in range(1, 6)], axis=1)\n",
    "\n",
    "noise_level = np.array(noise_level[1:])\n",
    "noise_level = np.repeat(noise_level, len(segments_lists[0]))\n",
    "\n",
    "data = np.transpose(data, axes=(1, 2, 0))\n",
    "\n",
    "print(data.shape)\n",
    "print(noise_level.shape)\n",
    "nst_df = pd.DataFrame({\"data\": [data[i] for i in range(data.shape[0])], \"noise_level\": noise_level})\n",
    "print(nst_df.head())\n",
    "\n",
    "pk_path = \"mit-bih-noise-stress-test-database/database_denoising.pk\"\n",
    "nst_df.to_pickle(pk_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "pk_path = \"mit-bih-noise-stress-test-database/database_denoising.pk\"\n",
    "nst_df = pd.read_pickle(pk_path)\n",
    "# normalise\n",
    "nst_df[\"data\"] = (nst_df[\"data\"] - nst_df[\"data\"].map(lambda x: x.mean(axis=0)))/nst_df[\"data\"].map(lambda x: x.std(axis=0))\n",
    "\n",
    "## Train test split here\n",
    "train_dataset = nst_df.sample(frac=0.8)\n",
    "test_dataset = nst_df[~nst_df.index.isin(train_dataset.index)]\n",
    "\n",
    "train_dataset = split_to_segments(train_dataset, 2048, 36000, 0.5)\n",
    "test_dataset = split_to_segments(test_dataset, 2048, 36000, 0.5)\n",
    "\n",
    "class NSTDataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dataset.index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.dataset.iloc[index]\n",
    "\n",
    "        X = row[\"data\"][:, 1]\n",
    "        X_clean = row[\"data\"][:, 0]\n",
    "\n",
    "        return X, X_clean, row.name\n",
    "\n",
    "torch_dataset_train = NSTDataset(train_dataset)\n",
    "torch_dataset_test = NSTDataset(test_dataset)\n",
    "train_dataloader = DataLoader(torch_dataset_train, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [85], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(clean_signals[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(test_dataset\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;28mint\u001B[39m(ind[\u001B[38;5;241m0\u001B[39m])][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m][:, \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m----> 5\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001B[0m, in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    408\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[1;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_backend_mod()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:3546\u001B[0m, in \u001B[0;36m_Backend.show\u001B[1;34m(cls, block)\u001B[0m\n\u001B[0;32m   3544\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m ipython_pylab \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive()\n\u001B[0;32m   3545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m-> 3546\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:1032\u001B[0m, in \u001B[0;36m_BackendTk.mainloop\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1030\u001B[0m manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1032\u001B[0m     \u001B[43mfirst_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m   1457\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1458\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for (signals, clean_signals, ind) in test_dataloader:\n",
    "    plt.plot(signals[0])\n",
    "    plt.plot(clean_signals[0])\n",
    "    plt.plot(test_dataset.loc[int(ind[0])][\"data\"][:, 0])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test high quality: 4764 low quality: 101 \n",
      "Train high quality: 17915 low quality: 479 \n"
     ]
    }
   ],
   "source": [
    "# For SAFER data\n",
    "# Split train and test data according to each patient\n",
    "def make_SAFER_dataloaders(pt_data, ecg_data, test_frac, only_clean_training=True):\n",
    "    pt_data[\"noLQrecs\"] = pt_data[\"noRecs\"] - pt_data[\"noHQrecs\"]  # for Feas1 this might include stuff flagged by zenicor as noisy?\n",
    "    train_patients = []\n",
    "    test_patients = []\n",
    "\n",
    "    for val, df in pt_data.groupby(\"noLQrecs\"):\n",
    "        # print(f\"processing {val}\")\n",
    "        # print(f\"number of patients {len(df.index)}\")\n",
    "        test = df.sample(frac=test_frac)\n",
    "        test_patients.append(test)\n",
    "        train_patients.append(df[~df[\"ptID\"].isin(test[\"ptID\"])])\n",
    "\n",
    "    train_pt_df = pd.concat(train_patients)\n",
    "    test_pt_df = pd.concat(test_patients)\n",
    "\n",
    "    print(f\"Test high quality: {test_pt_df['noHQrecs'].sum()} low quality: {test_pt_df['noLQrecs'].sum()} \")\n",
    "    print(f\"Train high quality: {train_pt_df['noHQrecs'].sum()} low quality: {train_pt_df['noLQrecs'].sum()} \")\n",
    "\n",
    "    train_dataloader = None\n",
    "    test_dataloader = None\n",
    "\n",
    "    train_dataset = None\n",
    "    test_dataset = None\n",
    "\n",
    "    if not train_pt_df.empty:\n",
    "        # get ECG datasets\n",
    "        train_dataset = split_to_segments(ecg_data[ecg_data[\"ptID\"].isin(train_pt_df[\"ptID\"])], 2048, 9120, 0.5)\n",
    "        # Normalise\n",
    "        train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "\n",
    "        if only_clean_training:\n",
    "            torch_dataset_train = Dataset(train_dataset[train_dataset[\"class_index\"] == 0])\n",
    "        else:\n",
    "            torch_dataset_train = Dataset(train_dataset)\n",
    "\n",
    "        train_dataloader = DataLoader(torch_dataset_train, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "    if not test_pt_df.empty:\n",
    "        test_dataset = split_to_segments(ecg_data[ecg_data[\"ptID\"].isin(test_pt_df[\"ptID\"])], 2048, 9120, 0.5)\n",
    "        test_dataset[\"data\"] = (test_dataset[\"data\"] - test_dataset[\"data\"].map(lambda x: x.mean()))/test_dataset[\"data\"].map(lambda x: x.std())\n",
    "        torch_dataset_test = Dataset(test_dataset)\n",
    "        test_dataloader = DataLoader(torch_dataset_test, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader, train_dataset, test_dataset\n",
    "\n",
    "\n",
    "train_dataloader, test_dataloader, train_dataset, test_dataset = make_SAFER_dataloaders(feas2_pt_data, feas2_ecg_data, test_frac=0.2, only_clean_training=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If we want noisy and clean test_data for evaluation, after training and testing on only clean data in training loop\n",
    "_, noisy_test_dataloader, _, noisy_test_dataset = make_SAFER_dataloaders(feas2_pt_data, feas2_ecg_data[~feas2_ecg_data[\"measID\"].isin(train_dataset[\"measID\"])], test_frac=1, only_clean_training=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup dataloaders for only the clean data\n",
    "train_dataloader, test_dataloader, train_dataset, test_dataset = make_SAFER_dataloaders(all_clean_pt, all_clean_data, test_frac=0.2, only_clean_training=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GMM latent space prior - not sure if this does any good"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.8099)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gmm_components = 10\n",
    "gmm_means = torch.randn((num_gmm_components, 60))\n",
    "gmm_stds = torch.ones((num_gmm_components, 60))\n",
    "gmm_mixture_weights = (torch.ones(num_gmm_components)/num_gmm_components)\n",
    "\n",
    "def kl_gauss(z_m, z_std, t_m, t_std):\n",
    "    z_var = z_std ** 2\n",
    "    t_var = t_std ** 2\n",
    "\n",
    "    term1 = torch.sum(torch.log(t_var)[None, :] - torch.log(z_var), dim=-1)\n",
    "    term2 = torch.sum(z_var/t_var[None, :], dim=-1) - z_m.shape[-1]\n",
    "    term3 = torch.sum(((z_m - t_m[None, :]) ** 2) * 1/t_var[None, :])\n",
    "\n",
    "    return (1/2) * (term1 + term2 + term3)\n",
    "\n",
    "\n",
    "def gmm_kl_latent_loss(z_m, z_std):\n",
    "\n",
    "    batch_size = z_m.shape[0]\n",
    "    kl_divs = torch.zeros((batch_size, num_gmm_components))\n",
    "    for i in range(num_gmm_components):\n",
    "        kl_divs[:, i] = kl_gauss(z_m, z_std, gmm_means[i], gmm_stds[i])\n",
    "\n",
    "    kl_divs = kl_divs * 1/500\n",
    "\n",
    "    return torch.mean(torch.log(1/torch.matmul(torch.exp(-kl_divs), gmm_mixture_weights)))\n",
    "\n",
    "gmm_kl_latent_loss(torch.zeros((32, 60)), torch.ones((32, 60)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cuda\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using Cuda\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "z_dim = 128\n",
    "\n",
    "model = CVAE(z_dim).to(device)\n",
    "\n",
    "# Use weightings to avoid\n",
    "\n",
    "# class_counts = torch.tensor(dataset[\"class_index\"].value_counts().values.astype(np.float32))\n",
    "# class_weights = torch.nn.functional.normalize(1.0/class_counts, dim=0)\n",
    "\n",
    "\n",
    "def kl_latent_loss(z_mean, z_std):\n",
    "    # The regularization loss based on kl divergence of the latent distribution from N(0, 1)\n",
    "    vars = z_std ** 2\n",
    "    means = z_mean\n",
    "\n",
    "    return 1/500 * torch.mean( - torch.log(vars) + vars + means ** 2 - 1)\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "loss_func = lambda x, s, z: kl_latent_loss(z[:, :z_dim], z[:, z_dim:]) +  mse_loss(x, s)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.03, momentum=0.8)\n",
    "num_batches = len(train_dataloader)\n",
    "num_test_batches = len(test_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dist(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "triplet_margin = 0.02\n",
    "\n",
    "def triplet_latent_loss(za, zp, zn):\n",
    "    return max(dist(za, zp) - dist(za, zn) + triplet_margin, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train on feas 1 and 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# warning: changing these chunk sizes may reload feas1 data from scratch, which will take ages\n",
    "chunk_size = 20000\n",
    "num_chunks = math.ceil(162515 / chunk_size )\n",
    "\n",
    "def get_feas1_dataloader(chunk_num):\n",
    "    feas1_pt_data, feas1_ecg_data = SAFERDataset.load_feas_dataset(1, f\"dataframe_{chunk_num}.pk\", ecg_range=[chunk_size * chunk_num, chunk_size * (chunk_num + 1)])\n",
    "    train_dataset = split_to_segments(feas1_ecg_data, 2048, 9120, 0.5)\n",
    "    train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "\n",
    "    torch_dataset_train = Dataset(train_dataset)\n",
    "    train_dataloader = DataLoader(torch_dataset_train, batch_size=128, shuffle=True, pin_memory=True)\n",
    "\n",
    "    return train_dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0 ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [46], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Train\u001B[39;00m\n\u001B[0;32m     13\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m---> 15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ds_ind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[43mnum_chunks\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining on dataset: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mds_ind\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ds_ind \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'num_chunks' is not defined"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "import copy\n",
    "\n",
    "best_test_loss = 100\n",
    "best_model = copy.deepcopy(model).cpu()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    print(f\"starting epoch {epoch} ...\")\n",
    "    # Train\n",
    "    model.train()\n",
    "\n",
    "    for ds_ind in range(num_chunks + 1):\n",
    "        print(f\"training on dataset: {ds_ind}\")\n",
    "        if ds_ind == 0:\n",
    "            train_dataloader_part = train_dataloader\n",
    "        else:\n",
    "            train_dataloader_part = get_feas1_dataloader(ds_ind-1)\n",
    "\n",
    "        for i, (signals, _, _) in enumerate(train_dataloader_part):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output, latents = model(signals)\n",
    "            loss = loss_func(output, signals, latents)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += float(loss)\n",
    "\n",
    "        print(f\"Total loss {total_loss/num_batches}\")\n",
    "\n",
    "    print(f\"Epoch {epoch} finished with average loss {total_loss/num_batches}\")\n",
    "    print(\"Testing ...\")\n",
    "    # Test\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (signals, _, _)in enumerate(test_dataloader):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "\n",
    "            output, latents = model (signals)\n",
    "            loss = loss_func(output, signals, latents)\n",
    "            test_loss += float(loss)\n",
    "\n",
    "    print(f\"Average test loss: {test_loss/num_test_batches}\")\n",
    "\n",
    "    if test_loss/num_test_batches < best_test_loss:\n",
    "        best_model = copy.deepcopy(model).cpu()\n",
    "        best_test_loss = test_loss/num_test_batches\n",
    "\n",
    "model = best_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train only using feas2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0 ...\n",
      "Epoch 0 finished with average loss 3.962674920601169\n",
      "Testing ...\n",
      "Average test loss: 3.9451854661194203\n",
      "starting epoch 1 ...\n",
      "Epoch 1 finished with average loss 3.887753474548107\n",
      "Testing ...\n",
      "Average test loss: 3.881276798991897\n",
      "starting epoch 2 ...\n",
      "Epoch 2 finished with average loss 3.9108802906171545\n",
      "Testing ...\n",
      "Average test loss: 4.19552626572622\n",
      "starting epoch 3 ...\n",
      "Epoch 3 finished with average loss 3.912668073505867\n",
      "Testing ...\n",
      "Average test loss: 3.846326551009805\n",
      "starting epoch 4 ...\n",
      "Epoch 4 finished with average loss 3.940700568669424\n",
      "Testing ...\n",
      "Average test loss: inf\n",
      "starting epoch 5 ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [59], line 27\u001B[0m\n\u001B[0;32m     24\u001B[0m     nn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), max_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2.0\u001B[39m, norm_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     26\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 27\u001B[0m     total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m finished with average loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_loss\u001B[38;5;241m/\u001B[39mnum_batches\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTesting ...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "import copy\n",
    "\n",
    "best_test_loss = 100\n",
    "best_model = copy.deepcopy(model).cpu()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    print(f\"starting epoch {epoch} ...\")\n",
    "    # Train\n",
    "    model.train()\n",
    "    for i, (signals, _, _) in enumerate(train_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, latents = model(signals)\n",
    "        loss = loss_func(output, signals, latents.to(\"cpu\"))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "\n",
    "    print(f\"Epoch {epoch} finished with average loss {total_loss/num_batches}\")\n",
    "    print(\"Testing ...\")\n",
    "    # Test\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (signals, _, _)in enumerate(test_dataloader):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "\n",
    "            output, latents = model (signals)\n",
    "            loss = loss_func(output, signals, latents.to(\"cpu\"))\n",
    "            test_loss += float(loss)\n",
    "\n",
    "    print(f\"Average test loss: {test_loss/num_test_batches}\")\n",
    "\n",
    "    if test_loss/num_test_batches < best_test_loss:\n",
    "        best_model = copy.deepcopy(model).cpu()\n",
    "        best_test_loss = test_loss/num_test_batches\n",
    "\n",
    "model = best_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train using the NST dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0 ...\n",
      "Epoch 0 finished with average loss 0.400227868819938\n",
      "Testing ...\n",
      "Average test loss: 0.37143253578859214\n",
      "starting epoch 1 ...\n",
      "Epoch 1 finished with average loss 0.40309759667691064\n",
      "Testing ...\n",
      "Average test loss: 0.373511717599981\n",
      "starting epoch 2 ...\n",
      "Epoch 2 finished with average loss 0.4044528840219273\n",
      "Testing ...\n",
      "Average test loss: 0.3732363511534298\n",
      "starting epoch 3 ...\n",
      "Epoch 3 finished with average loss 0.4039087159668698\n",
      "Testing ...\n",
      "Average test loss: 0.3708088310325847\n",
      "starting epoch 4 ...\n",
      "Epoch 4 finished with average loss 0.40508778261787753\n",
      "Testing ...\n",
      "Average test loss: 0.37695128426832314\n",
      "starting epoch 5 ...\n",
      "Epoch 5 finished with average loss 0.40080102489275093\n",
      "Testing ...\n",
      "Average test loss: 0.38048596767818227\n",
      "starting epoch 6 ...\n",
      "Epoch 6 finished with average loss 0.40437007563955646\n",
      "Testing ...\n",
      "Average test loss: 0.37527622019543366\n",
      "starting epoch 7 ...\n",
      "Epoch 7 finished with average loss 0.40649035835967345\n",
      "Testing ...\n",
      "Average test loss: 0.37587883191950183\n",
      "starting epoch 8 ...\n",
      "Epoch 8 finished with average loss 0.3997736972044496\n",
      "Testing ...\n",
      "Average test loss: 0.3760336392066058\n",
      "starting epoch 9 ...\n",
      "Epoch 9 finished with average loss 0.40399297852726546\n",
      "Testing ...\n",
      "Average test loss: 0.3765006819192101\n",
      "starting epoch 10 ...\n",
      "Epoch 10 finished with average loss 0.40172330553040786\n",
      "Testing ...\n",
      "Average test loss: 0.3761910813696244\n",
      "starting epoch 11 ...\n",
      "Epoch 11 finished with average loss 0.405391568208442\n",
      "Testing ...\n",
      "Average test loss: 0.37459660628262686\n",
      "starting epoch 12 ...\n",
      "Epoch 12 finished with average loss 0.399419804706293\n",
      "Testing ...\n",
      "Average test loss: 0.3698061722166398\n",
      "starting epoch 13 ...\n",
      "Epoch 13 finished with average loss 0.3997577463879305\n",
      "Testing ...\n",
      "Average test loss: 0.37847397081992207\n",
      "starting epoch 14 ...\n",
      "Epoch 14 finished with average loss 0.40443339505616355\n",
      "Testing ...\n",
      "Average test loss: 0.37334489997695475\n",
      "starting epoch 15 ...\n",
      "Epoch 15 finished with average loss 0.40264145065756407\n",
      "Testing ...\n",
      "Average test loss: 0.3758282924399656\n",
      "starting epoch 16 ...\n",
      "Epoch 16 finished with average loss 0.40285230910076814\n",
      "Testing ...\n",
      "Average test loss: 0.376090407371521\n",
      "starting epoch 17 ...\n",
      "Epoch 17 finished with average loss 0.40313855953076305\n",
      "Testing ...\n",
      "Average test loss: 0.37387256937868457\n",
      "starting epoch 18 ...\n",
      "Epoch 18 finished with average loss 0.4065669827601489\n",
      "Testing ...\n",
      "Average test loss: 0.3801198759499718\n",
      "starting epoch 19 ...\n",
      "Epoch 19 finished with average loss 0.4048439588616876\n",
      "Testing ...\n",
      "Average test loss: 0.37560179654289694\n",
      "starting epoch 20 ...\n",
      "Epoch 20 finished with average loss 0.39912191077190284\n",
      "Testing ...\n",
      "Average test loss: 0.3721800674410427\n",
      "starting epoch 21 ...\n",
      "Epoch 21 finished with average loss 0.40380948036909103\n",
      "Testing ...\n",
      "Average test loss: 0.37709520844852223\n",
      "starting epoch 22 ...\n",
      "Epoch 22 finished with average loss 0.4046939979581272\n",
      "Testing ...\n",
      "Average test loss: 0.37085288237122926\n",
      "starting epoch 23 ...\n",
      "Epoch 23 finished with average loss 0.40225333632791743\n",
      "Testing ...\n",
      "Average test loss: 0.375233811490676\n",
      "starting epoch 24 ...\n",
      "Epoch 24 finished with average loss 0.4037479661843356\n",
      "Testing ...\n",
      "Average test loss: 0.371685431284063\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "import copy\n",
    "\n",
    "best_test_loss = 100\n",
    "best_model = copy.deepcopy(model).cpu()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    print(f\"starting epoch {epoch} ...\")\n",
    "    # Train\n",
    "    model.train()\n",
    "    for i, (signals, clean_signals, _) in enumerate(train_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        clean_signals = torch.unsqueeze(clean_signals.to(device), 1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, latents = model(signals)\n",
    "        loss = loss_func(output, clean_signals, latents.to(\"cpu\"))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "\n",
    "    print(f\"Epoch {epoch} finished with average loss {total_loss/num_batches}\")\n",
    "    print(\"Testing ...\")\n",
    "    # Test\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (signals, clean_signals, _)in enumerate(test_dataloader):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "            clean_signals = torch.unsqueeze(clean_signals.to(device), 1).float()\n",
    "\n",
    "            output, latents = model (signals)\n",
    "            loss = loss_func(output, clean_signals, latents.to(\"cpu\"))\n",
    "            test_loss += float(loss)\n",
    "\n",
    "    print(f\"Average test loss: {test_loss/num_test_batches}\")\n",
    "\n",
    "    if test_loss/num_test_batches < best_test_loss:\n",
    "        best_model = copy.deepcopy(model).cpu()\n",
    "        best_test_loss = test_loss/num_test_batches\n",
    "\n",
    "model = best_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model = model.to(device)  # if train finished use this to put back on the GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "model = best_model.to(device)  # if train did not finish use this to take the best intermediate result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Save a model\n",
    "torch.save(model.state_dict(), \"TrainedModels/Autoencoder_50_epochs_nst.pt\")\n",
    "train_dataset.to_pickle(\"TrainedModels/Autoencoder_50_epochs_nst_train_set.pk\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_dim = 128\n",
    "model = CVAE(z_dim).to(device)\n",
    "model.load_state_dict(torch.load(\"TrainedModels/Autoencoder_new_6_epochs_all_feas1_feas2.pt\", map_location=device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Reload the training and dataset with the model so we don't test on stuff we trained on\n",
    "train_dataset = pd.read_pickle(\"TrainedModels/Autoencoder_new_6_epochs_all_feas1_feas2_train_set.pk\")\n",
    "\n",
    "train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "torch_dataset_train = Dataset(train_dataset)\n",
    "train_dataloader = DataLoader(torch_dataset_train, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_pt_df = feas2_pt_data[~feas2_pt_data[\"ptID\"].isin(train_dataset[\"ptID\"])]\n",
    "\n",
    "if not test_pt_df.empty:\n",
    "    test_dataset = test_dataset[test_dataset[\"measDiag\"] != DiagEnum.Undecided]\n",
    "    test_dataset = split_to_segments(feas2_ecg_data[feas2_ecg_data[\"ptID\"].isin(test_pt_df[\"ptID\"])], 2048, 9120, 0.5)\n",
    "    test_dataset[\"data\"] = (test_dataset[\"data\"] - test_dataset[\"data\"].map(lambda x: x.mean()))/test_dataset[\"data\"].map(lambda x: x.std())\n",
    "    torch_dataset_test = Dataset(test_dataset)\n",
    "    test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reconstruction for clean samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# Plot test data reconstruction\n",
    "test_dataset[\"reconstruction\"] = None\n",
    "mse_only_loss = lambda truth, pred: torch.mean((truth - pred) ** 2, dim=(1,2))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    r_err = []\n",
    "    inds = []\n",
    "    reconstructions = []\n",
    "\n",
    "    for i, (signals, _, ind) in enumerate(test_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # signals_clean = torch.unsqueeze(signals_clean.to(device), 1).float()\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        output, latents  = model(-signals)\n",
    "        loss = mse_only_loss(output, signals).detach().cpu().numpy()\n",
    "\n",
    "        output = output.detach().cpu().numpy()\n",
    "\n",
    "        for i, o, l in zip(ind, output[:, 0, :], loss):\n",
    "            r_err.append(l)\n",
    "            reconstructions.append(o)\n",
    "            inds.append(int(i))\n",
    "\n",
    "\n",
    "test_dataset[\"r_err\"] = pd.Series(data=r_err, index=inds)\n",
    "test_dataset[\"reconstruction\"] = pd.Series(data=reconstructions, index=inds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "test_df = test_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "   index  ptID   age         ptDiag     ptDiagRev1          ptDiagRev2  \\\n0    590     8  72.5  DiagEnum.NoAF  DiagEnum.NoAF  DiagEnum.Undecided   \n1    590     8  72.5  DiagEnum.NoAF  DiagEnum.NoAF  DiagEnum.Undecided   \n2    590     8  72.5  DiagEnum.NoAF  DiagEnum.NoAF  DiagEnum.Undecided   \n3    590     8  72.5  DiagEnum.NoAF  DiagEnum.NoAF  DiagEnum.Undecided   \n4    590     8  72.5  DiagEnum.NoAF  DiagEnum.NoAF  DiagEnum.Undecided   \n\n           ptDiagRev3  cardRev            measDiag        measDiagRev1  ...  \\\n0  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided  ...   \n1  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided  ...   \n2  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided  ...   \n3  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided  ...   \n4  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided  ...   \n\n  perhapsAF  measID                                               data  \\\n0         0     591  [-0.49644204545732973, -0.6246603189506869, -0...   \n1         0     591  [0.6110765438273132, 0.6934087028050593, 0.796...   \n2         0     591  [4.487455908826463, 5.457356318373902, 6.04539...   \n3         0     591  [-0.19036774215761504, -0.13728679542462185, -...   \n4         0     591  [-0.2725175881175217, -0.3385749643142289, -0....   \n\n                    file_path  class_index  length  rec_ind  rec_pos  \\\n0  ECGs/000000/saferF2_000591            0    9120      590        0   \n1  ECGs/000000/saferF2_000591            0    9120      590        1   \n2  ECGs/000000/saferF2_000591            0    9120      590        2   \n3  ECGs/000000/saferF2_000591            0    9120      590        3   \n4  ECGs/000000/saferF2_000591            0    9120      590        4   \n\n                                      reconstruction     r_err  \n0  [0.27881688, 0.18085302, 0.30135077, 0.2448078...  1.414751  \n1  [0.2756654, 0.16722995, 0.3430887, 0.32528114,...  1.502876  \n2  [0.28695422, 0.1368554, 0.22762185, 0.20471534...  1.426323  \n3  [0.34878796, 0.11950919, 0.31936407, 0.1697063...  1.354892  \n4  [0.373186, 0.29026645, 0.4235611, 0.34632695, ...  1.427138  \n\n[5 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>ptID</th>\n      <th>age</th>\n      <th>ptDiag</th>\n      <th>ptDiagRev1</th>\n      <th>ptDiagRev2</th>\n      <th>ptDiagRev3</th>\n      <th>cardRev</th>\n      <th>measDiag</th>\n      <th>measDiagRev1</th>\n      <th>...</th>\n      <th>perhapsAF</th>\n      <th>measID</th>\n      <th>data</th>\n      <th>file_path</th>\n      <th>class_index</th>\n      <th>length</th>\n      <th>rec_ind</th>\n      <th>rec_pos</th>\n      <th>reconstruction</th>\n      <th>r_err</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>590</td>\n      <td>8</td>\n      <td>72.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>591</td>\n      <td>[-0.49644204545732973, -0.6246603189506869, -0...</td>\n      <td>ECGs/000000/saferF2_000591</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>590</td>\n      <td>0</td>\n      <td>[0.27881688, 0.18085302, 0.30135077, 0.2448078...</td>\n      <td>1.414751</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>590</td>\n      <td>8</td>\n      <td>72.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>591</td>\n      <td>[0.6110765438273132, 0.6934087028050593, 0.796...</td>\n      <td>ECGs/000000/saferF2_000591</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>590</td>\n      <td>1</td>\n      <td>[0.2756654, 0.16722995, 0.3430887, 0.32528114,...</td>\n      <td>1.502876</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>590</td>\n      <td>8</td>\n      <td>72.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>591</td>\n      <td>[4.487455908826463, 5.457356318373902, 6.04539...</td>\n      <td>ECGs/000000/saferF2_000591</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>590</td>\n      <td>2</td>\n      <td>[0.28695422, 0.1368554, 0.22762185, 0.20471534...</td>\n      <td>1.426323</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>590</td>\n      <td>8</td>\n      <td>72.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>591</td>\n      <td>[-0.19036774215761504, -0.13728679542462185, -...</td>\n      <td>ECGs/000000/saferF2_000591</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>590</td>\n      <td>3</td>\n      <td>[0.34878796, 0.11950919, 0.31936407, 0.1697063...</td>\n      <td>1.354892</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>590</td>\n      <td>8</td>\n      <td>72.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>591</td>\n      <td>[-0.2725175881175217, -0.3385749643142289, -0....</td>\n      <td>ECGs/000000/saferF2_000591</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>590</td>\n      <td>4</td>\n      <td>[0.373186, 0.29026645, 0.4235611, 0.34632695, ...</td>\n      <td>1.427138</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 43 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "nan"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"reconstruction\"].iloc[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.565233\n",
      "Name: 637, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.475245\n",
      "Name: 638, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.915962\n",
      "Name: 639, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.953902\n",
      "Name: 640, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.354805\n",
      "Name: 641, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                          1.55388\n",
      "Name: 642, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.441283\n",
      "Name: 643, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.345248\n",
      "Name: 1750, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.557865\n",
      "Name: 1751, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.727465\n",
      "Name: 1752, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                         1.311485\n",
      "Name: 1753, dtype: object\n",
      "ptDiag                   DiagEnum.NoAF\n",
      "measDiag                 DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                0\n",
      "poss_AF_tag                          1\n",
      "r_err                          1.25387\n",
      "Name: 1754, dtype: object\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [65], line 41\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, ecg \u001B[38;5;129;01min\u001B[39;00m test_df[test_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeasDiag\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m DiagEnum\u001B[38;5;241m.\u001B[39mNoAF]\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;66;03m# print(ecg)\u001B[39;00m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28mprint\u001B[39m(ecg[[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mptDiag\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeasDiag\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtag_orig_Poor_Quality\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mposs_AF_tag\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr_err\u001B[39m\u001B[38;5;124m\"\u001B[39m]])\n\u001B[1;32m---> 41\u001B[0m     \u001B[43mplot_ecg_and_reconstruction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mecg\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mecg\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreconstruction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [65], line 36\u001B[0m, in \u001B[0;36mplot_ecg_and_reconstruction\u001B[1;34m(x, r, fs, n_split)\u001B[0m\n\u001B[0;32m     33\u001B[0m     ax[j][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mgrid(which\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmajor\u001B[39m\u001B[38;5;124m'\u001B[39m, linestyle\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m, linewidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0.5\u001B[39m\u001B[38;5;124m'\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblack\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     34\u001B[0m     ax[j][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mgrid(which\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminor\u001B[39m\u001B[38;5;124m'\u001B[39m, linestyle\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m, linewidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0.5\u001B[39m\u001B[38;5;124m'\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlightgray\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 36\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001B[0m, in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    408\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[1;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_backend_mod()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:3546\u001B[0m, in \u001B[0;36m_Backend.show\u001B[1;34m(cls, block)\u001B[0m\n\u001B[0;32m   3544\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m ipython_pylab \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive()\n\u001B[0;32m   3545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m-> 3546\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:1032\u001B[0m, in \u001B[0;36m_BackendTk.mainloop\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1030\u001B[0m manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1032\u001B[0m     \u001B[43mfirst_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m   1457\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1458\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "def plot_ecg_and_reconstruction(x, r, fs=300, n_split=3):\n",
    "    sample_len = x.shape[0]\n",
    "    time_axis = np.arange(sample_len)/fs\n",
    "\n",
    "    cuts = np.round(np.linspace(0, sample_len-1, n_split+1)).astype(int)\n",
    "\n",
    "    fig, ax = plt.subplots(n_split, 1, figsize=(16, 10), squeeze=False)\n",
    "    for j in range(n_split):\n",
    "        ax[j][0].plot(time_axis[cuts[j]:cuts[j+1]], x[cuts[j]:cuts[j+1]])\n",
    "        ax[j][0].plot(time_axis[cuts[j]:cuts[j+1]], r[cuts[j]:cuts[j+1]])\n",
    "        ax[j][0].set_xlabel(\"Time\")\n",
    "        ax[j][0].set_xlim((time_axis[cuts[j]], time_axis[cuts[j+1]]))\n",
    "\n",
    "        t_s = time_axis[cuts[j]]\n",
    "        t_f = time_axis[cuts[j+1]]\n",
    "        time_ticks = np.arange(t_s - t_s%0.2, t_f + (0.2 - t_f%0.2), 0.2)\n",
    "        decimal_labels = ~np.isclose(time_ticks, np.round(time_ticks))\n",
    "        time_labels = np.round(time_ticks).astype(int).astype(str)\n",
    "        time_labels[decimal_labels] = \"\"\n",
    "\n",
    "        ax[j][0].set_xticks(time_ticks, time_labels)\n",
    "\n",
    "        ax[j][0].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        ax[j][0].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "        ax[j][0].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "        ax[j][0].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "        ax[j][0].grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "        ax[j][0].grid(which='minor', linestyle='-', linewidth='0.5', color='lightgray')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for _, ecg in test_df[test_df[\"measDiag\"] == DiagEnum.NoAF].iterrows():\n",
    "    # print(ecg)\n",
    "    print(ecg[[\"ptDiag\", \"measDiag\", \"tag_orig_Poor_Quality\", \"poss_AF_tag\", \"r_err\"]])\n",
    "    plot_ecg_and_reconstruction(ecg[\"data\"], -ecg[\"reconstruction\"], n_split=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "def plot_ecg_and_reconstruction_for_classes(xs, rs, titles, fs=300):\n",
    "    fig, ax = plt.subplots(len(xs), 1, figsize=(6, 7))\n",
    "\n",
    "    for j, (x, r, t) in enumerate(zip(xs, rs, titles)):\n",
    "        sample_len = x.shape[0]\n",
    "        time_axis = np.arange(sample_len)/fs\n",
    "\n",
    "        ax[j].plot(time_axis, x)\n",
    "        ax[j].plot(time_axis, r)\n",
    "        ax[j].set_xlabel(\"Time\")\n",
    "        ax[j].set_xlim((time_axis[0], time_axis[-1]))\n",
    "\n",
    "        ax[j].set_xticks(np.arange(time_axis[0], time_axis[-1]+0.2,0.2))\n",
    "        ax[j].set_title(t)\n",
    "\n",
    "        ax[j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        ax[j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "        ax[j].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "        ax[j].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "        ax[j].grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "        ax[j].grid(which='minor', linestyle='-', linewidth='0.5', color='lightgray')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(\"TMRFigures/cvae_reconst_examples_large_dataset.png\")\n",
    "\n",
    "ecg_ind_list = [3195, 2916, 1563, 1561]  # 2192 # 441 # 315\n",
    "\n",
    "xs = test_df.loc[ecg_ind_list][\"data\"].tolist()\n",
    "rs = test_df.loc[ecg_ind_list][\"reconstruction\"].tolist()\n",
    "titles = test_df.loc[ecg_ind_list].apply(lambda x: f\"{x['measDiag'].name} e = {x['r_err']:.3f}\", axis=1)   # [\"measDiag\"].map(lambda x: x.name).tolist()\n",
    "print(len(titles))\n",
    "\n",
    "plot_ecg_and_reconstruction_for_classes(xs, rs, titles)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Latent space exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 120)\n"
     ]
    }
   ],
   "source": [
    "# Try some latent space exploration\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, (signals, _, _) in enumerate(test_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        latent_position = model.encode(signals)\n",
    "        latent_position = latent_position.detach().cpu().numpy()\n",
    "        signals_np = signals.detach().cpu().numpy()\n",
    "\n",
    "        print(latent_position.shape)\n",
    "\n",
    "        break\n",
    "\n",
    "index = 3\n",
    "latent_positions = np.zeros((10, *latent_position.shape), dtype=np.float32)\n",
    "for i in range(10):\n",
    "    latent_positions[i, :, :] += latent_position\n",
    "    latent_positions[i, :, index] = i * 4 - 2\n",
    "\n",
    "signals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for l in latent_positions:\n",
    "        latent = torch.from_numpy(l[:, :60]).to(device)\n",
    "        signal = model.decode(latent)\n",
    "        signals.append(signal.detach().cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interpolate between a noisy and clean ECG!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting\n"
     ]
    }
   ],
   "source": [
    "# noisy 441 # clean 315\n",
    "\n",
    "noisy_latent = test_dataset.loc[441][\"latent_encoding\"][:60]\n",
    "clean_latent = test_dataset.loc[315][\"latent_encoding\"][:60]\n",
    "\n",
    "latent_sequence = np.linspace(noisy_latent, clean_latent, 32)\n",
    "latent_sequence = torch.from_numpy(latent_sequence).to(device)\n",
    "\n",
    "ecgs = model.decode(latent_sequence).detach().cpu().numpy()\n",
    "print(\"plotting\")\n",
    "\n",
    "for ecg in np.flip(ecgs[:, 0, :], axis=0):\n",
    "    plt.plot(ecg)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find the reconstruction error for noisy and clean samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "            r_err            measDiag\nrec_ind                              \n590      1.461073  DiagEnum.Undecided\n591      1.734338  DiagEnum.Undecided\n592      1.272624  DiagEnum.Undecided\n593      1.588059  DiagEnum.Undecided\n594      1.382735  DiagEnum.Undecided\n...           ...                 ...\n23182    1.404204  DiagEnum.Undecided\n23183    1.498458  DiagEnum.Undecided\n23184    1.509076  DiagEnum.Undecided\n23185    1.468974  DiagEnum.Undecided\n23186    1.429129  DiagEnum.Undecided\n\n[4843 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>r_err</th>\n      <th>measDiag</th>\n    </tr>\n    <tr>\n      <th>rec_ind</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>590</th>\n      <td>1.461073</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>1.734338</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>1.272624</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>1.588059</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>1.382735</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23182</th>\n      <td>1.404204</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>23183</th>\n      <td>1.498458</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>23184</th>\n      <td>1.509076</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>23185</th>\n      <td>1.468974</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>23186</th>\n      <td>1.429129</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n  </tbody>\n</table>\n<p>4843 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For NST data\n",
    "# test_whole_ecgs_rec_err = test_dataset.groupby(\"rec_ind\").agg({\"r_err\": \"mean\", \"noise_level\": lambda x: x.iloc[0]})\n",
    "# For safer data\n",
    "test_whole_ecgs_rec_err = test_dataset.groupby(\"rec_ind\").agg({\"r_err\": \"mean\" ,\"measDiag\": lambda x: x.iloc[0]})\n",
    "test_whole_ecgs_rec_err"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# A little bit of faff to plot the results from small and large datasets on one axis, for the TMR, not sure it made it into the report in the end\n",
    "test_whole_ecgs_rec_err.to_pickle(\"TrainedModels/Autoecoder_small_dataset.pk\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'measDiag'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3799\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'measDiag'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [41], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m test_not_undecided \u001B[38;5;241m=\u001B[39m test_whole_ecgs_rec_err\n\u001B[0;32m      3\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m4\u001B[39m), dpi\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(\u001B[43mtest_not_undecided\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmeasDiag\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mvalue), test_not_undecided[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr_err\u001B[39m\u001B[38;5;124m\"\u001B[39m], marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m+\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mxticks([e\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m pd\u001B[38;5;241m.\u001B[39munique(test_not_undecided[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeasDiag\u001B[39m\u001B[38;5;124m\"\u001B[39m])], [e\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m pd\u001B[38;5;241m.\u001B[39munique(test_not_undecided[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeasDiag\u001B[39m\u001B[38;5;124m\"\u001B[39m])])\n\u001B[0;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReconstruction error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3805\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3807\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3802\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3805\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'measDiag'"
     ]
    }
   ],
   "source": [
    "test_not_undecided = test_whole_ecgs_rec_err\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=300)\n",
    "plt.scatter(test_not_undecided[\"measDiag\"].map(lambda x: x.value), test_not_undecided[\"r_err\"], marker='+')\n",
    "plt.xticks([e.value for e in pd.unique(test_not_undecided[\"measDiag\"])], [e.name for e in pd.unique(test_not_undecided[\"measDiag\"])])\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Measurement diagnosis\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"TMRFigures/cvae_reconst_err_large_dataset.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "DiagEnum.Undecided      4569\nDiagEnum.NoAF            172\nDiagEnum.PoorQuality      99\nDiagEnum.AF                3\nName: measDiag, dtype: int64"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_whole_ecgs_rec_err[\"measDiag\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# Safer data\n",
    "\n",
    "test_not_undecided = test_whole_ecgs_rec_err\n",
    "# test_not_undecided_2 = pd.read_pickle(\"TrainedModels/Autoecoder_large_dataset.pk\")\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=300)\n",
    "\n",
    "enum_order = [DiagEnum.NoAF, DiagEnum.AF, DiagEnum.PoorQuality]\n",
    "data = [test_not_undecided[test_not_undecided[\"measDiag\"] == e][\"r_err\"] for e in enum_order]\n",
    "\n",
    "# print(test_not_undecided_2[\"measDiag\"].value_counts())\n",
    "# data_2 = [test_not_undecided_2[test_not_undecided_2[\"measDiag\"] == e][\"r_err\"] for e in enum_order]\n",
    "\n",
    "plt.violinplot(data)    # quantiles=[[0.25, 0.75]]*4, showmedians=True)\n",
    "# plt.violinplot(data_2)\n",
    "plt.xticks([1, 2, 3], [e.name for e in enum_order])\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Measurement diagnosis\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"TMRFigures/cvae_reconst_err_small_dataset.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '06' '12' '18' '_6']\n"
     ]
    }
   ],
   "source": [
    "# NST data\n",
    "\n",
    "test_not_undecided = test_whole_ecgs_rec_err\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=300)\n",
    "\n",
    "noise_levels = np.sort(pd.unique(test_not_undecided[\"noise_level\"]))\n",
    "print(noise_levels)\n",
    "data = [test_not_undecided[test_not_undecided[\"noise_level\"] == e][\"r_err\"] for e in noise_levels]\n",
    "\n",
    "\n",
    "plt.violinplot(data)    # quantiles=[[0.25, 0.75]]*4, showmedians=True)\n",
    "plt.xticks([1, 2, 3, 4, 5])\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Measurement diagnosis\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"TMRFigures/cvae_reconst_err_small_dataset.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sample cross validation code for SAFER (not yet applied to anything)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification from the latent space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    inds = []\n",
    "\n",
    "    for i, (signals, _, ind) in enumerate(train_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        latent_position = model.encode(signals)\n",
    "        latent_position = latent_position.detach().cpu().numpy()\n",
    "        signals_np = signals.detach().cpu().numpy()\n",
    "\n",
    "        for i, l in zip(ind, latent_position):\n",
    "            latents.append(l)\n",
    "            inds.append(i)\n",
    "\n",
    "train_dataset[\"latent_encoding\"] = pd.Series(data=latents, index=inds)\n",
    "svc_train_df = train_dataset.dropna(subset=[\"latent_encoding\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "        index  ptID   age         ptDiag          ptDiagRev1     ptDiagRev2  \\\n0           0     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n1           0     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n2           0     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n3           0     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n4           0     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n...       ...   ...   ...            ...                 ...            ...   \n128907  23258   288  70.5  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n128908  23258   288  70.5  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n128909  23258   288  70.5  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n128910  23258   288  70.5  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n128911  23258   288  70.5  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n\n                ptDiagRev3  cardRev            measDiag        measDiagRev1  \\\n0       DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n1       DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n2       DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n3       DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n4       DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n...                    ...      ...                 ...                 ...   \n128907  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n128908  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n128909  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n128910  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n128911  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n\n        ... unlikelyAF  perhapsAF measID  \\\n0       ...          0          0      1   \n1       ...          0          0      1   \n2       ...          0          0      1   \n3       ...          0          0      1   \n4       ...          0          0      1   \n...     ...        ...        ...    ...   \n128907  ...          0          0  23259   \n128908  ...          0          0  23259   \n128909  ...          0          0  23259   \n128910  ...          0          0  23259   \n128911  ...          0          0  23259   \n\n                                                     data  \\\n0       [-0.25368181611599944, -0.45841503541331713, -...   \n1       [0.2026567814899965, 0.184902954707474, 0.1763...   \n2       [0.0664598504863543, 0.0779387026676995, 0.087...   \n3       [1.3574057452010926, 1.0019610647315154, 0.645...   \n4       [-0.025626811413227674, -0.038046522783888745,...   \n...                                                   ...   \n128907  [-0.801575410206255, -0.7448302284482392, -0.6...   \n128908  [-0.9279949051780753, -0.9494823052111254, -0....   \n128909  [0.4556109704687446, 0.3097769511612076, 0.185...   \n128910  [0.21881221826302832, 0.4723944748082791, 0.78...   \n128911  [-0.09619865014660389, -0.12374135799916317, -...   \n\n                         file_path  class_index  length  rec_ind  rec_pos  \\\n0       ECGs/000000/saferF2_000001            0    9120        0        0   \n1       ECGs/000000/saferF2_000001            0    9120        0        1   \n2       ECGs/000000/saferF2_000001            0    9120        0        2   \n3       ECGs/000000/saferF2_000001            0    9120        0        3   \n4       ECGs/000000/saferF2_000001            0    9120        0        4   \n...                            ...          ...     ...      ...      ...   \n128907  ECGs/023000/saferF2_023259            0    9120    23258        2   \n128908  ECGs/023000/saferF2_023259            0    9120    23258        3   \n128909  ECGs/023000/saferF2_023259            0    9120    23258        4   \n128910  ECGs/023000/saferF2_023259            0    9120    23258        5   \n128911  ECGs/023000/saferF2_023259            0    9120    23258        6   \n\n        latent_encoding  \n0                   NaN  \n1                   NaN  \n2                   NaN  \n3                   NaN  \n4                   NaN  \n...                 ...  \n128907              NaN  \n128908              NaN  \n128909              NaN  \n128910              NaN  \n128911              NaN  \n\n[128912 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>ptID</th>\n      <th>age</th>\n      <th>ptDiag</th>\n      <th>ptDiagRev1</th>\n      <th>ptDiagRev2</th>\n      <th>ptDiagRev3</th>\n      <th>cardRev</th>\n      <th>measDiag</th>\n      <th>measDiagRev1</th>\n      <th>...</th>\n      <th>unlikelyAF</th>\n      <th>perhapsAF</th>\n      <th>measID</th>\n      <th>data</th>\n      <th>file_path</th>\n      <th>class_index</th>\n      <th>length</th>\n      <th>rec_ind</th>\n      <th>rec_pos</th>\n      <th>latent_encoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[-0.25368181611599944, -0.45841503541331713, -...</td>\n      <td>ECGs/000000/saferF2_000001</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[0.2026567814899965, 0.184902954707474, 0.1763...</td>\n      <td>ECGs/000000/saferF2_000001</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[0.0664598504863543, 0.0779387026676995, 0.087...</td>\n      <td>ECGs/000000/saferF2_000001</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>0</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[1.3574057452010926, 1.0019610647315154, 0.645...</td>\n      <td>ECGs/000000/saferF2_000001</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>0</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[-0.025626811413227674, -0.038046522783888745,...</td>\n      <td>ECGs/000000/saferF2_000001</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>0</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>128907</th>\n      <td>23258</td>\n      <td>288</td>\n      <td>70.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23259</td>\n      <td>[-0.801575410206255, -0.7448302284482392, -0.6...</td>\n      <td>ECGs/023000/saferF2_023259</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>23258</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>128908</th>\n      <td>23258</td>\n      <td>288</td>\n      <td>70.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23259</td>\n      <td>[-0.9279949051780753, -0.9494823052111254, -0....</td>\n      <td>ECGs/023000/saferF2_023259</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>23258</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>128909</th>\n      <td>23258</td>\n      <td>288</td>\n      <td>70.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23259</td>\n      <td>[0.4556109704687446, 0.3097769511612076, 0.185...</td>\n      <td>ECGs/023000/saferF2_023259</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>23258</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>128910</th>\n      <td>23258</td>\n      <td>288</td>\n      <td>70.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23259</td>\n      <td>[0.21881221826302832, 0.4723944748082791, 0.78...</td>\n      <td>ECGs/023000/saferF2_023259</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>23258</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>128911</th>\n      <td>23258</td>\n      <td>288</td>\n      <td>70.5</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23259</td>\n      <td>[-0.09619865014660389, -0.12374135799916317, -...</td>\n      <td>ECGs/023000/saferF2_023259</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>23258</td>\n      <td>6</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>128912 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_train_df = svc_train_df[svc_train_df[\"measDiag\"] != DiagEnum.Undecided]\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualise the data with scatter plots and T-SNE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=60, step=1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [69], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m     plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlatent mean \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     13\u001B[0m     plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlatent mean 0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 14\u001B[0m     \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03mx_clean = latent_matrix[:, latent_inds[0]]\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;124;03my_clean = latent_matrix[:, latent_inds[1]]\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;124;03mplt.show()\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001B[0m, in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    408\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[1;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_backend_mod()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:3546\u001B[0m, in \u001B[0;36m_Backend.show\u001B[1;34m(cls, block)\u001B[0m\n\u001B[0;32m   3544\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m ipython_pylab \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive()\n\u001B[0;32m   3545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m-> 3546\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:1032\u001B[0m, in \u001B[0;36m_BackendTk.mainloop\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1030\u001B[0m manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1032\u001B[0m     \u001B[43mfirst_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m   1457\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1458\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "latent_list = list(svc_train_df[\"latent_encoding\"].map(lambda x: x[:60].tolist()).values)\n",
    "latent_df = pd.DataFrame(latent_list, index=svc_train_df.index)\n",
    "print(latent_df.columns)\n",
    "\n",
    "latent_ind = 0\n",
    "\n",
    "# scatter plot\n",
    "for i in range(60):\n",
    "    plt.figure(figsize=(6, 4), dpi=300)\n",
    "    for d in [DiagEnum.NoAF, DiagEnum.PoorQuality, DiagEnum.AF, DiagEnum.CannotExcludePathology]:\n",
    "        plt.scatter(latent_df[svc_train_df[\"measDiag\"] == d][0], latent_df[svc_train_df[\"measDiag\"] == d][i], marker=\"x\", label=d.name)\n",
    "    plt.legend()\n",
    "    plt.ylabel(f\"latent mean {i}\")\n",
    "    plt.xlabel(f\"latent mean 0\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting tsne\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [74], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstarting tsne\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      7\u001B[0m tsne \u001B[38;5;241m=\u001B[39m TSNE(n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, init\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m'\u001B[39m, perplexity\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m X_embedded \u001B[38;5;241m=\u001B[39m \u001B[43mtsne\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlatent_matrix\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m [DiagEnum\u001B[38;5;241m.\u001B[39mNoAF, DiagEnum\u001B[38;5;241m.\u001B[39mPoorQuality, DiagEnum\u001B[38;5;241m.\u001B[39mAF, DiagEnum\u001B[38;5;241m.\u001B[39mCannotExcludePathology]:\n\u001B[0;32m     12\u001B[0m     plt\u001B[38;5;241m.\u001B[39mscatter(X_embedded[latent_classes \u001B[38;5;241m==\u001B[39m d, \u001B[38;5;241m0\u001B[39m], X_embedded[latent_classes \u001B[38;5;241m==\u001B[39m d, \u001B[38;5;241m1\u001B[39m], marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m, label\u001B[38;5;241m=\u001B[39md\u001B[38;5;241m.\u001B[39mname)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1122\u001B[0m, in \u001B[0;36mTSNE.fit_transform\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m   1102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1103\u001B[0m     \u001B[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m \n\u001B[0;32m   1105\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001B[39;00m\n\u001B[0;32m   1121\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1122\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_params_vs_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1123\u001B[0m     embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit(X)\n\u001B[0;32m   1124\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_ \u001B[38;5;241m=\u001B[39m embedding\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:793\u001B[0m, in \u001B[0;36mTSNE._check_params_vs_input\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    791\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_params_vs_input\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    792\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperplexity \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m--> 793\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mperplexity must be less than n_samples\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "latent_matrix = np.array(list(svc_train_df[\"latent_encoding\"].map(lambda x: x[:60].tolist()).values))\n",
    "latent_classes = svc_train_df[\"measDiag\"].values\n",
    "\n",
    "print(\"starting tsne\")\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "\n",
    "X_embedded = tsne.fit_transform(latent_matrix)\n",
    "\n",
    "for d in [DiagEnum.NoAF, DiagEnum.PoorQuality, DiagEnum.AF, DiagEnum.CannotExcludePathology]:\n",
    "    plt.scatter(X_embedded[latent_classes == d, 0], X_embedded[latent_classes == d, 1], marker=\"x\", label=d.name)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Group all the segments together"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "(420,)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_train_df = svc_train_df[svc_train_df[\"measDiag\"] != DiagEnum.Undecided]\n",
    "\n",
    "def concatenate_means(x):\n",
    "    mean_series = x.map(lambda x: x[:60])\n",
    "    return np.concatenate(mean_series.tolist())\n",
    "\n",
    "full_ecg_train_df = svc_train_df.groupby(\"rec_ind\").agg({\"latent_encoding\": concatenate_means, \"measDiag\": lambda x: x.iloc[0], \"class_index\": lambda x: x.iloc[0]})\n",
    "full_ecg_train_df.iloc[0][\"latent_encoding\"].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting tsne\n"
     ]
    }
   ],
   "source": [
    "# Try a T-SNE now all the segments are together\n",
    "\n",
    "latent_matrix = np.array(list(full_ecg_train_df[\"latent_encoding\"].map(lambda x: x.tolist()).values))\n",
    "latent_classes = full_ecg_train_df[\"measDiag\"].values\n",
    "\n",
    "print(\"starting tsne\")\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "\n",
    "X_embedded = tsne.fit_transform(latent_matrix)\n",
    "\n",
    "for d in [DiagEnum.NoAF, DiagEnum.PoorQuality, DiagEnum.AF, DiagEnum.CannotExcludePathology]:\n",
    "    plt.scatter(X_embedded[latent_classes == d, 0], X_embedded[latent_classes == d, 1], marker=\"x\", label=d.name)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(655, 420)\n"
     ]
    }
   ],
   "source": [
    "train_matrix = np.vstack(full_ecg_train_df[\"latent_encoding\"].values)\n",
    "targets =  np.array(full_ecg_train_df[\"class_index\"].astype(int).values)\n",
    "\n",
    "print(train_matrix.shape)\n",
    "\n",
    "# class weightings?\n",
    "classifier = SVC()\n",
    "classifier = classifier.fit(train_matrix, targets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "test_dataset[\"latent_encoding\"] = None\n",
    "inds = []\n",
    "latents = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, (signals, _,  ind) in enumerate(test_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        latent_position = model.encode(signals)\n",
    "        latent_position = latent_position.detach().cpu().numpy()\n",
    "\n",
    "        for i, l in zip(ind, latent_position):\n",
    "            inds.append(int(i))\n",
    "            latents.append(l)\n",
    "\n",
    "test_dataset[\"latent_encoding\"] = pd.Series(data=latents, index=inds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586, 420)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_71904\\3497999537.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_ecg_no_undecided_test_df[\"prediction\"] = prediction\n"
     ]
    }
   ],
   "source": [
    "full_ecg_test_df = test_dataset.groupby(\"rec_ind\").agg({\"latent_encoding\": concatenate_means, \"measDiag\": lambda x: x.iloc[0], \"class_index\": lambda x: x.iloc[0], \"measID\": lambda x: x.iloc[0]})\n",
    "full_ecg_no_undecided_test_df = full_ecg_test_df[full_ecg_test_df[\"measDiag\"] != DiagEnum.Undecided]\n",
    "\n",
    "test_matrix = np.vstack(full_ecg_no_undecided_test_df[\"latent_encoding\"].values)\n",
    "targets =  np.array(full_ecg_no_undecided_test_df[\"class_index\"].astype(int).values)\n",
    "print(test_matrix.shape)\n",
    "\n",
    "prediction = classifier.predict(test_matrix)\n",
    "\n",
    "full_ecg_no_undecided_test_df[\"prediction\"] = prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[280 142]\n",
      " [ 41 123]]\n",
      "Sensitivity: 0.75\n",
      "Specificity: 0.6635071090047393\n",
      "Normal F1: 0.7537012113055181\n",
      "Noisy F1: 0.5734265734265734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(full_ecg_no_undecided_test_df[\"class_index\"].astype(int), full_ecg_no_undecided_test_df[\"prediction\"].astype(int))\n",
    "print(\"Confusion matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "def F1_ind(conf_mat, ind):\n",
    "    return (2 * conf_mat[ind, ind])/(np.sum(conf_mat[ind]) + np.sum(conf_mat[:, ind]))\n",
    "\n",
    "print(f\"Sensitivity: {conf_mat[1, 1]/np.sum(conf_mat[1])}\")\n",
    "print(f\"Specificity: {conf_mat[0, 0]/np.sum(conf_mat[0])}\")\n",
    "\n",
    "print(f\"Normal F1: {F1_ind(conf_mat, 0)}\")\n",
    "print(f\"Noisy F1: {F1_ind(conf_mat, 1)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_156864\\2192664923.py:1: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for _, ecg in feas2_ecg_data[feas2_ecg_data[\"measID\"].isin(false_positives[\"measID\"])][\"data\"].iteritems():\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [51], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, ecg \u001B[38;5;129;01min\u001B[39;00m feas2_ecg_data[feas2_ecg_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeasID\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39misin(false_positives[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeasID\u001B[39m\u001B[38;5;124m\"\u001B[39m])][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39miteritems():\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mplot_ecg_and_reconstruction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mecg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mecg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "Cell \u001B[1;32mIn [47], line 36\u001B[0m, in \u001B[0;36mplot_ecg_and_reconstruction\u001B[1;34m(x, r, fs, n_split)\u001B[0m\n\u001B[0;32m     33\u001B[0m     ax[j][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mgrid(which\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmajor\u001B[39m\u001B[38;5;124m'\u001B[39m, linestyle\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m, linewidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0.5\u001B[39m\u001B[38;5;124m'\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblack\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     34\u001B[0m     ax[j][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mgrid(which\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminor\u001B[39m\u001B[38;5;124m'\u001B[39m, linestyle\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m, linewidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0.5\u001B[39m\u001B[38;5;124m'\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlightgray\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 36\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001B[0m, in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    408\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[1;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_backend_mod()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:3546\u001B[0m, in \u001B[0;36m_Backend.show\u001B[1;34m(cls, block)\u001B[0m\n\u001B[0;32m   3544\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m ipython_pylab \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive()\n\u001B[0;32m   3545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m-> 3546\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:1032\u001B[0m, in \u001B[0;36m_BackendTk.mainloop\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1030\u001B[0m manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1032\u001B[0m     \u001B[43mfirst_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m   1457\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1458\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "false_positives = full_ecg_no_undecided_test_df[(full_ecg_no_undecided_test_df[\"class_index\"] == 0) & (full_ecg_no_undecided_test_df[\"prediction\"] == 1)]\n",
    "\n",
    "for _, ecg in feas2_ecg_data[feas2_ecg_data[\"measID\"].isin(false_positives[\"measID\"])][\"data\"].iteritems():\n",
    "    plot_ecg_and_reconstruction(ecg, ecg)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
