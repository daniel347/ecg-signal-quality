{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.signal import stft\n",
    "from scipy import signal\n",
    "# import pywt\n",
    "import CinCDataset\n",
    "import SAFERDataset\n",
    "from ecgdetectors import Detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(SAFERDataset)\n",
    "importlib.reload(CinCDataset)\n",
    "\n",
    "from DiagEnum import DiagEnum, feas1DiagToEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = CinCDataset.load_cinc_dataset()\n",
    "pt_dataset, dataset = SAFERDataset.load_feas_dataset(feas=2, force_reload=False, process=True, force_reprocess=False)\n",
    "# pt_dataset, dataset = SAFERDataset.load_feas_dataset(2, save_name=\"dataframe_laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recordings by length\n",
      "9120    23259\n",
      "Name: length, dtype: int64\n",
      "total number of recordings: 23259\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of recordings by length\")\n",
    "print(dataset[\"length\"].value_counts())\n",
    "# dataset = dataset[dataset[\"length\"] == 9120]\n",
    "print(f\"total number of recordings: {len(dataset.index)}\")\n",
    "dataset[\"class\"] = dataset[\"measDiag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3799\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue_counts()\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3805\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3807\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3802\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3805\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'class'"
     ]
    }
   ],
   "source": [
    "dataset[\"class\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   ptID   age         ptDiag          ptDiagRev1     ptDiagRev2  \\\n0     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n1     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n2     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n3     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n4     1  79.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.NoAF   \n\n           ptDiagRev3  cardRev            measDiag        measDiagRev1  \\\n0  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n1  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n2  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n3  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n4  DiagEnum.Undecided        1  DiagEnum.Undecided  DiagEnum.Undecided   \n\n         measDiagRev2  ...  presNoAF presAF  unlikelyAF perhapsAF  measID  \\\n0  DiagEnum.Undecided  ...         1      0           0         0       1   \n1  DiagEnum.Undecided  ...         1      0           0         0       2   \n2  DiagEnum.Undecided  ...         1      0           0         0       3   \n3  DiagEnum.Undecided  ...         1      0           0         0       4   \n4  DiagEnum.Undecided  ...         1      0           0         0       5   \n\n                                                data  \\\n0  [-0.2504208972513571, -0.4165748319143855, -0....   \n1  [-0.23307756027929932, -0.16123929562091616, 0...   \n2  [-0.1547458935312135, -0.16911306388956232, -0...   \n3  [0.002682835573766654, -0.5397147030048719, -1...   \n4  [0.054425319571957016, -0.22835743776367218, -...   \n\n                    file_path  class_index  length               class  \n0  ECGs/000000/saferF2_000001            0    9120  DiagEnum.Undecided  \n1  ECGs/000000/saferF2_000002            0    9120  DiagEnum.Undecided  \n2  ECGs/000000/saferF2_000003            0    9120  DiagEnum.Undecided  \n3  ECGs/000000/saferF2_000004            0    9120  DiagEnum.Undecided  \n4  ECGs/000000/saferF2_000005            0    9120  DiagEnum.Undecided  \n\n[5 rows x 39 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ptID</th>\n      <th>age</th>\n      <th>ptDiag</th>\n      <th>ptDiagRev1</th>\n      <th>ptDiagRev2</th>\n      <th>ptDiagRev3</th>\n      <th>cardRev</th>\n      <th>measDiag</th>\n      <th>measDiagRev1</th>\n      <th>measDiagRev2</th>\n      <th>...</th>\n      <th>presNoAF</th>\n      <th>presAF</th>\n      <th>unlikelyAF</th>\n      <th>perhapsAF</th>\n      <th>measID</th>\n      <th>data</th>\n      <th>file_path</th>\n      <th>class_index</th>\n      <th>length</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[-0.2504208972513571, -0.4165748319143855, -0....</td>\n      <td>ECGs/000000/saferF2_000001</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[-0.23307756027929932, -0.16123929562091616, 0...</td>\n      <td>ECGs/000000/saferF2_000002</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>[-0.1547458935312135, -0.16911306388956232, -0...</td>\n      <td>ECGs/000000/saferF2_000003</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>[0.002682835573766654, -0.5397147030048719, -1...</td>\n      <td>ECGs/000000/saferF2_000004</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>79.0</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.NoAF</td>\n      <td>DiagEnum.Undecided</td>\n      <td>1</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>DiagEnum.Undecided</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>[0.054425319571957016, -0.22835743776367218, -...</td>\n      <td>ECGs/000000/saferF2_000005</td>\n      <td>0</td>\n      <td>9120</td>\n      <td>DiagEnum.Undecided</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareEnums(series, e):\n",
    "    return series.map(lambda x: x.value) == e.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting example time series for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptDiag                          DiagEnum.NoAF\n",
      "tag_orig_Poor_Quality                       0\n",
      "poss_AF_tag                                 1\n",
      "measDiag                 DiagEnum.PoorQuality\n",
      "heartrate                           78.947368\n",
      "Name: 13914, dtype: object\n",
      "0.9999999902403353\n"
     ]
    }
   ],
   "source": [
    "# Plot with proper ECG grid in matplotlib\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "def plot_ecg(x, fs=500):\n",
    "    sample_len = x.shape[0]\n",
    "    time_axis = np.arange(sample_len)/fs\n",
    "\n",
    "    y_step = 2\n",
    "\n",
    "    cuts = [0, sample_len//3, (sample_len*2)//3, sample_len-1]\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(8, 6))\n",
    "    for j in range(3):\n",
    "        ax[j].plot(time_axis[cuts[j]:cuts[j+1]], x[cuts[j]:cuts[j+1]])\n",
    "        ax[j].set_xlabel(\"Time\")\n",
    "        ax[j].set_xlim((time_axis[cuts[j]], time_axis[cuts[j+1]]))\n",
    "\n",
    "        t_s = time_axis[cuts[j]]\n",
    "        t_f = time_axis[cuts[j+1]]\n",
    "        time_ticks = np.arange(t_s - t_s%0.2, t_f + (0.2 - t_f%0.2), 0.2)\n",
    "        decimal_labels = ~np.isclose(time_ticks, np.round(time_ticks))\n",
    "        time_labels = np.round(time_ticks).astype(int).astype(str)\n",
    "        time_labels[decimal_labels] = \"\"\n",
    "\n",
    "        ax[j].set_xticks(time_ticks, labels=time_labels)\n",
    "        ax[j].set_yticks(np.arange(x.min()-y_step, x.max()+y_step, y_step))\n",
    "\n",
    "        # ax[j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        ax[j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "        ax[j].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "        ax[j].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "        ax[j].set_ylim((x.min()-y_step, x.max()+y_step))\n",
    "        ax[j].set_xlim((t_s, t_f))\n",
    "\n",
    "        ax[j].grid(which='major', linestyle='-', linewidth='0.2', color='black')\n",
    "        ax[j].grid(which='minor', linestyle='-', linewidth='0.2', color='lightgray')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"test_ecg_plot.png\", dpi=300)\n",
    "\n",
    "c = DiagEnum.PoorQuality\n",
    "\n",
    "for _, ecg in dataset[dataset[\"class\"] == c].sample(frac=1).iterrows():\n",
    "    print(ecg[[\"ptDiag\", \"tag_orig_Poor_Quality\", \"poss_AF_tag\", \"measDiag\", \"heartrate\"]])\n",
    "    print(ecg[\"data\"].std())\n",
    "    plot_ecg(ecg[\"data\"], 300)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Check the average adc gain\n",
    "fig, ax = plt.subplots(5)\n",
    "\n",
    "for j, (i, df) in enumerate(dataset.groupby(\"measDiag\", sort=False)):\n",
    "    num_values = len(df.index)\n",
    "    ax[j].hist(df[\"adc_gain\"], bins=np.arange(0, 2, 0.2), density=True)\n",
    "    ax[j].set_title(i.name)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Check the heart rate\n",
    "detectors = Detectors(300)\n",
    "\n",
    "\"\"\"\n",
    "r_peaks = detectors.pan_tompkins_detector(dataset[\"data\"].loc[0])\n",
    "print(r_peaks)\n",
    "\n",
    "plt.plot(dataset[\"data\"].loc[0])\n",
    "plt.plot(r_peaks, dataset[\"data\"].loc[0][r_peaks], \"rx\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "dataset[\"r_peaks\"] = dataset[\"data\"].map(detectors.pan_tompkins_detector)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_heartrate(r_peaks, sig_len=30.4):\n",
    "    return (len(r_peaks)/sig_len) * 60\n",
    "\n",
    "dataset[\"heartrate\"] = dataset[\"r_peaks\"].map(get_heartrate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "177.63157894736844"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"heartrate\"].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5)\n",
    "\n",
    "for j, (i, df) in enumerate(dataset.groupby(\"measDiag\", sort=False)):\n",
    "    num_values = len(df.index)\n",
    "    ax[j].hist(df[\"heartrate\"], bins=np.arange(0, 210, 10), density=True)\n",
    "    ax[j].set_title(i.name)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compareEnums' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [20], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m num_class_samples \u001B[38;5;241m=\u001B[39m num_cols \u001B[38;5;241m*\u001B[39m num_rows\n\u001B[0;32m      7\u001B[0m fig \u001B[38;5;241m=\u001B[39m make_subplots(rows\u001B[38;5;241m=\u001B[39mnum_rows, cols\u001B[38;5;241m=\u001B[39mnum_cols)\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (_, sample) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataset[compareEnums(dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m\"\u001B[39m], c)]\u001B[38;5;241m.\u001B[39msample(num_class_samples)\u001B[38;5;241m.\u001B[39miterrows()):\n\u001B[0;32m     10\u001B[0m     fig\u001B[38;5;241m.\u001B[39madd_trace(go\u001B[38;5;241m.\u001B[39mScatter(y\u001B[38;5;241m=\u001B[39msample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m]), row\u001B[38;5;241m=\u001B[39mi\u001B[38;5;241m%\u001B[39mnum_cols \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, col \u001B[38;5;241m=\u001B[39m i\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39mnum_rows \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     12\u001B[0m fig\u001B[38;5;241m.\u001B[39mupdate_layout(height\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'compareEnums' is not defined"
     ]
    }
   ],
   "source": [
    "c = DiagEnum.AF\n",
    "\n",
    "num_rows = 4\n",
    "num_cols = 4\n",
    "\n",
    "num_class_samples = num_cols * num_rows\n",
    "fig = make_subplots(rows=num_rows, cols=num_cols)\n",
    "\n",
    "for i, (_, sample) in enumerate(dataset[compareEnums(dataset[\"class\"], c)].sample(num_class_samples).iterrows()):\n",
    "    fig.add_trace(go.Scatter(y=sample[\"data\"]), row=i%num_cols + 1, col = i//num_rows + 1)\n",
    "\n",
    "fig.update_layout(height=1000)\n",
    "fig.update_xaxes(title=\"sample number\")\n",
    "fig.update_yaxes(title=\"amplitude\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting samples from each class with their DFTs below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = DiagEnum.PoorQuality\n",
    "num_cols = 3\n",
    "num_rows = 2\n",
    "\n",
    "num_class_samples = num_cols\n",
    "fig = make_subplots(rows=num_rows, cols=num_cols)\n",
    "\n",
    "for i, (_, sample) in enumerate(dataset[compareEnums(dataset[\"class\"], c)].sample(num_class_samples).iterrows()):\n",
    "    fig.add_trace(go.Scatter(y=sample[\"data\"]), row=1, col = i + 1)\n",
    "    fft = np.log10(np.abs(np.fft.fft(sample[\"data\"])))\n",
    "    fftfreq = np.fft.fftfreq(len(sample[\"data\"]), d=1.0/300.0)\n",
    "\n",
    "    fig.add_trace(go.Scatter(y=fft, x=fftfreq), row = 2, col = i + 1)\n",
    "\n",
    "fig.update_layout(height=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting samples with their STFT below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = DiagEnum.PoorQuality\n",
    "num_cols = 3\n",
    "num_rows = 2\n",
    "\n",
    "num_class_samples = num_cols\n",
    "fig = make_subplots(rows=num_rows, cols=num_cols)\n",
    "\n",
    "for i, (_, sample) in enumerate(dataset[compareEnums(dataset[\"class\"], c)].sample(num_class_samples).iterrows()):\n",
    "    fig.add_trace(go.Scatter(y=sample[\"data\"]), row=1, col = i + 1)\n",
    "\n",
    "    f_axis, t_axis, stft = signal.stft(sample[\"data\"], nperseg=256)\n",
    "    fig.add_trace(go.Heatmap(z=np.log10(np.abs(stft)), y=f_axis, x=t_axis), row = 2, col = i + 1)\n",
    "\n",
    "fig.update_layout(height=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting samples from each class with their wavelet transform below\n",
    "\n",
    "These plots dont really work well and I so far have made no other use of wavelet transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First a Discrete wavelet transform (dont understand how this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi, psi, x = pywt.Wavelet('sym4').wavefun(1)\n",
    "plt.plot(x, phi)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, psi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = \"~\"\n",
    "num_cols = 3\n",
    "num_rows = 2\n",
    "\n",
    "num_class_samples = num_cols\n",
    "fig = make_subplots(rows=num_rows, cols=num_cols)\n",
    "\n",
    "for i, (_, sample) in enumerate(dataset[dataset[\"class\"] == c].sample(num_class_samples).iterrows()):\n",
    "    fig.add_trace(go.Scatter(y=sample[\"data\"][0]), row=1, col = i + 1)\n",
    "    wavelets = np.array(pywt.wavedec(sample[\"data\"][0], 'sym4'))\n",
    "    for wavelet in wavelets:\n",
    "        print(wavelet.shape)\n",
    "        # The wavelets arent the same shape IDK how to use this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a continuous wavelet transform from scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something feels off about this as well!\n",
    "\n",
    "c = \"N\"\n",
    "num_cols = 3\n",
    "num_rows = 2\n",
    "\n",
    "num_class_samples = num_cols\n",
    "fig = make_subplots(rows=num_rows, cols=num_cols)\n",
    "\n",
    "for i, (_, sample) in enumerate(dataset[dataset[\"class\"] == c].sample(num_class_samples).iterrows()):\n",
    "    fig.add_trace(go.Scatter(y=sample[\"data\"][0]), row=1, col = i + 1)\n",
    "    widths = np.linspace(1, 100, 20)\n",
    "    cwtmatr = signal.cwt(sample[\"data\"][0], signal.ricker, widths)\n",
    "    wavelets_sample = np.abs(cwtmatr)\n",
    "    print(wavelets_sample.shape)\n",
    "\n",
    "    fig.add_trace(go.Heatmap(z=wavelets_sample), row = 2, col = i + 1)\n",
    "\n",
    "fig.update_layout(height=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the performance of Zenicors system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(dataset[\"class_index\"], dataset[\"tag_orig_Poor_Quality\"])\n",
    "print(conf_mat)\n",
    "\n",
    "def F1_ind(conf_mat, ind):\n",
    "    return (2 * conf_mat[ind, ind])/(np.sum(conf_mat[ind]) + np.sum(conf_mat[:, ind]))\n",
    "\n",
    "print(f\"Sensitivity: {conf_mat[1, 1]/np.sum(conf_mat[1])}\")\n",
    "print(f\"Specificity: {conf_mat[0, 0]/np.sum(conf_mat[0])}\")\n",
    "\n",
    "print(f\"Normal F1: {F1_ind(conf_mat, 0)}\")\n",
    "print(f\"Noisy F1: {F1_ind(conf_mat, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Noise Stress Test Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"mit-bih-noise-stress-test-database/database.pk\")\n",
    "print(dataset[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ecg(dataset[dataset[\"class\"] == \"N\"][\"data\"].iloc[0][:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuroKit analysis\n",
    "I dont know for sure what use this will be but it might be cool\n",
    "From a signal processing point of view this could also be useful to compare how certian things are done and what effect noise has on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecgs = [nk.ecg_simulate(duration=10, heart_rate=70, sampling_rate=250, noise=0.1, random_state=i) for i in range(10)]\n",
    "\n",
    "fig = go.Figure()\n",
    "for ecg in ecgs:\n",
    "    fig.add_trace(go.Scatter(y=ecg))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals, info = nk.ecg_process(dataset[dataset[\"class\"] == \"N\"].iloc[100][\"data\"][0], sampling_rate=250)\n",
    "nk.ecg_plot(signals, sampling_rate=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks, info = nk.ecg_peaks(ecg, sampling_rate=250)\n",
    "print(peaks[peaks[\"ECG_R_Peaks\"] != 0])\n",
    "nk.hrv(peaks, sampling_rate=100, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate ECGs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_ecg = nk.ecg_simulate(duration=15, sampling_rate=300, heart_rate=70)\n",
    "plt.plot(simulated_ecg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from ecgdetectors import Detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[\"data\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = Detectors(300)\n",
    "\n",
    "beat_window = 300\n",
    "\n",
    "slices = []\n",
    "i = 0\n",
    "for _, series in dataset.iterrows():\n",
    "    print(f\"Processing ecg {i}/{len(dataset.index)}\\r\", end=\"\")\n",
    "    r_peaks = detectors.hamilton_detector(series[\"data\"])\n",
    "    windows = [(int(p-beat_window/2), int(p+beat_window/2)) for p in r_peaks]\n",
    "    padded_data = np.pad(series[\"data\"], beat_window, mode=\"reflect\")\n",
    "    slices.extend([padded_data[w[0]:w[1]] for w in windows])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slices[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = filter(lambda x: x.shape[0] == beat_window, slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = list(slices)\n",
    "print(len(slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(slices)\n",
    "\n",
    "pca = PCA(20)\n",
    "pca.fit(X)\n",
    "components = pca.components_\n",
    "print(components.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_cols = 4\n",
    "\n",
    "num_class_samples = num_cols * num_rows\n",
    "fig = make_subplots(rows=num_rows, cols=num_cols)\n",
    "\n",
    "for i, comp in enumerate(components):\n",
    "    fig.add_trace(go.Scatter(y=comp), row= i//num_cols + 1, col = i%num_cols + 1)\n",
    "\n",
    "fig.update_layout(height=1000)\n",
    "fig.update_xaxes(title=\"sample number\")\n",
    "fig.update_yaxes(title=\"amplitude\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
