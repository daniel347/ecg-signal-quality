{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-11T19:47:39.329182900Z",
     "start_time": "2023-06-11T19:46:18.713331700Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import scipy.signal\n",
    "from ecgdetectors import Detectors\n",
    "\n",
    "import math\n",
    "from DataHandlers.DiagEnum import DiagEnum\n",
    "import DataHandlers.DiagEnum\n",
    "import DataHandlers.SAFERDataset as SAFERDataset\n",
    "import DataHandlers.CinC2020Dataset as CinC2020Dataset\n",
    "import DataHandlers.CinC2020Enums\n",
    "import importlib\n",
    "import DataHandlers.CinCDataset as CinCDataset\n",
    "import DataHandlers.DataAugmentations as DataAugmentations\n",
    "from multiprocesspandas import applyparallel\n",
    "\n",
    "import DataHandlers.DataProcessUtilities\n",
    "importlib.reload(DataHandlers.DataProcessUtilities)\n",
    "from DataHandlers.DataProcessUtilities import *\n",
    "import Utilities.Plotting\n",
    "importlib.reload(Utilities.Plotting)\n",
    "from Utilities.Plotting import *\n",
    "\n",
    "# A fudge because I moved the files\n",
    "sys.modules[\"SAFERDataset\"] = SAFERDataset\n",
    "sys.modules[\"CinC2020Dataset\"] = CinC2020Dataset\n",
    "sys.modules[\"DiagEnum\"] = DataHandlers.DiagEnum\n",
    "sys.modules[\"CinC2020Enums\"] = DataHandlers.CinC2020Enums\n",
    "sys.modules[\"CinCDataset\"] = CinCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-11T19:47:39.329182900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "enable_cuda = True\n",
    "\n",
    "if torch.cuda.is_available() and enable_cuda:\n",
    "    print(\"Using Cuda\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAFER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\2022_23_DSiromani\\Feas2\\ECGs/filtered_dataframe_reload.pk\n"
     ]
    }
   ],
   "source": [
    "feas2_pt_data, feas2_ecg_data = SAFERDataset.load_feas_dataset(2, \"dataframe_reload\")\n",
    "feas2_ecg_data[\"measID\"] += 300000\n",
    "feas2_ecg_data[\"feas\"] = 2\n",
    "feas2_ecg_data.index = feas2_ecg_data[\"measID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas2_ecg_data[\"feas\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_normals_all_other_af(pt_data, ecg_data):\n",
    "    accepted_meas_diags = [DiagEnum.AF, DiagEnum.NoAF, DiagEnum.HeartBlock]\n",
    "    ecg_data = ecg_data[(ecg_data[\"measDiag\"].isin(accepted_meas_diags)) | (ecg_data[\"measID\"] < 20000) | (ecg_data[\"not_tagged_ign_wide_qrs\"] == 0)]\n",
    "    pt_data = pt_data[pt_data[\"ptID\"].isin(ecg_data[\"ptID\"])]\n",
    "\n",
    "    return pt_data, ecg_data\n",
    "\n",
    "# warning: changing these chunk sizes may reload feas1 data from scratch, which will take ages\n",
    "chunk_size = 20000\n",
    "num_chunks = math.ceil(162515 / chunk_size )\n",
    "\n",
    "def load_feas1_chunk_range(chunk_range=(0, num_chunks)):\n",
    "    ecg_data = []\n",
    "    pt_data = []\n",
    "\n",
    "    for chunk_num in range(chunk_range[0], chunk_range[1]):\n",
    "        feas1_pt_data, feas1_ecg_data = SAFERDataset.load_feas_dataset(1, f\"dataframe_{chunk_num}.pk\")\n",
    "\n",
    "        ecg_data.append(feas1_ecg_data)\n",
    "        pt_data.append(feas1_pt_data)\n",
    "\n",
    "    feas1_ecg_data = pd.concat(ecg_data)\n",
    "    feas1_ecg_data[\"feas\"] = 1\n",
    "    feas1_ecg_data[\"rri_len\"] = feas1_ecg_data[\"rri_feature\"].map(lambda x: x[x > 0].shape[-1])\n",
    "    feas1_pt_data = pd.concat(pt_data).drop_duplicates()\n",
    "\n",
    "    return feas1_ecg_data, feas1_pt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_safer_data(pt_data, ecg_data):\n",
    "    if \"length\" in ecg_data:\n",
    "        ecg_data = ecg_data[ecg_data[\"length\"] == 9120]\n",
    "\n",
    "    ecg_data = ecg_data[ecg_data[\"measDiag\"] != DiagEnum.PoorQuality]\n",
    "    # ecg_data = ecg_data[ecg_data[\"tag_orig_Poor_Quality\"] == 0]\n",
    "\n",
    "    ecg_data = ecg_data[ecg_data[\"rri_len\"] > 5]\n",
    "\n",
    "\n",
    "    pt_data.index = pt_data[\"ptID\"]\n",
    "    ecg_data = SAFERDataset.generate_af_class_labels(ecg_data)\n",
    "    pt_data = SAFERDataset.add_ecg_class_counts(pt_data, ecg_data)\n",
    "\n",
    "    return pt_data, ecg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_0.pk.pk\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_1.pk.pk\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_2.pk.pk\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_3.pk.pk\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_4.pk.pk\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_5.pk.pk\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_6.pk.pk\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_7.pk.pk\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_8.pk.pk\n"
     ]
    }
   ],
   "source": [
    "feas1_ecg_data, feas1_pt_data = load_feas1_chunk_range((0, num_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just use feas2\n",
    "safer_ecg_data = feas2_ecg_data\n",
    "safer_ecg_data[\"ffReview_sent\"] = -1\n",
    "safer_ecg_data[\"ffReview_remain\"] = -1\n",
    "safer_pt_data = feas2_pt_data\n",
    "\n",
    "safer_pt_data, safer_ecg_data = prepare_safer_data(safer_pt_data, safer_ecg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22274\n",
      "2      377\n",
      "1      102\n",
      "Name: class_index, dtype: int64\n",
      "0    22862\n",
      "2      452\n",
      "1      126\n",
      "Name: class_index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Just use feas1 to prepare test and validation datasets (The train is best handled with a DatasetSequenceIterator)\n",
    "feas1_pt_data, feas1_ecg_data = prepare_safer_data(feas1_pt_data, feas1_ecg_data)\n",
    "feas1_ecg_data[\"class_index\"].value_counts()\n",
    "\n",
    "feas1_ecg_data_test = feas1_ecg_data[feas1_ecg_data[\"ptID\"].isin(test_pts[\"ptID\"])]\n",
    "feas1_ecg_data_val = feas1_ecg_data[feas1_ecg_data[\"ptID\"].isin(val_pts[\"ptID\"])]\n",
    "\n",
    "print(feas1_ecg_data_test[\"class_index\"].value_counts())\n",
    "print(feas1_ecg_data_val[\"class_index\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    31274\n",
      "2     2281\n",
      "1      513\n",
      "Name: class_index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Undersample normals and produce a dataloader\n",
    "feas1_ecg_data_train_norm = feas1_ecg_data[(feas1_ecg_data[\"class_index\"] == 0) & (feas1_ecg_data[\"ptID\"].isin(train_pts[\"ptID\"]))].sample(frac=0.3)\n",
    "feas1_ecg_data_train_not_norm = feas1_ecg_data[(feas1_ecg_data[\"class_index\"] != 0) & (feas1_ecg_data[\"ptID\"].isin(train_pts[\"ptID\"]))]\n",
    "\n",
    "feas1_ecg_data_test_norm = feas1_ecg_data[(feas1_ecg_data[\"class_index\"] == 0) & (feas1_ecg_data[\"ptID\"].isin(test_pts[\"ptID\"]))].sample(frac=0.3)\n",
    "feas1_ecg_data_test_not_norm = feas1_ecg_data[(feas1_ecg_data[\"class_index\"] != 0) & (feas1_ecg_data[\"ptID\"].isin(test_pts[\"ptID\"]))]\n",
    "\n",
    "feas1_ecg_data_test_undersamp = pd.concat([feas1_ecg_data_test_norm, feas1_ecg_data_test_not_norm])\n",
    "feas1_ecg_data_train_undersamp = pd.concat([feas1_ecg_data_train_norm, feas1_ecg_data_train_not_norm])\n",
    "print(feas1_ecg_data_train_undersamp[\"class_index\"].value_counts())\n",
    "\n",
    "feas1_train_dataloader_undersamp = get_dataloaders(feas1_ecg_data_train_undersamp, 64)\n",
    "feas1_test_dataloader_undersamp = get_dataloaders(feas1_ecg_data_test_undersamp, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = r\"C:\\Users\\daniel\\Documents\"\n",
    "\n",
    "feas1_ecg_data_test.to_pickle(os.path.join(doc_path, \"feas1_test_27_mar.pk\"))\n",
    "feas1_ecg_data_val.to_pickle(os.path.join(doc_path, \"feas1_val_27_mar.pk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "safer_ecg_data = pd.concat([feas2_ecg_data, feas1_ecg_data])\n",
    "safer_pt_data = pd.concat([feas2_pt_data, feas1_pt_data])\n",
    "\n",
    "safer_pt_data, safer_ecg_data = prepare_safer_data(safer_pt_data, safer_ecg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feas  class_index\n",
       "2     0              19513\n",
       "      2                757\n",
       "      1                 16\n",
       "Name: class_index, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safer_ecg_data.groupby(\"feas\")[\"class_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a heartrate histogram for AF and not AF\n",
    "fig, ax = plt.subplots(figsize=(4, 4), dpi=300)\n",
    "ax.hist(safer_ecg_data[\"heartrate\"][(safer_ecg_data[\"measDiag\"] != DiagEnum.AF) & (safer_ecg_data[\"feas\"] == 1)], alpha=0.7, density=True, label=\"Normal or Other Rhythm\")\n",
    "ax.hist(safer_ecg_data[\"heartrate\"][(safer_ecg_data[\"measDiag\"] == DiagEnum.AF) & (safer_ecg_data[\"feas\"] == 1)], alpha=0.7, density=True, label=\"AF\")\n",
    "ax.set_xlabel(\"Heartrate (bpm)\")\n",
    "ax.set_ylabel(\"Frequency proportion\")\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out high and low heartrates - I dont think this makes a difference so havent been doing it mostly\n",
    "safer_ecg_data = safer_ecg_data[(safer_ecg_data[\"heartrate\"] < 120) & (safer_ecg_data[\"heartrate\"] > 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for _, ecg in safer_ecg_data[safer_ecg_data[\"feas\"] == 1].sample(frac=1).iterrows():\n",
    "    print(ecg[[\"measDiag\", \"class_index\", \"heartrate\", \"r_peaks\"]])\n",
    "    plot_ecg(ecg[\"data\"], r_peaks=ecg[\"r_peaks\"], fs=300, n_split=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 1 feas2 AF example with high heartrate!\n",
    "\n",
    "plot_ecg(safer_ecg_data.loc[310209][\"data\"], r_peaks=safer_ecg_data.loc[310209][\"r_peaks\"], fs=300, n_split=3, figsize=(6, 5), export_quality=True)\n",
    "plot_ecg_spectrogram(safer_ecg_data.loc[310209][\"data\"], fs=300, n_split=3, figsize=(6, 5), export_quality=True, cut_range=(2, 18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CinC 2020 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataHandlers.CinC2020Dataset as CinC2020Dataset\n",
    "import importlib\n",
    "importlib.reload(CinC2020Dataset)\n",
    "\n",
    "df = CinC2020Dataset.load_dataset(save_name=\"dataframe_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the moment we only select data with length which can be truncated to 3000 samples (10s)\n",
    "def select_length(df):\n",
    "    df_within_range = df[(df[\"length\"] <= 5000) & (df[\"length\"] >= 3000)].copy()\n",
    "    df_within_range[\"data\"] = df_within_range[\"data\"].map(lambda x: x[:3000])\n",
    "    df_within_range[\"length\"] = df_within_range[\"data\"].map(lambda x: x.shape[0])\n",
    "    return df_within_range\n",
    "\n",
    "df = select_length(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a heartrate histogram for AF and not AF\n",
    "fig, ax = plt.subplots(figsize=(4, 4), dpi=300)\n",
    "ax.hist(df[\"heartrate\"][(df[\"measDiag\"] != DiagEnum.AF)], alpha=0.7, density=True, label=\"Normal or Other Rhythm\")\n",
    "ax.hist(df[\"heartrate\"][(df[\"measDiag\"] == DiagEnum.AF)], alpha=0.7, density=True, label=\"AF\")\n",
    "ax.set_xlabel(\"Heartrate (bpm)\")\n",
    "ax.set_ylabel(\"Frequency proportion\")\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04636585375203334\n",
      "-0.12941265829123266\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [26], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m plot_ecg(ecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m noise, figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m2\u001B[39m), export_quality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      9\u001B[0m plot_ecg(noise, figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m2\u001B[39m), export_quality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001B[0m, in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    408\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[1;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_backend_mod()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:3546\u001B[0m, in \u001B[0;36m_Backend.show\u001B[1;34m(cls, block)\u001B[0m\n\u001B[0;32m   3544\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m ipython_pylab \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive()\n\u001B[0;32m   3545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m-> 3546\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:1032\u001B[0m, in \u001B[0;36m_BackendTk.mainloop\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1030\u001B[0m manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1032\u001B[0m     \u001B[43mfirst_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m   1457\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1458\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "noise = noise_df.sample()[\"data\"].iloc[0] * np.random.normal(scale=1)\n",
    "\n",
    "for _, ecg in df.iterrows():\n",
    "    noise_scale = np.random.normal(scale=0.2)\n",
    "    noise = noise_df.sample()[\"data\"].iloc[0] * noise_scale\n",
    "    print(noise_scale)\n",
    "    plot_ecg(ecg[\"data\"], figsize=(5, 2), export_quality=True)\n",
    "    plot_ecg(ecg[\"data\"] + noise, figsize=(5, 2), export_quality=True)\n",
    "    plot_ecg(noise, figsize=(5, 2), export_quality=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [83], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, ecg \u001B[38;5;129;01min\u001B[39;00m df[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass_index\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[0;32m      2\u001B[0m     plot_ecg(ecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m][:\u001B[38;5;241m1500\u001B[39m], figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m2.5\u001B[39m), export_quality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 3\u001B[0m     \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001B[0m, in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    408\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[1;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_backend_mod()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:3546\u001B[0m, in \u001B[0;36m_Backend.show\u001B[1;34m(cls, block)\u001B[0m\n\u001B[0;32m   3544\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m ipython_pylab \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive()\n\u001B[0;32m   3545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m-> 3546\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:1032\u001B[0m, in \u001B[0;36m_BackendTk.mainloop\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1030\u001B[0m manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1032\u001B[0m     \u001B[43mfirst_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m   1457\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1458\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for _, ecg in df[df[\"class_index\"] == 0].iterrows():\n",
    "    plot_ecg(ecg[\"data\"][:1500], figsize=(5, 2.5), export_quality=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset               class_index\n",
       "cpsc_2018             2               2047\n",
       "                      0                984\n",
       "                      1                903\n",
       "cpsc_2018_extra       2                364\n",
       "                      0                350\n",
       "                      1                113\n",
       "georgia               2               5257\n",
       "                      0               3508\n",
       "                      1                566\n",
       "ptb-xl                0              10692\n",
       "                      2               9349\n",
       "                      1               1514\n",
       "st_petersburg_incart  0              10955\n",
       "                      1               1010\n",
       "                      2                363\n",
       "Name: class_index, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"dataset\")[\"class_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load noise from MIT database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "from scipy import signal\n",
    "\n",
    "noises = [\"em\", \"ma\"]\n",
    "noise_dfs = []\n",
    "mit_dataset_path = \"Datasets/mit-bih-noise-stress-test-database\"\n",
    "\n",
    "f_low = 0.67\n",
    "f_high = 25\n",
    "\n",
    "def split_signal(data, split_len):\n",
    "    data_splits = []\n",
    "    splits = np.arange(0, data[\"data\"].shape[0], split_len)\n",
    "\n",
    "    for i, (start, end) in enumerate(zip(splits, splits[1:])):\n",
    "        data_split = data.copy()\n",
    "        data_split[\"data\"] = data[\"data\"][start:end]\n",
    "        data_split[\"data\"] = (data_split[\"data\"] - data_split[\"data\"].mean())/ data_split[\"data\"].std()\n",
    "\n",
    "        data_split.name = i\n",
    "        data_splits.append(data_split)\n",
    "\n",
    "    return data_splits\n",
    "\n",
    "\n",
    "for n_path in noises:\n",
    "    rec = wfdb.rdrecord(os.path.join(mit_dataset_path, n_path))\n",
    "    sig = np.concatenate([rec.p_signal[:, 0], rec.p_signal[:, 1]])\n",
    "\n",
    "    bandpass = signal.butter(3, [f_low, f_high], 'bandpass', fs=rec.fs, output='sos')\n",
    "    notch = signal.butter(3, [48, 52], 'bandstop', fs=rec.fs, output='sos')\n",
    "\n",
    "    sig = filter_and_norm(sig, bandpass)\n",
    "    sig = filter_and_norm(sig, notch)\n",
    "\n",
    "    sig = resample(sig, rec.fs, 300)\n",
    "    sig_series = pd.Series(data={\"data\": sig, \"fs\": 300, \"noise_type\": n_path})\n",
    "\n",
    "    split_signals = split_signal(sig_series, 3000)\n",
    "    split_signals = pd.DataFrame(split_signals)\n",
    "\n",
    "    noise_dfs.append(split_signals)\n",
    "\n",
    "noise_df = pd.concat(noise_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CinC2017 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8528/8528 [00:03<00:00, 2435.20it/s]\n",
      "C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\DataHandlers\\CinCDataset.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ecg_data[\"rri_len\"] = ecg_data[\"rri_feature\"].map(lambda x: x[x > 0].shape[-1])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(CinCDataset)\n",
    "import DataHandlers.DataProcessUtilities\n",
    "importlib.reload(DataHandlers.DataProcessUtilities)\n",
    "from DataHandlers.DataProcessUtilities import *\n",
    "\n",
    "cinc2017_df = CinCDataset.load_cinc_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiagEnum.NoAF                      3694\n",
       "DiagEnum.CannotExcludePathology    1649\n",
       "DiagEnum.AF                         504\n",
       "DiagEnum.PoorQuality                123\n",
       "Name: measDiag, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cinc2017_df = cinc2017_df[cinc2017_df[\"length\"] == 9000]\n",
    "cinc2017_df[\"measDiag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cinc2017_df = cinc2017_df[cinc2017_df[\"length\"] == 9000]\n",
    "cinc2017_df = cinc2017_df[cinc2017_df[\"measDiag\"] != DiagEnum.PoorQuality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5847\n",
       "Name: class_index, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cinc2017_df[\"class_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a heartrate histogram for AF and not AF\n",
    "fig, ax = plt.subplots(figsize=(4, 4), dpi=300)\n",
    "ax.hist(cinc2017_df[\"heartrate\"][(cinc2017_df[\"class_index\"] != 1)], alpha=0.7, density=True, label=\"Normal or Other Rhythm\")\n",
    "ax.hist(cinc2017_df[\"heartrate\"][(cinc2017_df[\"class_index\"] == 1)], alpha=0.7, density=True, label=\"AF\")\n",
    "ax.set_xlabel(\"Heartrate (bpm)\")\n",
    "ax.set_ylabel(\"Frequency proportion\")\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [81], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m plot_ecg(ecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m][:\u001B[38;5;241m3000\u001B[39m], \u001B[38;5;241m300\u001B[39m, n_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, r_peaks\u001B[38;5;241m=\u001B[39mecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr_peaks\u001B[39m\u001B[38;5;124m\"\u001B[39m], figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m2.5\u001B[39m), export_quality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m plot_ecg_spectrogram(ecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m][:\u001B[38;5;241m3000\u001B[39m], \u001B[38;5;241m300\u001B[39m, n_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, cut_range\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m18\u001B[39m], figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m2.5\u001B[39m), export_quality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mplot_ecg_poincare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mecg\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrri_feature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;66;03m# ecg[\"rri_len\"])\u001B[39;00m\n\u001B[0;32m      7\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\Utilities\\Plotting.py:40\u001B[0m, in \u001B[0;36mplot_ecg_poincare\u001B[1;34m(rri, rri_len, figsize)\u001B[0m\n\u001B[0;32m     38\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlim((\u001B[38;5;241m0.3\u001B[39m, \u001B[38;5;241m1.5\u001B[39m))\n\u001B[0;32m     39\u001B[0m plt\u001B[38;5;241m.\u001B[39mylim((\u001B[38;5;241m0.3\u001B[39m, \u001B[38;5;241m1.5\u001B[39m))\n\u001B[1;32m---> 40\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001B[0m, in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    408\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[1;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_backend_mod()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:3546\u001B[0m, in \u001B[0;36m_Backend.show\u001B[1;34m(cls, block)\u001B[0m\n\u001B[0;32m   3544\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m ipython_pylab \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive()\n\u001B[0;32m   3545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m-> 3546\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:1032\u001B[0m, in \u001B[0;36m_BackendTk.mainloop\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1030\u001B[0m manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1032\u001B[0m     \u001B[43mfirst_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m   1457\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1458\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ecgs = cinc2017_df[(cinc2017_df[\"class_index\"] == 2) & (cinc2017_df[\"heartrate\"] > 120)]\n",
    "\n",
    "for _, ecg in ecgs.iterrows():\n",
    "    plot_ecg(ecg[\"data\"][:3000], 300, n_split=1, r_peaks=ecg[\"r_peaks\"], figsize=(6, 2.5), export_quality=True)\n",
    "    plot_ecg_spectrogram(ecg[\"data\"][:3000], 300, n_split=1, cut_range=[2, 18], figsize=(6, 2.5), export_quality=True)\n",
    "    plot_ecg_poincare(ecg[\"rri_feature\"][:10], 10)# ecg[\"rri_len\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg = cinc2017_df.loc[\"A02650\"]\n",
    "\n",
    "plot_ecg(ecg[\"data\"], 300, n_split=3, r_peaks=ecg[\"r_peaks\"], figsize=(6, 2.5), export_quality=True)\n",
    "plot_ecg_drr(ecg[\"rri_feature\"], ecg[\"rri_len\"], export_quality=True)# ecg[\"rri_len\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = CinC2020Dataset.CinC2020DiagMapper()\n",
    "num_unique_classes = len(mapper.diag_desc.index)\n",
    "\n",
    "# Note this only gets used for CinC data - the safer data labels were decided to have different meanings\n",
    "def class_index_map(diag):\n",
    "    if diag == DiagEnum.NoAF:\n",
    "        return 0\n",
    "    elif diag == DiagEnum.AF:\n",
    "        return 1\n",
    "    elif diag == DiagEnum.CannotExcludePathology:\n",
    "        return 2\n",
    "    elif diag == DiagEnum.Undecided:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cinc2017_df[\"class_index\"] = cinc2017_df[\"measDiag\"].map(class_index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot encoding\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "        self.noise_prob = 0\n",
    "        self.temp_warp = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dataset.index)\n",
    "\n",
    "    def set_noise_prob(self, prob, power_std, noise_df):\n",
    "        self.noise_prob = prob\n",
    "        self.noise_power_std = power_std\n",
    "        self.noise_df = noise_df\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.dataset.iloc[index]\n",
    "\n",
    "        data = row[\"data\"]\n",
    "        rri = row[\"rri_feature\"]\n",
    "        rri_len = row[\"rri_len\"]\n",
    "\n",
    "        warp = np.random.binomial(1, self.temp_warp)\n",
    "        if warp:\n",
    "            data, r_peaks = DataAugmentations.temporal_warp(data, row[\"r_peaks_hamilton\"])\n",
    "            rri = get_rri_feature(r_peaks, 20)\n",
    "\n",
    "        add_noise = np.random.binomial(1, self.noise_prob)\n",
    "        if add_noise:\n",
    "            noise = noise_df.sample()[\"data\"].iloc[0] * np.random.normal(scale=self.noise_power_std)\n",
    "            data += noise\n",
    "\n",
    "        X = (data, rri, rri_len)\n",
    "        y = row[\"class_index\"]\n",
    "        ind = row.name\n",
    "\n",
    "        return X, y, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SAFER data\n",
    "# Split train and test data according to each patient\n",
    "# Note this function stratifies for AF and non AF!\n",
    "def generate_patient_splits(pt_data, test_frac, val_frac):\n",
    "    train_patients = []\n",
    "    test_patients = []\n",
    "    val_patients = []\n",
    "\n",
    "    test_val_frac = test_frac + val_frac\n",
    "    val_second_frac = val_frac/test_val_frac\n",
    "\n",
    "    for val, df in pt_data.groupby(\"noAFRecs\"):\n",
    "        print(f\"processing {val}\")\n",
    "        print(f\"number of patients {len(df.index)}\")\n",
    "\n",
    "\n",
    "\n",
    "        n = math.floor(len(df.index) * test_val_frac)\n",
    "        if  test_val_frac > 0:\n",
    "            res = ((len(df.index) * test_val_frac) - n)/test_val_frac\n",
    "        else:\n",
    "            res = 0\n",
    "        n += np.random.binomial(res, test_val_frac)\n",
    "        test_val = df.sample(n)\n",
    "\n",
    "        n = math.floor(len(test_val.index) * val_second_frac)\n",
    "        if  val_second_frac > 0:\n",
    "            res = ((len(test_val.index) * val_second_frac) - n)/val_second_frac\n",
    "        else:\n",
    "            res = 0\n",
    "        n += np.random.binomial(res, val_second_frac)\n",
    "        val = test_val.sample(n)\n",
    "        val_patients.append(val)\n",
    "\n",
    "        test_patients.append(test_val[~test_val[\"ptID\"].isin(val[\"ptID\"])])\n",
    "        train_patients.append(df[~df[\"ptID\"].isin(test_val[\"ptID\"])])\n",
    "\n",
    "    train_pt_df = pd.concat(train_patients)\n",
    "    test_pt_df = pd.concat(test_patients)\n",
    "    val_pt_df = pd.concat(val_patients)\n",
    "\n",
    "    return train_pt_df, test_pt_df, val_pt_df\n",
    "\n",
    "\n",
    "def make_SAFER_dataloaders(pt_data, ecg_data, test_frac, val_frac, batch_size=128):\n",
    "    train_pt_df, test_pt_df, val_pt_df = generate_patient_splits(pt_data, test_frac, val_frac)\n",
    "\n",
    "    print(f\"Test AF: {test_pt_df['noAFRecs'].sum()} Normal: {test_pt_df['noNormalRecs'].sum()} Other: {test_pt_df['noOtherRecs'].sum()}\")\n",
    "    print(f\"Train AF: {train_pt_df['noAFRecs'].sum()} Normal: {train_pt_df['noNormalRecs'].sum()} Other: {train_pt_df['noOtherRecs'].sum()}\")\n",
    "    print(f\"Val AF: {val_pt_df['noAFRecs'].sum()} Normal: {val_pt_df['noNormalRecs'].sum()} Other: {val_pt_df['noOtherRecs'].sum()}\")\n",
    "\n",
    "    train_dataloader = None\n",
    "    test_dataloader = None\n",
    "    val_dataloader = None\n",
    "\n",
    "    train_dataset = None\n",
    "    test_dataset = None\n",
    "    val_dataset = None\n",
    "\n",
    "    if not train_pt_df.empty:\n",
    "        # get ECG datasets\n",
    "        train_dataset = ecg_data[ecg_data[\"ptID\"].isin(train_pt_df[\"ptID\"])]\n",
    "        # Normalise\n",
    "        train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "        torch_dataset_train = Dataset(train_dataset)\n",
    "        train_dataloader = DataLoader(torch_dataset_train, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "    if not test_pt_df.empty:\n",
    "        test_dataset = ecg_data[(ecg_data[\"ptID\"].isin(test_pt_df[\"ptID\"]))]\n",
    "        test_dataset[\"data\"] = (test_dataset[\"data\"] - test_dataset[\"data\"].map(lambda x: x.mean()))/test_dataset[\"data\"].map(lambda x: x.std())\n",
    "        torch_dataset_test = Dataset(test_dataset)\n",
    "        test_dataloader = DataLoader(torch_dataset_test, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "    if not val_pt_df.empty:\n",
    "        val_dataset = ecg_data[(ecg_data[\"ptID\"].isin(val_pt_df[\"ptID\"]))]\n",
    "        val_dataset[\"data\"] = (val_dataset[\"data\"] - val_dataset[\"data\"].map(lambda x: x.mean()))/val_dataset[\"data\"].map(lambda x: x.std())\n",
    "        torch_dataset_val = Dataset(val_dataset)\n",
    "        val_dataloader = DataLoader(torch_dataset_val, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader, val_dataloader, train_dataset, test_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0.0\n",
      "number of patients 2366\n",
      "processing 1.0\n",
      "number of patients 12\n",
      "processing 2.0\n",
      "number of patients 11\n",
      "processing 3.0\n",
      "number of patients 4\n",
      "processing 4.0\n",
      "number of patients 5\n",
      "processing 5.0\n",
      "number of patients 3\n",
      "processing 6.0\n",
      "number of patients 1\n",
      "processing 8.0\n",
      "number of patients 2\n",
      "processing 9.0\n",
      "number of patients 2\n",
      "processing 10.0\n",
      "number of patients 3\n",
      "processing 11.0\n",
      "number of patients 3\n",
      "processing 18.0\n",
      "number of patients 2\n",
      "processing 19.0\n",
      "number of patients 2\n",
      "processing 22.0\n",
      "number of patients 2\n",
      "processing 26.0\n",
      "number of patients 1\n",
      "processing 29.0\n",
      "number of patients 2\n",
      "processing 35.0\n",
      "number of patients 2\n",
      "processing 39.0\n",
      "number of patients 1\n",
      "processing 45.0\n",
      "number of patients 1\n",
      "processing 53.0\n",
      "number of patients 1\n",
      "processing 62.0\n",
      "number of patients 1\n",
      "processing 80.0\n",
      "number of patients 1\n",
      "processing 94.0\n",
      "number of patients 1\n",
      "Test AF: 155.0 Normal: 24905.0 Other: 853.0\n",
      "Train AF: 498.0 Normal: 118092.0 Other: 2360.0\n",
      "Val AF: 176.0 Normal: 25902.0 Other: 713.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_83556\\1040082616.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [70], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_dataloader_safer, test_dataloader_safer, val_dataloader_safer, train_dataset_safer, test_dataset_safer, val_dataset_safer \u001B[38;5;241m=\u001B[39m \u001B[43mmake_SAFER_dataloaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43msafer_pt_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafer_ecg_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_frac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_frac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [69], line 65\u001B[0m, in \u001B[0;36mmake_SAFER_dataloaders\u001B[1;34m(pt_data, ecg_data, test_frac, val_frac, batch_size)\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;66;03m# Normalise\u001B[39;00m\n\u001B[0;32m     64\u001B[0m     train_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m (train_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m-\u001B[39m train_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mmean()))\u001B[38;5;241m/\u001B[39mtrain_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mstd())\n\u001B[1;32m---> 65\u001B[0m     torch_dataset_train \u001B[38;5;241m=\u001B[39m \u001B[43mDataset\u001B[49m(train_dataset)\n\u001B[0;32m     66\u001B[0m     train_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(torch_dataset_train, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, pin_memory\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m test_pt_df\u001B[38;5;241m.\u001B[39mempty:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataloader_safer, test_dataloader_safer, val_dataloader_safer, train_dataset_safer, test_dataset_safer, val_dataset_safer = make_SAFER_dataloaders(safer_pt_data, safer_ecg_data, test_frac=0.15, val_frac=0.15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(dataset, batch_size=32):\n",
    "    torch_dataset = Dataset(dataset)\n",
    "    dataloader = DataLoader(torch_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate on Feas2 and train/test on feas1\n",
    "val_dataset_safer = safer_ecg_data[safer_ecg_data[\"feas\"] == 2]\n",
    "val_dataloader_safer = get_dataloaders(val_dataset_safer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19513\n",
       "2      757\n",
       "1       16\n",
       "Name: class_index, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset_safer[\"class_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make dataloaders for CinC data - separate cpsc as the validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "val_dataset = df[df[\"dataset\"] == \"cpsc_2018\"]\n",
    "train_dataset, test_dataset = train_test_split(df[df[\"dataset\"] != \"cpsc_2018\"], test_size=0.15, stratify=df[df[\"dataset\"] != \"cpsc_2018\"][\"class_index\"])\n",
    "# test_dataset, val_dataset = train_test_split(test_dataset, test_size=0.5, stratify=test_dataset[\"class_index\"])\n",
    "\n",
    "test_dataset = test_dataset[test_dataset[\"measDiag\"] != DiagEnum.Undecided]  # Should just remove any errors in loading the dataset\n",
    "val_dataset = val_dataset[val_dataset[\"measDiag\"] != DiagEnum.Undecided]  # Should just remove any errors in loading the dataset\n",
    "\n",
    "torch_dataset_test = Dataset(test_dataset)\n",
    "test_dataloader = DataLoader(torch_dataset_test, batch_size=128, shuffle=True, pin_memory=True)\n",
    "\n",
    "torch_dataset_val = Dataset(val_dataset)\n",
    "val_dataloader = DataLoader(torch_dataset_val, batch_size=128, shuffle=True, pin_memory=True)\n",
    "\n",
    "torch_dataset_train = Dataset(train_dataset)\n",
    "# torch_dataset_train.temp_warp = 0.2\n",
    "# torch_dataset_train.set_noise_prob(0.1, 0.2, noise_df)\n",
    "train_dataloader = DataLoader(torch_dataset_train, batch_size=128, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    21679\n",
      "2    13033\n",
      "1     2722\n",
      "Name: class_index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[\"class_index\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the proportion of AF samples in the test data to that of the train data\n",
    "\n",
    "val_df_counts = val_dataset[\"class_index\"].value_counts()\n",
    "train_df_counts = train_dataset[\"class_index\"].value_counts()\n",
    "\n",
    "train_not_af = train_df_counts.loc[2] + train_df_counts.loc[0]\n",
    "val_not_af = val_df_counts.loc[2] + val_df_counts.loc[0]\n",
    "\n",
    "val_af_wanted = int(round((train_df_counts.loc[1]/train_not_af) * val_not_af))\n",
    "\n",
    "wanted_af_samples = val_dataset[val_dataset[\"class_index\"] == 1].sample(val_af_wanted)\n",
    "val_dataset = pd.concat([val_dataset[val_dataset[\"class_index\"] != 1], wanted_af_samples])\n",
    "\n",
    "torch_dataset_val = Dataset(val_dataset)\n",
    "val_dataloader = DataLoader(torch_dataset_val, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CinC2017 data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "train_dataset_2017, test_val = train_test_split(cinc2017_df.dropna(subset=\"class_index\"), test_size=test_size + val_size, stratify=cinc2017_df[\"class_index\"].dropna())\n",
    "test_dataset_2017, val_dataset_2017 = train_test_split(test_val, test_size=val_size/(test_size + val_size), stratify=test_val[\"class_index\"])\n",
    "\n",
    "# test_dataset_2017 = test_dataset_2017[test_dataset_2017[\"measDiag\"] != DiagEnum.Undecided]  # Should just remove any errors in loading the dataset\n",
    "\n",
    "torch_dataset_test = Dataset(test_dataset_2017)\n",
    "test_dataloader_2017 = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "torch_dataset_train = Dataset(train_dataset_2017)\n",
    "train_dataloader_2017 = DataLoader(torch_dataset_train, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "torch_dataset_val = Dataset(val_dataset_2017)\n",
    "val_dataloader_2017 = DataLoader(torch_dataset_val, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2585\n",
      "2    1154\n",
      "1     353\n",
      "Name: class_index, dtype: int64\n",
      "0    554\n",
      "2    247\n",
      "1     76\n",
      "Name: class_index, dtype: int64\n",
      "0    555\n",
      "2    248\n",
      "1     75\n",
      "Name: class_index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_2017[\"class_index\"].value_counts())\n",
    "print(test_dataset_2017[\"class_index\"].value_counts())\n",
    "print(val_dataset_2017[\"class_index\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CinC2017 data splits for consistent results!\n",
    "train_dataset_2017.to_pickle(\"TrainedModels/19_May_cinc_2017_train.pk\")\n",
    "test_dataset_2017.to_pickle(\"TrainedModels/19_May_cinc_2017_test.pk\")\n",
    "val_dataset_2017.to_pickle(\"TrainedModels/19_May_cinc_2017_val.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_2017 = pd.read_pickle(\"TrainedModels/19_May_cinc_2017_train.pk\")\n",
    "test_dataset_2017 = pd.read_pickle(\"TrainedModels/19_May_cinc_2017_test.pk\")\n",
    "val_dataset_2017 = pd.read_pickle(\"TrainedModels/19_May_cinc_2017_val.pk\")\n",
    "\n",
    "train_dataloader_2017 = get_dataloaders(train_dataset_2017, 32)\n",
    "test_dataloader_2017 = get_dataloaders(test_dataset_2017, 32)\n",
    "val_dataloader_2017 = get_dataloaders(val_dataset_2017, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use whole CinC2017 as a test\n",
    "dataset_2017 = cinc2017_df[cinc2017_df[\"measDiag\"] != DiagEnum.Undecided].dropna(subset=\"class_index\")\n",
    "\n",
    "torch_dataset = Dataset(dataset_2017)\n",
    "dataloader_2017 = DataLoader(torch_dataset, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    555\n",
       "2    248\n",
       "1     75\n",
       "Name: class_index, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset_2017[\"class_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the noise detector to filter the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter noisy things out of SAFER\n",
    "import Models.NoiseCNN\n",
    "import importlib\n",
    "\n",
    "importlib.reload(Models.NoiseCNN)\n",
    "from Models.NoiseCNN import CNN, hyperparameters\n",
    "\n",
    "noiseDetector = CNN(**hyperparameters).to(device)\n",
    "noiseDetector.load_state_dict(torch.load(\"TrainedModels/CNN_16_may_final_no_undecided.pt\", map_location=device))\n",
    "noiseDetector.eval()\n",
    "\n",
    "def add_noise_predictions(nd, dataloader, dataset):\n",
    "    noise_ps = []\n",
    "    inds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (signals, labels, ind) in enumerate(dataloader):\n",
    "            signal = signals[0].to(device).float()\n",
    "            noise_prob = nd(torch.unsqueeze(signal, 1)).detach().to(\"cpu\").numpy()\n",
    "\n",
    "            for i, n in zip(ind, noise_prob):\n",
    "                if type(i) == str:\n",
    "                    inds.append(i)\n",
    "                else:\n",
    "                    inds.append(i.item())\n",
    "                noise_ps.append(float(n))\n",
    "\n",
    "    if dataset is not None:\n",
    "        dataset[\"noise_probs\"] = pd.Series(data=noise_ps, index=inds)\n",
    "    else:\n",
    "        return pd.Series(data=noise_ps, index=inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise_predictions(noiseDetector, val_dataloader_safer, val_dataset_safer)\n",
    "# add_noise_predictions(noiseDetector, test_dataloader_safer, test_dataset_safer)\n",
    "# add_noise_predictions(noiseDetector, train_dataloader_safer, train_dataset_safer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17861\n"
     ]
    }
   ],
   "source": [
    "# Remove the noisy samples\n",
    "# train_dataset_safer_clean = train_dataset_safer[train_dataset_safer[\"noise_probs\"] < 0]\n",
    "# test_dataset_safer_clean = test_dataset_safer[test_dataset_safer[\"noise_probs\"] < 0]\n",
    "val_dataset_safer_clean = val_dataset_safer[val_dataset_safer[\"noise_probs\"] < 0]\n",
    "\n",
    "# print(len(train_dataset_safer_clean.index))\n",
    "# print(len(test_dataset_safer_clean.index))\n",
    "print(len(val_dataset_safer_clean.index))\n",
    "\n",
    "# train_dataloader_safer_clean = get_dataloaders(train_dataset_safer_clean)\n",
    "# test_dataloader_safer_clean = get_dataloaders(test_dataset_safer_clean)\n",
    "val_dataloader_safer_clean = get_dataloaders(val_dataset_safer_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise_predictions(noiseDetector, train_dataloader_2017, train_dataset_2017)\n",
    "add_noise_predictions(noiseDetector, test_dataloader_2017, test_dataset_2017)\n",
    "add_noise_predictions(noiseDetector, val_dataloader_2017, val_dataset_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2585\n",
      "2    1154\n",
      "1     353\n",
      "Name: class_index, dtype: int64\n",
      "0    554\n",
      "2    247\n",
      "1     76\n",
      "Name: class_index, dtype: int64\n",
      "0    555\n",
      "2    248\n",
      "1     75\n",
      "Name: class_index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_2017[\"class_index\"].value_counts())\n",
    "print(test_dataset_2017[\"class_index\"].value_counts())\n",
    "print(val_dataset_2017[\"class_index\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1955\n",
      "2     857\n",
      "1     255\n",
      "Name: class_index, dtype: int64\n",
      "0    405\n",
      "2    172\n",
      "1     50\n",
      "Name: class_index, dtype: int64\n",
      "0    392\n",
      "2    178\n",
      "1     50\n",
      "Name: class_index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove the noisy samples\n",
    "thresh = 0.3\n",
    "\n",
    "train_dataset_2017_clean = train_dataset_2017[train_dataset_2017[\"noise_probs\"] < 0]\n",
    "test_dataset_2017_clean = test_dataset_2017[test_dataset_2017[\"noise_probs\"] < 0]\n",
    "val_dataset_2017_clean = val_dataset_2017[val_dataset_2017[\"noise_probs\"] < 0]\n",
    "\n",
    "print(train_dataset_2017_clean[\"class_index\"].value_counts())\n",
    "print(test_dataset_2017_clean[\"class_index\"].value_counts())\n",
    "print(val_dataset_2017_clean[\"class_index\"].value_counts())\n",
    "\n",
    "\n",
    "train_dataloader_2017_clean = get_dataloaders(train_dataset_2017_clean)\n",
    "test_dataloader_2017_clean = get_dataloaders(test_dataset_2017_clean)\n",
    "val_dataset_2017_clean = val_dataset_2017[val_dataset_2017[\"noise_probs\"] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class DatasetSequenceIterator:\n",
    "\n",
    "    def __init__(self, data_loading_functions, batch_sizes, filter=lambda x:x):\n",
    "        self.dl_functions = data_loading_functions\n",
    "\n",
    "        self.dataset = None\n",
    "        self.next_dataset = None\n",
    "\n",
    "        self.dataloader_iterator = None\n",
    "        self.next_dataloader_iterator = None\n",
    "\n",
    "        self.next_dataset_loaded = False\n",
    "        self.dataloader_thread = None\n",
    "\n",
    "        self.filter = filter\n",
    "\n",
    "        self.batch_sizes = batch_sizes\n",
    "        self.dl_index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.dl_index = -1\n",
    "        self.dataloader_thread = threading.Thread(target=self.load_next_dataset)\n",
    "        self.dataloader_thread.start()\n",
    "        self.dataloader_thread.join()\n",
    "        self.swap_to_next_dataset()\n",
    "        self.dl_index += 1\n",
    "        self.dataloader_thread = threading.Thread(target=self.load_next_dataset)\n",
    "        self.dataloader_thread.start()\n",
    "        print(self.dl_index)\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO make this return the right value\n",
    "        return 100\n",
    "\n",
    "    def swap_to_next_dataset(self):\n",
    "        self.dataset = self.next_dataset\n",
    "        self.dataloader_iterator = self.next_dataloader_iterator\n",
    "        self.next_dataset_loaded = False\n",
    "\n",
    "    def load_next_dataset(self):\n",
    "        if self.dl_index + 1 < len(self.dl_functions):\n",
    "            print(f\"Loading dataset {self.dl_index + 1}\")\n",
    "            self.next_dataset = self.dl_functions[self.dl_index + 1]()\n",
    "            self.next_dataset = self.filter(self.next_dataset)\n",
    "\n",
    "            torch_dataset = Dataset(self.next_dataset)\n",
    "            self.next_dataloader_iterator = iter(DataLoader(torch_dataset, batch_size=self.batch_sizes[self.dl_index], shuffle=True, pin_memory=True))\n",
    "            self.next_dataset_loaded = True\n",
    "        else:\n",
    "            print(\"Finished loading all datasets\")\n",
    "            self.next_dataset_loaded = False\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            ret = next(self.dataloader_iterator)\n",
    "        except StopIteration:\n",
    "            print(\"stop_iteration\")\n",
    "            if self.dl_index >= len(self.dl_functions):\n",
    "                # We have gone through all the datasets\n",
    "                print(\"Completed all datasets\")\n",
    "                raise StopIteration\n",
    "            else:\n",
    "\n",
    "                if not self.next_dataset_loaded:\n",
    "                    print(\"waiting_for_next_dataset\")\n",
    "                    self.dataloader_thread.join()\n",
    "\n",
    "                self.swap_to_next_dataset()\n",
    "                self.dl_index += 1\n",
    "                self.dataloader_thread = threading.Thread(target=self.load_next_dataset)\n",
    "                self.dataloader_thread.start()\n",
    "                ret = next(self.dataloader_iterator)\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the DatasetSequenceIterator by dividing feas1 into two parts\n",
    "\n",
    "def load_feas1_first_half():\n",
    "    ecg_data, pt_data = load_feas1_chunk_range((0, 1))\n",
    "    return prepare_safer_data(pt_data, ecg_data)[1]\n",
    "\n",
    "def load_feas1_second_half():\n",
    "    ecg_data, pt_data = load_feas1_chunk_range((4, 5))\n",
    "    return prepare_safer_data(pt_data, ecg_data)[1]\n",
    "\n",
    "def load_feas1_nth_chuck(n):\n",
    "    ecg_data, pt_data = load_feas1_chunk_range((n, n+1))\n",
    "    ecg_data.index = ecg_data[\"measID\"]\n",
    "    pt_data.index = pt_data[\"ptID\"]\n",
    "    return prepare_safer_data(pt_data, ecg_data)[1]\n",
    "\n",
    "loading_functions = [lambda n=n: load_feas1_nth_chuck(n) for n in range(num_chunks)]\n",
    "\n",
    "feas1_dataloader_entire = DatasetSequenceIterator(loading_functions, [128 for n in range(num_chunks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset 0\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_0.pk.pk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10 (load_next_dataset):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\daniel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_18972\\2813032984.py\", line 47, in load_next_dataset\n",
      "  File \"C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_18972\\2109776680.py\", line 6, in filter_train_pts\n",
      "NameError: name 'train_pts' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering 2967 ECGs out\n",
      "   ptID   age         ptDiag          ptDiagRev1          ptDiagRev2  \\\n",
      "0     1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "1     1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "2     1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "3     1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "4     1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "\n",
      "           ptDiagRev3  cardRev            measDiag        measDiagRev1  \\\n",
      "0  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "1  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "2  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "3  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "4  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
      "\n",
      "         measDiagRev2  ...                                               data  \\\n",
      "0  DiagEnum.Undecided  ...  [-0.2662027385359386, -0.30664578332807735, -0...   \n",
      "1  DiagEnum.Undecided  ...  [-0.2472898417342083, -0.35996621105942916, -0...   \n",
      "2  DiagEnum.Undecided  ...  [-0.12187294470354347, -0.2163261498947629, -0...   \n",
      "3  DiagEnum.Undecided  ...  [-0.05252154229922338, -0.16537173569464994, -...   \n",
      "4  DiagEnum.Undecided  ...  [-0.5590172346386594, -0.7189315563426425, -0....   \n",
      "\n",
      "  adc_gain                   file_path class_index  length  \\\n",
      "0  0.61458  ECGs/000000/saferF1_000001           0    9120   \n",
      "1  0.10008  ECGs/000000/saferF1_000002           0    9120   \n",
      "2  0.22967  ECGs/000000/saferF1_000003           0    9120   \n",
      "3  0.53907  ECGs/000000/saferF1_000004           0    9120   \n",
      "4  0.12386  ECGs/000000/saferF1_000005           0    9120   \n",
      "\n",
      "                                             r_peaks  heartrate  \\\n",
      "0  [97, 315, 534, 754, 974, 1192, 1408, 1625, 184...  80.921053   \n",
      "1  [305, 542, 776, 1007, 1240, 1475, 1709, 1948, ...  78.947368   \n",
      "2  [165, 389, 611, 830, 1049, 1270, 1497, 1732, 1...  76.973684   \n",
      "3  [163, 376, 592, 806, 1019, 1234, 1451, 1672, 1...  82.894737   \n",
      "4  [238, 479, 716, 962, 1208, 1463, 1720, 1965, 2...  73.026316   \n",
      "\n",
      "                                         rri_feature  rri_len  feas  \n",
      "0  [0.73, 0.7333333333333332, 0.7333333333333334,...       38     1  \n",
      "1  [0.7799999999999998, 0.77, 0.7766666666666673,...       37     1  \n",
      "2  [0.74, 0.73, 0.73, 0.7366666666666668, 0.75666...       36     1  \n",
      "3  [0.72, 0.7133333333333332, 0.71, 0.71666666666...       39     1  \n",
      "4  [0.79, 0.8199999999999998, 0.8199999999999998,...       34     1  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "568     -1.095473\n",
      "12643   -0.943967\n",
      "7036    -0.762686\n",
      "10987   -1.010029\n",
      "8388    -0.976872\n",
      "dtype: float64\n",
      "Loading dataset 1\n",
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [49], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m num_ecgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (signals, labels, _) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(feas1_train_dataloader):\n\u001B[0;32m      3\u001B[0m     signal \u001B[38;5;241m=\u001B[39m signals[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[0;32m      4\u001B[0m     rris \u001B[38;5;241m=\u001B[39m signals[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat()\n",
      "Cell \u001B[1;32mIn [40], line 61\u001B[0m, in \u001B[0;36mDatasetSequenceIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 61\u001B[0m         ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m     63\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop_iteration\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not an iterator"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_1.pk.pk\n"
     ]
    }
   ],
   "source": [
    "num_ecgs = 0\n",
    "for i, (signals, labels, _) in enumerate(feas1_train_dataloader):\n",
    "    signal = signals[0].to(device).float()\n",
    "    rris = signals[1].to(device).float()\n",
    "    rri_len = signals[2].to(device).float()\n",
    "\n",
    "    num_ecgs += signal.shape[0]\n",
    "\n",
    "print(num_ecgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_data = SAFERDataset.load_pt_dataset(1)\n",
    "ecg_data = SAFERDataset.load_ecg_csv(1, pt_data, ecg_range=None, ecg_meas_diag=None, feas2_offset=10000, feas2_ecg_offset=200000)\n",
    "\n",
    "ecg_data[\"feas\"] = 1\n",
    "ecg_data[\"length\"] = 9120\n",
    "ecg_data[\"rri_len\"] = 20\n",
    "\n",
    "pt_data, ecg_data = prepare_safer_data(pt_data, ecg_data)\n",
    "# train_pts, test_pts, val_pts = generate_patient_splits(pt_data, 0.15, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset 0\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_0.pk.pk\n",
      "Loading dataset 10\n",
      "\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_1.pk.pk\n",
      "stop_iteration\n",
      "waiting_for_next_dataset\n",
      "Loading dataset 2\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_2.pk.pk\n",
      "stop_iteration\n",
      "waiting_for_next_dataset\n",
      "Loading dataset 3\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_3.pk.pk\n",
      "stop_iteration\n",
      "waiting_for_next_dataset\n",
      "Loading dataset 4\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_4.pk.pk\n",
      "stop_iteration\n",
      "waiting_for_next_dataset\n",
      "Loading dataset 5\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_5.pk.pk\n",
      "stop_iteration\n",
      "waiting_for_next_dataset\n",
      "Loading dataset 6\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_6.pk.pk\n",
      "stop_iteration\n",
      "waiting_for_next_dataset\n",
      "Loading dataset 7\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_7.pk.pk\n",
      "stop_iteration\n",
      "waiting_for_next_dataset\n",
      "Loading dataset 8\n",
      "D:\\2022_23_DSiromani\\Feas1\\ECGs/filtered_dataframe_8.pk.pk\n",
      "stop_iteration\n",
      "Finished loading all datasets\n",
      "stop_iteration\n",
      "waiting_for_next_dataset\n",
      "Finished loading all datasets\n"
     ]
    }
   ],
   "source": [
    "feas1_noise_predictions = add_noise_predictions(noiseDetector, feas1_dataloader_entire, ecg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data[\"noise_prediction\"] = ecg_data[\"noise_probs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5860\n",
       "False    4345\n",
       "Name: noise_prediction, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_data.dropna(subset=[\"noise_prediction\"])\n",
    "(ecg_data[ecg_data['poss_AF_tag'] == 1][\"noise_prediction\"] < 0).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"number of noisy ECGs: {(feas1_noise_predictions > 0).sum()}\")\n",
    "feas1_path = r\"D:\\2022_23_DSiromani\\Feas1\"\n",
    "feas1_noise_predictions.to_pickle(os.path.join(feas1_path, \"ECGs/feas1_noise_predictions.pk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_path = r\"D:\\2022_23_DSiromani\\Feas1\"\n",
    "feas1_noise_predictions = pd.read_pickle(os.path.join(feas1_path, \"ECGs/feas1_noise_predictions.pk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[18614   496     0]\n",
      " [   21    77     0]\n",
      " [  260   206     0]]\n",
      "Sensitivity: 0.786\n",
      "Specificity: 0.964\n",
      "\n",
      "Normal F1: 0.980\n",
      "AF F1: 0.176\n",
      "Other F1: 0.000\n"
     ]
    }
   ],
   "source": [
    "zenicor_conf_mat = confusion_matrix(feas1_ecg_data_test[\"class_index\"], feas1_ecg_data_test[\"poss_AF_tag\"])\n",
    "print_results(zenicor_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    122688\n",
      "2      2355\n",
      "1       470\n",
      "Name: class_index, dtype: int64\n",
      "0    149586\n",
      "2      3120\n",
      "1       745\n",
      "Name: class_index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ecg_data[\"noise_prediction\"] = feas1_noise_predictions\n",
    "print(ecg_data[ecg_data[\"noise_prediction\"] < 0][\"class_index\"].value_counts())\n",
    "print(ecg_data[\"class_index\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_pts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [26], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m feas1_train_data \u001B[38;5;241m=\u001B[39m ecg_data[ecg_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mptID\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39misin(\u001B[43mtrain_pts\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mptID\u001B[39m\u001B[38;5;124m\"\u001B[39m])]\n\u001B[0;32m      2\u001B[0m feas1_train_data_clean \u001B[38;5;241m=\u001B[39m feas1_train_data[feas1_train_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnoise_prediction\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_pts' is not defined"
     ]
    }
   ],
   "source": [
    "feas1_train_data = ecg_data[ecg_data[\"ptID\"].isin(train_pts[\"ptID\"])]\n",
    "feas1_train_data_clean = feas1_train_data[feas1_train_data[\"noise_prediction\"] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105156.0\n",
      "567.0\n",
      "2207.0\n",
      "\n",
      "22464.0\n",
      "134.0\n",
      "562.0\n",
      "\n",
      "21966.0\n",
      "121.0\n",
      "410.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pts in [train_pts, test_pts, val_pts]:\n",
    "    print(pts[\"noNormalRecs\"].sum())\n",
    "    print(pts[\"noAFRecs\"].sum())\n",
    "    print(pts[\"noOtherRecs\"].sum())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_path = r\"D:\\2022_23_DSiromani\\Feas1\"\n",
    "train_pts.to_pickle(os.path.join(feas1_path, \"all_feas1_train_pts_27_may.pk\"))\n",
    "test_pts.to_pickle(os.path.join(feas1_path, \"all_feas1_test_pts_27_may.pk\"))\n",
    "val_pts.to_pickle(os.path.join(feas1_path, \"all_feas1_val_pts_27_may.pk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_path = r\"D:\\2022_23_DSiromani\\Feas1\"\n",
    "train_pts = pd.read_pickle(os.path.join(feas1_path, \"all_feas1_train_pts_27_may.pk\"))\n",
    "test_pts = pd.read_pickle(os.path.join(feas1_path, \"all_feas1_test_pts_27_may.pk\"))\n",
    "val_pts = pd.read_pickle(os.path.join(feas1_path, \"all_feas1_val_pts_27_may.pk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_ecg_data_test = pd.read_pickle(os.path.join(feas1_path, \"ECGs/feas1_test_27_mar.pk\"))\n",
    "feas1_ecg_data_test = feas1_ecg_data_test[feas1_ecg_data_test[\"rri_len\"] > 5]\n",
    "\n",
    "feas1_ecg_data_val = pd.read_pickle(os.path.join(feas1_path, \"ECGs/feas1_val_27_mar.pk\"))\n",
    "feas1_ecg_data_val = feas1_ecg_data_val[feas1_ecg_data_val[\"rri_len\"] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_ecg_data_test[\"noise_prediction\"] = feas1_noise_predictions\n",
    "feas1_ecg_data_test_clean = feas1_ecg_data_test[feas1_ecg_data_test[\"noise_prediction\"] < 0]\n",
    "\n",
    "feas1_ecg_data_val[\"noise_prediction\"] = feas1_noise_predictions\n",
    "feas1_ecg_data_val_clean = feas1_ecg_data_val[feas1_ecg_data_val[\"noise_prediction\"] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3711\n",
       "2      61\n",
       "1      36\n",
       "Name: class_index, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feas1_ecg_data_val[\"class_index\"].value_counts() - feas1_ecg_data_val_clean[\"class_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexingError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [179], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mecg_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeas1_noise_predictions\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\frame.py:3796\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3794\u001B[0m \u001B[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001B[39;00m\n\u001B[0;32m   3795\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m com\u001B[38;5;241m.\u001B[39mis_bool_indexer(key):\n\u001B[1;32m-> 3796\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_bool_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3798\u001B[0m \u001B[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001B[39;00m\n\u001B[0;32m   3799\u001B[0m \u001B[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001B[39;00m\n\u001B[0;32m   3800\u001B[0m is_single_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_list_like(key)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\frame.py:3849\u001B[0m, in \u001B[0;36mDataFrame._getitem_bool_array\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3843\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3844\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mItem wrong length \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(key)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m instead of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3845\u001B[0m     )\n\u001B[0;32m   3847\u001B[0m \u001B[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001B[39;00m\n\u001B[0;32m   3848\u001B[0m \u001B[38;5;66;03m# be reindexed to match DataFrame rows\u001B[39;00m\n\u001B[1;32m-> 3849\u001B[0m key \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_bool_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3850\u001B[0m indexer \u001B[38;5;241m=\u001B[39m key\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   3851\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_take_with_is_copy(indexer, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\indexing.py:2548\u001B[0m, in \u001B[0;36mcheck_bool_indexer\u001B[1;34m(index, key)\u001B[0m\n\u001B[0;32m   2546\u001B[0m indexer \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_indexer_for(index)\n\u001B[0;32m   2547\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01min\u001B[39;00m indexer:\n\u001B[1;32m-> 2548\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m IndexingError(\n\u001B[0;32m   2549\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnalignable boolean Series provided as \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2550\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindexer (index of the boolean Series and of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2551\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe indexed object do not match).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2552\u001B[0m     )\n\u001B[0;32m   2554\u001B[0m result \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   2556\u001B[0m \u001B[38;5;66;03m# fall through for boolean\u001B[39;00m\n",
      "\u001B[1;31mIndexingError\u001B[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "ecg_data[(feas1_noise_predictions[ecg_data.index] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some a filter function to select data from each partition\n",
    "def filter_train_pts(ecg_data):\n",
    "    print(f\"filtering {(feas1_noise_predictions[ecg_data.index] > 0).sum()} ECGs out\")\n",
    "    print(ecg_data.head())\n",
    "    print(feas1_noise_predictions.head())\n",
    "    return ecg_data[(ecg_data[\"ptID\"].isin(train_pts[\"ptID\"])) & (feas1_noise_predictions[ecg_data.index] < 0)]\n",
    "\n",
    "def filter_test_pts(ecg_data):\n",
    "    return ecg_data[ecg_data[\"ptID\"].isin(test_pts[\"ptID\"]) & (feas1_noise_predictions[ecg_data.index] < 0)]\n",
    "\n",
    "def filter_val_pts(ecg_data):\n",
    "    return ecg_data[ecg_data[\"ptID\"].isin(test_pts[\"ptID\"]) & (feas1_noise_predictions[ecg_data.index] < 0)]\n",
    "\n",
    "feas1_train_dataloader = DatasetSequenceIterator(loading_functions, [64 for n in range(num_chunks)], filter=filter_train_pts)\n",
    "feas1_test_dataloader = get_dataloaders(feas1_ecg_data_test)\n",
    "feas1_val_dataloader = get_dataloaders(feas1_ecg_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feas1_ecg_data_test_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [48], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m feas1_test_dataloader_clean \u001B[38;5;241m=\u001B[39m get_dataloaders(\u001B[43mfeas1_ecg_data_test_clean\u001B[49m)\n\u001B[0;32m      2\u001B[0m feas1_val_dataloader_clean \u001B[38;5;241m=\u001B[39m get_dataloaders(feas1_ecg_data_val_clean)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'feas1_ecg_data_test_clean' is not defined"
     ]
    }
   ],
   "source": [
    "feas1_test_dataloader_clean = get_dataloaders(feas1_ecg_data_test_clean)\n",
    "feas1_val_dataloader_clean = get_dataloaders(feas1_ecg_data_val_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    19247\n",
      "2      325\n",
      "1       60\n",
      "Name: class_index, dtype: int64\n",
      "0    19151\n",
      "2      391\n",
      "1       90\n",
      "Name: class_index, dtype: int64\n",
      "  \n",
      "0    22274\n",
      "2      377\n",
      "1      102\n",
      "Name: class_index, dtype: int64\n",
      "0    22862\n",
      "2      452\n",
      "1      126\n",
      "Name: class_index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(feas1_ecg_data_test_clean[\"class_index\"].value_counts())\n",
    "print(feas1_ecg_data_val_clean[\"class_index\"].value_counts())\n",
    "\n",
    "print(\"  \")\n",
    "\n",
    "print(feas1_ecg_data_test[\"class_index\"].value_counts())\n",
    "print(feas1_ecg_data_val[\"class_index\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5522"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del feas1_train_dataloader\n",
    "del feas1_test_dataloader\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Models.SpectrogramTransformer\n",
    "importlib.reload(Models.SpectrogramTransformer)\n",
    "# from Models.SpectrogramTransformer import TransformerModel\n",
    "import Models.SpectrogramTransformerAttentionPooling\n",
    "importlib.reload(Models.SpectrogramTransformerAttentionPooling)\n",
    "from Models.SpectrogramTransformerAttentionPooling import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, LambdaLR, SequentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18)\n"
     ]
    }
   ],
   "source": [
    "n_head = 4\n",
    "n_fft = 128\n",
    "embed_dim = 128 # int(n_fft/2)\n",
    "n_inp_rri = 64\n",
    "\n",
    "model = TransformerModel(3, embed_dim, n_head, 512, 6, n_fft, n_inp_rri, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class focal_loss(nn.Module):\n",
    "\n",
    "    def __init__(self, weights, gamma=2, label_smoothing=0):\n",
    "        super(focal_loss, self).__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction=\"none\", label_smoothing=label_smoothing)\n",
    "        self.weights = weights\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, pred, targets):\n",
    "        ce = self.ce_loss(pred, targets)\n",
    "        pt = torch.exp(-ce)\n",
    "\n",
    "        loss_sum = torch.sum(((1-pt) ** self.gamma) * ce * self.weights[targets])\n",
    "        norm_factor = torch.sum(self.weights[targets])\n",
    "        return loss_sum/norm_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup(current_step: int):\n",
    "    if current_step < number_warmup_batches:\n",
    "        # print(current_step / number_warmup_batches ** 1.5)\n",
    "        return current_step / number_warmup_batches ** 1.5\n",
    "    else:\n",
    "        # print(1/math.sqrt(current_step))\n",
    "        return 1/math.sqrt(current_step)  # 1 / (10 ** (float(number_warmup_epochs - current_step)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [25], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m class_counts \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43mtrain_dataset\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass_index\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue_counts()\u001B[38;5;241m.\u001B[39msort_index()\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32))\n\u001B[0;32m      2\u001B[0m class_weights \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39mclass_counts)\n\u001B[0;32m      3\u001B[0m class_weights \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(class_weights)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class_counts = torch.tensor(train_dataset[\"class_index\"].value_counts().sort_index().values.astype(np.float32))\n",
    "class_weights = (1/class_counts)\n",
    "class_weights /= torch.sum(class_weights)\n",
    "print(class_weights)\n",
    "\n",
    "loss_func = focal_loss(class_weights, 2) # nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1) # focal_loss(class_weights, 2, 0.05) #\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "number_warmup_batches = 600\n",
    "def warmup(current_step: int):\n",
    "    if current_step < number_warmup_batches:\n",
    "        # print(current_step / number_warmup_batches ** 1.5)\n",
    "        return current_step / number_warmup_batches ** 1.5\n",
    "    else:\n",
    "        # print(1/math.sqrt(current_step))\n",
    "        return 1/math.sqrt(current_step)  # 1 / (10 ** (float(number_warmup_epochs - current_step)))\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=warmup)\n",
    "# scheduler = SequentialLR(optimizer, [warmup_scheduler, scheduler], [number_warmup_epochs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feas1_ecg_data_train_undersamp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [270], line 21\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;03m# Use all of feas1 to compute the class counts - precomputed values for next time: tensor([0.0043, 0.7924, 0.2033])\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124;03mclass_counts = torch.tensor(feas1_ecg_data[\"class_index\"].value_counts().sort_index().values.astype(np.float32))\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03mclass_weights /= torch.sum(class_weights)\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# class_counts = torch.tensor(ecg_data[ecg_data[\"noise_prediction\"] < 0][\"class_index\"].value_counts().sort_index().values.astype(np.float32))\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m class_counts \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43mfeas1_ecg_data_train_undersamp\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass_index\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue_counts()\u001B[38;5;241m.\u001B[39msort_index()\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32))\n\u001B[0;32m     22\u001B[0m class_weights \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39mclass_counts)\n\u001B[0;32m     23\u001B[0m class_weights \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(class_weights)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'feas1_ecg_data_train_undersamp' is not defined"
     ]
    }
   ],
   "source": [
    "# Remake scheduler before retraining on SAFER\n",
    "\n",
    "\"\"\"\n",
    "class_counts = torch.tensor(train_dataset_safer_clean[\"class_index\"].value_counts().sort_index().values.astype(np.float32))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# just approximate weights using feas2 rather than computing for feas 1 - these might be fundamentally different because in feas2 the cardiologist stopped labelling after the first AF from a patient therefore fewer AF.\n",
    "class_counts = torch.tensor(val_dataset_safer[\"class_index\"].value_counts().sort_index().values.astype(np.float32))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Use all of feas1 to compute the class counts - precomputed values for next time: tensor([0.0043, 0.7924, 0.2033])\n",
    "class_counts = torch.tensor(feas1_ecg_data[\"class_index\"].value_counts().sort_index().values.astype(np.float32))\n",
    "\n",
    "class_weights = (1/class_counts)\n",
    "class_weights /= torch.sum(class_weights)\n",
    "\"\"\"\n",
    "\n",
    "# class_counts = torch.tensor(ecg_data[ecg_data[\"noise_prediction\"] < 0][\"class_index\"].value_counts().sort_index().values.astype(np.float32))\n",
    "class_counts = torch.tensor(feas1_ecg_data_train_undersamp[\"class_index\"].value_counts().sort_index().values.astype(np.float32))\n",
    "class_weights = (1/class_counts)\n",
    "class_weights /= torch.sum(class_weights)\n",
    "\n",
    "# class_weights = torch.tensor([0.0043, 0.7924, 0.2033])\n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "loss_func = focal_loss(class_weights, gamma=2, label_smoothing=0)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "number_warmup_batches = 600\n",
    "def warmup(current_step: int):\n",
    "    if current_step < number_warmup_batches:\n",
    "        # print(current_step / number_warmup_batches ** 1.5)\n",
    "        return current_step / number_warmup_batches ** 1.5\n",
    "    else:\n",
    "        # print(1/math.sqrt(current_step))\n",
    "        return 1/math.sqrt(current_step)  # 1 / (10 ** (float(number_warmup_epochs - current_step)))\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0947, 0.6933, 0.2121])\n"
     ]
    }
   ],
   "source": [
    "# Remake scheduler before retraining on CinC2017\n",
    "\n",
    "class_counts = torch.tensor(train_dataset_2017[\"class_index\"].value_counts().sort_index().values.astype(np.float32))\n",
    "class_weights = (1/class_counts)\n",
    "class_weights /= torch.sum(class_weights)\n",
    "print(class_weights)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(weight=class_weights) # multiclass_cross_entropy_loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00004)\n",
    "\n",
    "number_warmup_batches = 600\n",
    "def warmup(current_step: int):\n",
    "    if current_step < number_warmup_batches:\n",
    "        # print(current_step / number_warmup_batches ** 1.5)\n",
    "        return current_step / number_warmup_batches ** 1.5\n",
    "    else:\n",
    "        # print(1/math.sqrt(current_step))\n",
    "        return 1/math.sqrt(current_step)  # 1 / (10 ** (float(number_warmup_epochs - current_step)))\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1427, 0.7559, 0.1014])\n"
     ]
    }
   ],
   "source": [
    "# Train the model I stole\n",
    "\n",
    "import OtherModels.Prna.physionet2020_submission.model\n",
    "importlib.reload(OtherModels.Prna.physionet2020_submission.model)\n",
    "from OtherModels.Prna.physionet2020_submission.model import CTN\n",
    "import OtherModels.Prna.physionet2020_submission.optimizer\n",
    "importlib.reload(OtherModels.Prna.physionet2020_submission.optimizer)\n",
    "from OtherModels.Prna.physionet2020_submission.optimizer import NoamOpt\n",
    "\n",
    "# Train prna's transformer\n",
    "n_head = 8\n",
    "n_fft = 128\n",
    "embed_dim = 128 # int(n_fft/2)\n",
    "n_inp_rri = 64\n",
    "\n",
    "class_counts = torch.tensor(train_dataset[\"class_index\"].value_counts().sort_index().values.astype(np.float32))\n",
    "class_weights = (1/class_counts)\n",
    "class_weights /= torch.sum(class_weights)\n",
    "print(class_weights)\n",
    "\n",
    "model = CTN(256, n_head, 2048, 4, 0.1, 64, 0, 0, 3).to(device)\n",
    "\n",
    "# Initialize parameters with Glorot / fan_avg.\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "# optimizer = NoamOpt(256, 1, 4000, torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "loss_func = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "number_warmup_batches = 2\n",
    "def warmup(current_step: int):\n",
    "    return 1 / (10 ** (float(number_warmup_batches - current_step)))\n",
    "warmup_scheduler = LambdaLR(optimizer, lr_lambda=warmup)\n",
    "\n",
    "scheduler = SequentialLR(optimizer, [warmup_scheduler, scheduler], [number_warmup_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, tensorboard_trace_handler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "model = model.to(device)\n",
    "model.fix_transformer_params(fix_spec=False, fix_rri=False)\n",
    "num_epochs = 40\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader):\n",
    "    best_test_loss = 100\n",
    "    best_epoch = -1\n",
    "    best_model = copy.deepcopy(model).cpu()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        print(f\"starting epoch {epoch} ...\")\n",
    "        # Train\n",
    "        num_batches = 0\n",
    "        model.train()\n",
    "        for i, (signals, labels, _) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            signal = signals[0].to(device).float()\n",
    "            rris = signals[1].to(device).float()\n",
    "            rri_len = signals[2].to(device).float()\n",
    "\n",
    "            if torch.any(torch.isnan(signal)):\n",
    "                print(\"Signals are nan\")\n",
    "                continue\n",
    "\n",
    "            if torch.any(torch.isnan(rris)):\n",
    "                print(\"Signals are nan\")\n",
    "                continue\n",
    "\n",
    "            labels = labels.long()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(signal, rris, rri_len).to(\"cpu\")\n",
    "\n",
    "            if torch.any(torch.isnan(output)):\n",
    "                print(signal)\n",
    "                print(rris)\n",
    "                print(rri_len)\n",
    "                print(output)\n",
    "                raise ValueError\n",
    "\n",
    "            loss = loss_func(output, labels)\n",
    "            if torch.isnan(loss):\n",
    "                raise ValueError\n",
    "            loss.backward()\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            num_batches += 1\n",
    "            total_loss += float(loss)\n",
    "\n",
    "        print(num_batches)\n",
    "\n",
    "        print(f\"Epoch {epoch} finished with average loss {total_loss/num_batches}\")\n",
    "        # writer.add_scalar(\"Loss/train\", total_loss/num_batches, epoch)\n",
    "        print(\"Testing ...\")\n",
    "        # Test\n",
    "        num_test_batches = 0\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, (signals, labels, _) in enumerate(test_dataloader):\n",
    "                signal = signals[0].to(device).float()\n",
    "                rris = signals[1].to(device).float()\n",
    "                rri_len = signals[2].to(device).float()\n",
    "\n",
    "                if torch.any(torch.isnan(signal)):\n",
    "                    print(\"Signals are nan\")\n",
    "                    continue\n",
    "\n",
    "                labels = labels.long()\n",
    "                output = model(signal, rris, rri_len).to(\"cpu\")\n",
    "                loss = loss_func(output, labels)\n",
    "                test_loss += float(loss)\n",
    "                num_test_batches += 1\n",
    "\n",
    "        print(f\"Average test loss: {test_loss/num_test_batches}\")\n",
    "        losses.append([total_loss/num_batches, test_loss/num_test_batches])\n",
    "        # writer.add_scalar(\"Loss/test\", test_loss/num_t est_batches, epoch)\n",
    "\n",
    "        if test_loss/num_test_batches < best_test_loss:\n",
    "            best_model = copy.deepcopy(model).cpu()\n",
    "            best_test_loss = test_loss/num_test_batches\n",
    "            best_epoch = epoch\n",
    "        else:\n",
    "            if best_epoch + 5 <= epoch:\n",
    "                return best_model, losses\n",
    "\n",
    "    return best_model, losses\n",
    "\n",
    "model, losses = train(model, feas1_train_dataloader_undersamp, feas1_test_dataloader_undersamp)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.load(\"TrainedModels/Transformer_23_May_cinc_train_attention_pooling_no_augmentation_smoothing_training_curve.npy\")\n",
    "\n",
    "# \"C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\TrainedModels\\Transformer_23_May_feas1_train_attention_pooling_augmentation_smoothing_retrain.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training curve (1 axis only)\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "train_l = ax.plot([l[0] for l in losses], label=\"training loss\")\n",
    "val_l = ax.plot([l[1] for l in losses], label=\"validation loss\", color=\"#ff7f0e\")\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.set_ylim(bottom=0)\n",
    "ax.set_xlim(left=0)\n",
    "\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_np = np.array(losses)\n",
    "np.save(\"TrainedModels/Transformer_24_May_cinc_2017_train_attention_pooling_augmentation_smoothing\", losses_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "torch.save(model.state_dict(), \"TrainedModels/Transformer_24_May_cinc_2017_train_attention_pooling_augmentation_smoothing.pt\")\n",
    "\n",
    "# train_dataset_safer.to_pickle(\"TrainedModels/Transformer_15_Mar_train.pk\")\n",
    "# test_dataset_safer.to_pickle(\"TrainedModels/Transformer_15_Mar_test.pk\")\n",
    "# val_dataset_safer.to_pickle(\"TrainedModels/Transformer_15_Mar_val.pk\")\n",
    "# train_pt_df.to_pickle(\"TrainedModels/Transformer_spectrogram_small_fft_cut_all_safer_trained_average_warped_train.pk\")\n",
    "# val_pt_df.to_pickle(\"TrainedModels/Transformer_spectrogram_small_fft_cut_all_safer_trained_average_warped_val.pk\")\n",
    "# test_pt_df.to_pickle(\"TrainedModels/Transformer_spectrogram_small_fft_cut_all_safer_trained_average_warped_test.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_pickle(\"TrainedModels/Transformer_13_May_cinc_trained_initial_train.pk\")\n",
    "test_dataset.to_pickle(\"TrainedModels/Transformer_13_May_cinc_trained_initial_test.pk\")\n",
    "val_dataset.to_pickle(\"TrainedModels/Transformer_13_May_cinc_trained_initial_val.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_safer = pd.read_pickle(\"TrainedModels/Transformer_13_Mar_train.pk\")\n",
    "test_dataset_safer = pd.read_pickle(\"TrainedModels/Transformer_13_Mar_test.pk\")\n",
    "val_dataset_safer = pd.read_pickle(\"TrainedModels/Transformer_13_Mar_val.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_safer = get_dataloaders(train_dataset_safer)\n",
    "test_dataloader_safer = get_dataloaders(test_dataset_safer)\n",
    "val_dataloader_safer = get_dataloaders(val_dataset_safer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_2017.to_pickle(\"TrainedModels/Transformer_13_May_cinc_2017_trained_train.pk\")\n",
    "test_dataset_2017.to_pickle(\"TrainedModels/Transformer_13_May_cinc_2017_trained_test.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this for safer cross validation later\n",
    "cinc_model_path = \"TrainedModels/Transformer_15_Mar_cinc_trained_noise_augmentation.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model\n",
    "# model = TransformerModel(2, embed_dim, n_head, 1024, 4, 47, n_fft).to(device)\n",
    "model.load_state_dict(torch.load(\"TrainedModels/Transformer_27_may_feas1_train_attention_pooling_augmentation_smoothing_nk_beats_retrain.pt\", map_location=device))\n",
    "\n",
    "# train_pt_df = pd.read_pickle(\"TrainedModels/Transformer_spectrogram_small_fft_cut_all_safer_trained_average_warped_train.pk\")\n",
    "# val_pt_df = pd.read_pickle(\"TrainedModels/Transformer_spectrogram_small_fft_cut_all_safer_trained_average_warped_val.pk\")\n",
    "# test_pt_df = pd.read_pickle(\"TrainedModels/Transformer_spectrogram_small_fft_cut_all_safer_trained_average_warped_test.pk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_pt_df = pd.read_pickle(\"TrainedModels/Transformer_13_May_cinc_2017_trained_train.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptID</th>\n",
       "      <th>age</th>\n",
       "      <th>ptDiag</th>\n",
       "      <th>ptDiagRev1</th>\n",
       "      <th>ptDiagRev2</th>\n",
       "      <th>ptDiagRev3</th>\n",
       "      <th>cardRev</th>\n",
       "      <th>noRecs</th>\n",
       "      <th>noHQrecs</th>\n",
       "      <th>noRecsPossAF</th>\n",
       "      <th>feas</th>\n",
       "      <th>noNormalRecs</th>\n",
       "      <th>noAFRecs</th>\n",
       "      <th>noOtherRecs</th>\n",
       "      <th>pt_prediction_af</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>91</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>2137</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>2138</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>2139</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>2140</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>2141</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2141 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ptID   age  ptDiag  ptDiagRev1  ptDiagRev2  ptDiagRev3  cardRev  noRecs  \\\n",
       "ptID                                                                            \n",
       "1        1  71.0       4           6           6           6        0     118   \n",
       "2        2  71.0       4           6           6           6        0     117   \n",
       "3        3  75.0       4           6           6           6        0      30   \n",
       "4        4  73.0       4           6           6           6        0      59   \n",
       "5        5  70.0       4           6           6           6        0     118   \n",
       "...    ...   ...     ...         ...         ...         ...      ...     ...   \n",
       "2137  2137  72.0       4           6           6           6        0      95   \n",
       "2138  2138  65.0       4           6           6           6        0      57   \n",
       "2139  2139  78.0       4           6           6           6        0      51   \n",
       "2140  2140  69.0       4           4           4           4        1      60   \n",
       "2141  2141  70.0       4           6           6           6        0      59   \n",
       "\n",
       "      noHQrecs  noRecsPossAF  feas  noNormalRecs  noAFRecs  noOtherRecs  \\\n",
       "ptID                                                                      \n",
       "1          118             8     1         118.0       0.0          0.0   \n",
       "2          116             4     1         116.0       0.0          0.0   \n",
       "3           30             2     1          25.0       0.0          0.0   \n",
       "4           59             2     1          59.0       0.0          0.0   \n",
       "5           91            38     1          89.0       0.0          0.0   \n",
       "...        ...           ...   ...           ...       ...          ...   \n",
       "2137        95             1     1          93.0       0.0          0.0   \n",
       "2138        57             0     1          57.0       0.0          0.0   \n",
       "2139        51             0     1          51.0       0.0          0.0   \n",
       "2140        60             2     1          59.0       0.0          1.0   \n",
       "2141        57             3     1          55.0       0.0          0.0   \n",
       "\n",
       "     pt_prediction_af  \n",
       "ptID                   \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "5                 NaN  \n",
       "...               ...  \n",
       "2137              NaN  \n",
       "2138              NaN  \n",
       "2139              NaN  \n",
       "2140              NaN  \n",
       "2141              NaN  \n",
       "\n",
       "[2141 rows x 15 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Tonights training schedule\n",
    "\n",
    "# Cross Validation dataset construction for SAFER data\n",
    "# Split train and test data according to each patient\n",
    "\n",
    "\n",
    "def get_train_and_val_feas1_sets(test_pts, val_pts):\n",
    "    # Have to load all the data!\n",
    "    feas1_ecg_data, feas1_pt_data = load_feas1_chunk_range((0, num_chunks))\n",
    "\n",
    "    # Just use feas1 to prepare test and validation datasets (The train is best handled with a DatasetSequenceIterator)\n",
    "    feas1_pt_data, feas1_ecg_data = prepare_safer_data(feas1_pt_data, feas1_ecg_data)\n",
    "    feas1_ecg_data[\"class_index\"].value_counts()\n",
    "\n",
    "    feas1_ecg_data_test = feas1_ecg_data[feas1_ecg_data[\"ptID\"].isin(test_pts[\"ptID\"])]\n",
    "    feas1_ecg_data_val = feas1_ecg_data[feas1_ecg_data[\"ptID\"].isin(val_pts[\"ptID\"])]\n",
    "\n",
    "    print(feas1_ecg_data_test[\"class_index\"].value_counts())\n",
    "    print(feas1_ecg_data_val[\"class_index\"].value_counts())\n",
    "\n",
    "    del feas1_ecg_data\n",
    "    del feas1_pt_data\n",
    "\n",
    "    return feas1_ecg_data_test, feas1_ecg_data_val\n",
    "\n",
    "\n",
    "def split_patients_2_groups(pt_data, frac):\n",
    "    split_ratios = np.array([frac, 1-frac])\n",
    "\n",
    "    splits = [[], []]\n",
    "\n",
    "    af_counts = np.zeros(2, dtype=int)\n",
    "    total_counts = np.zeros(2, dtype=int)\n",
    "\n",
    "    total_total_count = 0\n",
    "    total_af_count = 0\n",
    "\n",
    "    for _, pt in pt_data.sample(frac=1).iterrows():\n",
    "        total_total_count += pt[\"noHQrecs\"]\n",
    "        total_af_count += pt[\"noAFRecs\"]\n",
    "\n",
    "        exp_total_counts = total_total_count * split_ratios\n",
    "        exp_af_counts = total_af_count * split_ratios\n",
    "\n",
    "        af_rec_mat = np.diag(np.array([pt[\"noAFRecs\"] for _ in range(2)]))\n",
    "        hq_rec_mat = np.diag(np.array([pt[\"noHQrecs\"] for _ in range(2)]))\n",
    "\n",
    "        loss =  np.sum(np.abs(af_counts[None, :] + af_rec_mat - exp_af_counts[None, :]) + np.abs(total_counts[None, :] + hq_rec_mat - exp_total_counts[None, :]), axis=-1)\n",
    "        best_fold = np.argmin(loss)\n",
    "\n",
    "        splits[best_fold].append(pt)\n",
    "        af_counts[best_fold] += pt[\"noAFRecs\"]\n",
    "        total_counts[best_fold] += pt[\"noHQrecs\"]\n",
    "\n",
    "    return pd.DataFrame(splits[0]), pd.DataFrame(splits[1])\n",
    "\n",
    "\n",
    "pt_data = SAFERDataset.load_pt_dataset(1)\n",
    "ecg_data = SAFERDataset.load_ecg_csv(1, pt_data, ecg_range=None, ecg_meas_diag=None, feas2_offset=10000, feas2_ecg_offset=200000)\n",
    "\n",
    "ecg_data[\"feas\"] = 1\n",
    "ecg_data[\"length\"] = 9120\n",
    "ecg_data[\"rri_len\"] = 20\n",
    "\n",
    "pt_data, ecg_data = prepare_safer_data(pt_data, ecg_data)\n",
    "\n",
    "ecg_data[\"noise_prediction\"] = feas1_noise_predictions\n",
    "ecg_data = ecg_data[ecg_data[\"noise_prediction\"] < 0]  # Remove noisy samples here itself\n",
    "\n",
    "# now set the counts in pt\n",
    "pt_data[\"noHQrecs\"] = ecg_data[\"ptID\"].value_counts()\n",
    "pt_data[\"noAFRecs\"] = ecg_data[ecg_data[\"class_index\"] == 1][\"ptID\"].value_counts()\n",
    "pt_data[\"noHQrecs\"].fillna(0, inplace=True)\n",
    "pt_data[\"noAFRecs\"].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "num_cv = 5\n",
    "num_folds = num_cv  # We'll produce a validation set from the test set in each fold!\n",
    "pt_folds = [[] for _ in range(num_folds)]\n",
    "\n",
    "af_counts = np.zeros(num_folds, dtype=int)\n",
    "total_counts = np.zeros(num_folds, dtype=int)\n",
    "\n",
    "total_total_count = 0\n",
    "total_af_count = 0\n",
    "\n",
    "\n",
    "# Go around the folds and assign patients to each\n",
    "for _, pt in pt_data.sample(frac=1).iterrows():\n",
    "    total_total_count += pt[\"noHQrecs\"]\n",
    "    total_af_count += pt[\"noAFRecs\"]\n",
    "\n",
    "    exp_total_counts = total_total_count * 1.0/num_folds\n",
    "    exp_af_counts = total_af_count * 1.0/num_folds\n",
    "\n",
    "    af_rec_mat = np.diag(np.array([pt[\"noAFRecs\"] for _ in range(num_folds)]))\n",
    "    hq_rec_mat = np.diag(np.array([pt[\"noHQrecs\"] for _ in range(num_folds)]))\n",
    "\n",
    "    loss =  np.sum(np.abs(af_counts[None, :] + af_rec_mat - exp_af_counts) + np.abs(total_counts[None, :] + hq_rec_mat - exp_total_counts), axis=-1)\n",
    "    best_fold = np.argmin(loss)\n",
    "\n",
    "    pt_folds[best_fold].append(pt)\n",
    "    af_counts[best_fold] += pt[\"noAFRecs\"]\n",
    "    total_counts[best_fold] += pt[\"noHQrecs\"]\n",
    "\n",
    "\n",
    "test_pt_folds = [pd.DataFrame(fold) for fold in pt_folds]\n",
    "val_pt_folds = []\n",
    "train_pt_folds = []\n",
    "\n",
    "for test_pt_f in test_pt_folds:\n",
    "    val_pt_f, train_pt_f = split_patients_2_groups(pt_data[~pt_data[\"ptID\"].isin(test_pt_f[\"ptID\"])], 0.125)\n",
    "    val_pt_folds.append(val_pt_f)\n",
    "    train_pt_folds.append(train_pt_f)\n",
    "\n",
    "\n",
    "for f in test_pt_folds:\n",
    "    print(f[\"noAFRecs\"].sum(), f[\"noHQrecs\"].sum())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "for f in val_pt_folds:\n",
    "    print(f[\"noAFRecs\"].sum(), f[\"noHQrecs\"].sum())\n",
    "\n",
    "conf_mats = []\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for i, (train_pt_df, test_pt_df, val_pt_df) in enumerate(zip(train_pt_folds, test_pt_folds, val_pt_folds)):\n",
    "    print(\"======\")\n",
    "    print(f\"Fold {i}\")\n",
    "    # Create some a filter function to select data from each partition\n",
    "    def filter_train_pts(ecg_data):\n",
    "        return ecg_data[(ecg_data[\"ptID\"].isin(train_pt_df[\"ptID\"])) & (feas1_noise_predictions[ecg_data.index] < 0)]\n",
    "\n",
    "    feas1_train_dataloader = DatasetSequenceIterator(loading_functions, [64 for n in range(num_chunks)], filter=filter_train_pts)\n",
    "    feas1_ecg_data_test, feas1_ecg_data_val = get_train_and_val_feas1_sets(test_pt_df, val_pt_df)\n",
    "\n",
    "    feas1_test_dataloader = get_dataloaders(feas1_ecg_data_test, 64)\n",
    "    feas1_val_dataloader = get_dataloaders(feas1_ecg_data_val, 64)\n",
    "\n",
    "\n",
    "    class_counts = torch.tensor(ecg_data[ecg_data[\"ptID\"].isin(train_pt_df[\"ptID\"])][\"class_index\"].value_counts().values.astype(np.float32))\n",
    "    class_weights = (1/class_counts)\n",
    "    class_weights /= torch.sum(class_weights)\n",
    "    print(class_weights)\n",
    "\n",
    "    print(feas1_ecg_data_test[\"class_index\"].value_counts())\n",
    "    print(feas1_ecg_data_val[\"class_index\"].value_counts())\n",
    "\n",
    "    #  now get the model\n",
    "    model = TransformerModel(3, embed_dim, n_head, 512, 6, n_fft, n_inp_rri, device=device).to(device)\n",
    "    model.load_state_dict(torch.load(\"TrainedModels/Transformer_27_May_feas1_train_attention_pooling_augmentation_smoothing_no_noisy_nk_beats.pt\", map_location=device))\n",
    "\n",
    "    loss_func = focal_loss(class_weights, gamma=2, label_smoothing=0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "    number_warmup_batches = 600\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=warmup)\n",
    "\n",
    "    model, losses = train(model, feas1_train_dataloader, feas1_val_dataloader)\n",
    "    model = model.to(device)\n",
    "\n",
    "    losses_np = np.array(losses)\n",
    "    np.save(f\"TrainedModels/Transformer_29_May_final_cross_validate_{i}_training_curve\", losses_np)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"TrainedModels/Transformer_29_May_final_cross_validate_{i}_training_curve.pt\")\n",
    "    feas1_ecg_data_test.to_pickle(f\"C:/Users/daniel/Documents/feas1_train_set_cross_validate_{i}.pk\")\n",
    "\n",
    "    predictions, true_labels = get_predictions(model, feas1_test_dataloader, feas1_ecg_data_test)\n",
    "    conf_mat = confusion_matrix(true_labels, np.argmax(predictions, axis=1))\n",
    "\n",
    "    print(conf_mat)\n",
    "    print(losses_np)\n",
    "\n",
    "    conf_mats.append(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "def get_predictions(model, dataloader, dataset):\n",
    "\n",
    "    attentions = []\n",
    "\n",
    "    \"\"\"\n",
    "    def hook(module, x, y):\n",
    "        for a in y[1]:\n",
    "            attentions.append(a.detach().cpu().numpy())\n",
    "\n",
    "    attention_hook = model.attention_pooling.attn.register_forward_hook(hook)\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    outputs = []\n",
    "    inds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (signals, labels, ind) in enumerate(dataloader):\n",
    "            signal = signals[0].to(device).float()\n",
    "            rris = signals[1].to(device).float()\n",
    "            rri_len = signals[2].to(device).float()\n",
    "\n",
    "            labels = labels.long().detach().numpy()\n",
    "            true_labels.append(labels)\n",
    "\n",
    "            output = model(signal, rris, rri_len).detach().to(\"cpu\").numpy() # rris).detach().to(\"cpu\").numpy()\n",
    "\n",
    "            prediction = output # np.argmax(output, axis=-1)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "            for i, o in zip(ind, output):\n",
    "                outputs.append(o)\n",
    "                if isinstance(i, str):\n",
    "                    inds.append(i)\n",
    "                else:\n",
    "                    inds.append(i.item())\n",
    "\n",
    "    dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n",
    "    # dataset[\"attention\"] = pd.Series(data=attentions, index=inds)\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    true_labels = np.concatenate(true_labels)\n",
    "\n",
    "    # attention_hook.remove()\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# predictions, true_labels = get_predictions(model, feas1_val_dataloader_clean, feas1_ecg_data_val_clean)\n",
    "# conf_mat = confusion_matrix(true_labels, np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'noise_prediction'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3799\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'noise_prediction'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [77], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m feas1_ecg_data_test[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnoise_probs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfeas1_ecg_data_test\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnoise_prediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      2\u001B[0m feas1_ecg_data_val[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnoise_probs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m feas1_ecg_data_val[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnoise_prediction\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_noise_free_conf_mat\u001B[39m(dataset):\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3805\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3807\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3802\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3805\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'noise_prediction'"
     ]
    }
   ],
   "source": [
    "feas1_ecg_data_test[\"noise_probs\"] = feas1_ecg_data_test[\"noise_prediction\"]\n",
    "feas1_ecg_data_val[\"noise_probs\"] = feas1_ecg_data_val[\"noise_prediction\"]\n",
    "\n",
    "def get_noise_free_conf_mat(dataset):\n",
    "   return confusion_matrix(dataset[dataset[\"noise_probs\"] < 0][\"class_index\"], dataset[dataset[\"noise_probs\"] < 0][\"prediction\"].map(np.argmax))\n",
    "\n",
    "noise_free_conf_mat = get_noise_free_conf_mat(feas1_ecg_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conf_mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [11], line 18\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOther F1: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mF1_ind(conf_mat, \u001B[38;5;241m2\u001B[39m)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m0.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28mprint\u001B[39m()\n\u001B[1;32m---> 18\u001B[0m print_results(\u001B[43mconf_mat\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'conf_mat' is not defined"
     ]
    }
   ],
   "source": [
    "def F1_ind(conf_mat, ind):\n",
    "    return (2 * conf_mat[ind, ind])/(np.sum(conf_mat[ind]) + np.sum(conf_mat[:, ind]))\n",
    "\n",
    "def print_results(conf_mat):\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(conf_mat)\n",
    "\n",
    "    print(f\"Sensitivity: {conf_mat[1, 1]/np.sum(conf_mat[1]):0.3f}\")\n",
    "    print(f\"Specificity: {(conf_mat[0, 0] + conf_mat[0, 2] + conf_mat[2, 0] + conf_mat[2, 2])/(np.sum(conf_mat[0]) + np.sum(conf_mat[2])):0.3f}\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(f\"Normal F1: {F1_ind(conf_mat, 0):0.3f}\")\n",
    "    print(f\"AF F1: {F1_ind(conf_mat, 1):0.3f}\")\n",
    "    print(f\"Other F1: {F1_ind(conf_mat, 2):0.3f}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "print_results(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[18559    68   524]\n",
      " [    4    52    34]\n",
      " [   81   140   170]]\n",
      "Sensitivity: 0.578\n",
      "Specificity: 0.989\n",
      "\n",
      "Normal F1: 0.982\n",
      "AF F1: 0.297\n",
      "Other F1: 0.304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print noise free conf mats\n",
    "print_results(noise_free_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_inds = feas1_ecg_data_val[feas1_ecg_data_val[\"prediction\"].map(np.argmax) != feas1_ecg_data_val[\"class_index\"]].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_val_interesting = feas1_ecg_data_val[(feas1_ecg_data_val[\"class_index\"] != 0) | (feas1_ecg_data_val[\"class_index\"] != feas1_ecg_data_val[\"prediction\"].map(np.argmax))]\n",
    "feas1_val_interesting_dataloader = get_dataloaders(feas1_val_interesting, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy.special import softmax\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=250)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "\n",
    "labels = [\"Normal\", \"AF\", \"Other\"]\n",
    "\n",
    "for i in range(3):\n",
    "    p, r, d = precision_recall_curve((feas1_ecg_data_val_clean[\"class_index\"] == i),  feas1_ecg_data_val_clean[\"prediction\"].map(lambda x: softmax(x)[i]))\n",
    "    if i == 1:\n",
    "        p_af = p\n",
    "        r_af = r\n",
    "        d_af = d\n",
    "\n",
    "    ax.plot(r, p, label=labels[i])\n",
    "    # plt.xlim((0, 1.1))\n",
    "    # plt.ylim((0, 1.1))\n",
    "\n",
    "    # closest_point_to_0_final = np.argmin(np.abs(d))\n",
    "    # ax.plot(r[closest_point_to_0_final], p[closest_point_to_0_final], \"o\", color=\"#ff7f0e\", label=r\"$p(AF) = 0.5$\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "# fig.savefig(\"FinalReportFigs/CNN_NoiseDetect_precision_recall.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.022222222222222223\n",
      "0.80841523\n"
     ]
    }
   ],
   "source": [
    "max_prec = np.argmax(p_af)\n",
    "print(p_af[max_prec])\n",
    "print(r_af[max_prec])\n",
    "print(d_af[max_prec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Utilities.Plotting)\n",
    "from Utilities.Plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74351\n",
      "measDiag                                 DiagEnum.AF\n",
      "prediction     [-0.28620133, -0.32692084, 0.7239914]\n",
      "class_index                                        1\n",
      "Name: 74351, dtype: object\n",
      "74431\n",
      "measDiag                                DiagEnum.AF\n",
      "prediction     [-0.7460612, 0.22486098, 0.49314404]\n",
      "class_index                                       1\n",
      "Name: 74431, dtype: object\n",
      "74435\n",
      "measDiag                                 DiagEnum.AF\n",
      "prediction     [-0.017127324, -0.4723771, 0.8629926]\n",
      "class_index                                        1\n",
      "Name: 74435, dtype: object\n",
      "74385\n",
      "measDiag                                 DiagEnum.AF\n",
      "prediction     [-0.76330775, 0.16884518, 0.48620653]\n",
      "class_index                                        1\n",
      "Name: 74385, dtype: object\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [210], line 17\u001B[0m\n\u001B[0;32m     15\u001B[0m plot_ecg(ecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;241m300\u001B[39m, n_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, r_peaks\u001B[38;5;241m=\u001B[39mecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr_peaks\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     16\u001B[0m plot_ecg_spectrogram(ecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;241m300\u001B[39m, n_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, cut_range\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m18\u001B[39m], figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m2.5\u001B[39m), export_quality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 17\u001B[0m \u001B[43mplot_ecg_drr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mecg\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrri_feature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mecg\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrri_len\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexport_quality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\Utilities\\Plotting.py:57\u001B[0m, in \u001B[0;36mplot_ecg_drr\u001B[1;34m(rri, rri_len, figsize, export_quality)\u001B[0m\n\u001B[0;32m     54\u001B[0m ax\u001B[38;5;241m.\u001B[39mspines[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mright\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mset_visible(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     56\u001B[0m fig\u001B[38;5;241m.\u001B[39mtight_layout()\n\u001B[1;32m---> 57\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001B[0m, in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    408\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[1;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_backend_mod()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:3546\u001B[0m, in \u001B[0;36m_Backend.show\u001B[1;34m(cls, block)\u001B[0m\n\u001B[0;32m   3544\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m ipython_pylab \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive()\n\u001B[0;32m   3545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m-> 3546\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:1032\u001B[0m, in \u001B[0;36m_BackendTk.mainloop\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1030\u001B[0m manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1032\u001B[0m     \u001B[43mfirst_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m   1457\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1458\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import scipy.signal\n",
    "\n",
    "dataset = feas1_ecg_data_val_clean\n",
    "dataset[\"class_prediction\"] = dataset[\"prediction\"].map(lambda x: np.argmax(x))\n",
    "#  & (dataset[\"noise_probs\"] < 0)\n",
    "\n",
    "selection = dataset[(dataset[\"class_prediction\"] == 2) & (dataset[\"class_index\"] == 1)]\n",
    "\n",
    "\n",
    "for ecg_ind, ecg in selection.sample(frac=1).iterrows():\n",
    "    print(ecg_ind)\n",
    "    print(ecg[[\"measDiag\", \"prediction\", \"class_index\"]])\n",
    "    # filtered_ecg = scipy.signal.sosfiltfilt(sos, ecg[\"data\"], padlen=150)\n",
    "\n",
    "    plot_ecg(ecg[\"data\"], 300, n_split=3, r_peaks=ecg[\"r_peaks\"])\n",
    "    plot_ecg_spectrogram(ecg[\"data\"], 300, n_split=3, cut_range=[2, 18], figsize=(6, 2.5), export_quality=True)\n",
    "    plot_ecg_drr(ecg[\"rri_feature\"], ecg[\"rri_len\"], export_quality=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_initial_transformer = np.array([[[ 717,   41,  226],\n",
    " [  88,  686,  129],\n",
    " [ 456,  184, 1407]], # CinC2020\n",
    "[[   0, 2237, 1457],\n",
    " [   0,  437,   67],\n",
    " [   0, 1094,  555]],  # CinC2017\n",
    "[[7384, 2281, 9848],\n",
    " [   0,    8,    8],\n",
    " [ 249,  151,  357]],  # Safer Feas2\n",
    "[[ 8502,  2400, 11362],\n",
    " [    2,    50,    67],\n",
    " [  223,    75,   256]]])  # safer feas1\n",
    "\n",
    "conf_mat_fine_tuned = np.array([[[  0, 320, 419],\n",
    " [  0,  91,  10],\n",
    " [  0, 171, 159]],  # CinC 2017\n",
    "[[14918,  1543,  3052],\n",
    " [    3,     7,     6],\n",
    " [  562,    79,   116]],  # SAFER feas 2\n",
    "[[17558,  2061,  2829],\n",
    " [    7,    92,    34],\n",
    " [  343,    60,   159]]])  # SAFER feas 1\n",
    "\n",
    "\n",
    "conf_mat_final = np.array([[[20413,   376,  1475],\n",
    " [   13,    82,    38],\n",
    " [  203,    73,   282]],  # SAFER feas1\n",
    "[[19113,    19,   381],\n",
    " [    7,     5,     4],\n",
    " [  428,    67,   262]]]) # SAFER feas2\n",
    "\n",
    "\n",
    "for c in conf_mat_final:\n",
    "    plot_confusion_matrix_2(c, [\"Normal\", \"AF\", \"Other Rhythm\"], colour=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83267\n",
      "measDiag                                DiagEnum.AF\n",
      "prediction     [-1.5628628, 0.83602333, 0.26011002]\n",
      "class_index                                       1\n",
      "Name: 83267, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "74349\n",
      "measDiag                                DiagEnum.AF\n",
      "prediction     [-1.6065241, 0.97179544, 0.25990623]\n",
      "class_index                                       1\n",
      "Name: 74349, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "150683\n",
      "measDiag                                  DiagEnum.AF\n",
      "prediction     [-1.6618122, 0.85432255, -0.005189167]\n",
      "class_index                                         1\n",
      "Name: 150683, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "146007\n",
      "measDiag                               DiagEnum.AF\n",
      "prediction     [-2.0863369, 1.270616, 0.093946874]\n",
      "class_index                                      1\n",
      "Name: 146007, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "150667\n",
      "measDiag                               DiagEnum.AF\n",
      "prediction     [-1.8283519, 0.92098296, 0.1849329]\n",
      "class_index                                      1\n",
      "Name: 150667, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "146028\n",
      "measDiag                                DiagEnum.AF\n",
      "prediction     [-2.3819041, 1.6550652, -0.29732257]\n",
      "class_index                                       1\n",
      "Name: 146028, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "74406\n",
      "measDiag                               DiagEnum.AF\n",
      "prediction     [-1.2612442, 0.8504637, 0.10607182]\n",
      "class_index                                      1\n",
      "Name: 74406, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "146036\n",
      "measDiag                                DiagEnum.AF\n",
      "prediction     [-2.1433992, 1.5101649, -0.04690835]\n",
      "class_index                                       1\n",
      "Name: 146036, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "146058\n",
      "measDiag                               DiagEnum.AF\n",
      "prediction     [-2.461849, 1.7272497, -0.25826383]\n",
      "class_index                                      1\n",
      "Name: 146058, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "150653\n",
      "measDiag                               DiagEnum.AF\n",
      "prediction     [-1.6369882, 0.7653281, 0.27504772]\n",
      "class_index                                      1\n",
      "Name: 150653, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "150645\n",
      "measDiag                              DiagEnum.AF\n",
      "prediction     [-1.96293, 1.1182717, 0.028663618]\n",
      "class_index                                     1\n",
      "Name: 150645, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "150640\n",
      "measDiag                               DiagEnum.AF\n",
      "prediction     [-1.6584738, 0.7081909, 0.50657713]\n",
      "class_index                                      1\n",
      "Name: 150640, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n",
      "83213\n",
      "measDiag                               DiagEnum.AF\n",
      "prediction     [-0.762478, 0.30369082, 0.29651248]\n",
      "class_index                                      1\n",
      "Name: 83213, dtype: object\n",
      "(4, 286, 286)\n",
      "Plotting attention\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [403], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m plot_ecg_with_attention(ecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m][:\u001B[38;5;241m3000\u001B[39m], \u001B[38;5;241m300\u001B[39m, n_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, attention\u001B[38;5;241m=\u001B[39mecg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention\u001B[39m\u001B[38;5;124m\"\u001B[39m][:, :, :\u001B[38;5;241m96\u001B[39m])\u001B[38;5;66;03m# , figsize=(6, 4), export_quality=True)\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# plot_ecg_spectrogram(ecg[\"data\"], 300, n_split=3, cut_range=[2, 18])\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# plot_ecg_poincare(ecg[\"rri_feature\"], ecg[\"rri_len\"])\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\pyplot.py:409\u001B[0m, in \u001B[0;36mshow\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;124;03mDisplay all open figures.\u001B[39;00m\n\u001B[0;32m    367\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;124;03mexplicitly there.\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    408\u001B[0m _warn_if_gui_out_of_main_thread()\n\u001B[1;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_backend_mod()\u001B[38;5;241m.\u001B[39mshow(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:3546\u001B[0m, in \u001B[0;36m_Backend.show\u001B[1;34m(cls, block)\u001B[0m\n\u001B[0;32m   3544\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m ipython_pylab \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interactive()\n\u001B[0;32m   3545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m-> 3546\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\matplotlib\\backends\\_backend_tk.py:1032\u001B[0m, in \u001B[0;36m_BackendTk.mainloop\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1030\u001B[0m manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1032\u001B[0m     \u001B[43mfirst_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwindow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1034\u001B[0m     manager_class\u001B[38;5;241m.\u001B[39m_owns_mainloop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py:1458\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m   1457\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1458\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Plot with attention maps\n",
    "\n",
    "import scipy.signal\n",
    "\n",
    "dataset = feas1_val_interesting\n",
    "dataset[\"class_prediction\"] = dataset[\"prediction\"].map(lambda x: np.argmax(x))\n",
    "#  & (dataset[\"noise_probs\"] < 0)\n",
    "\n",
    "selection = dataset[(dataset[\"class_prediction\"] == 1) & (dataset[\"class_index\"] == 1)]\n",
    "\n",
    "for ecg_ind, ecg in selection.dropna(subset=[\"attention\"]).sample(frac=1).iterrows():\n",
    "    print(ecg_ind)\n",
    "    print(ecg[[\"measDiag\", \"prediction\", \"class_index\"]])\n",
    "    print(ecg[\"attention\"].shape)\n",
    "    # for 10s cut attention to 96\n",
    "    # filtered_ecg = scipy.signal.sosfiltfilt(sos, ecg[\"data\"], padlen=150)\n",
    "    plot_ecg_with_attention(ecg[\"data\"][:3000], 300, n_split=1, attention=ecg[\"attention\"][:, :, :96])# , figsize=(6, 4), export_quality=True)\n",
    "    # plot_ecg_spectrogram(ecg[\"data\"], 300, n_split=3, cut_range=[2, 18])\n",
    "    # plot_ecg_poincare(ecg[\"rri_feature\"], ecg[\"rri_len\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the attention mechanism (not very useful yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.transformer_encoder.layers.\n",
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "def patch_attention(m):\n",
    "    forward_orig = m.forward\n",
    "\n",
    "    def wrap(*args, **kwargs):\n",
    "        kwargs['need_weights'] = True\n",
    "        kwargs['average_attn_weights'] = False\n",
    "\n",
    "        return forward_orig(*args, **kwargs)\n",
    "\n",
    "    m.forward = wrap\n",
    "\n",
    "attentions = []\n",
    "inds = []\n",
    "\n",
    "def save_outputs(module, x, y):\n",
    "    for att in y[1]:\n",
    "        attentions.append(att.cpu().numpy())\n",
    "\n",
    "patch_attention(model.transformer_encoder.layers[0].self_attn)\n",
    "attention_hook = model.transformer_encoder.layers[0].self_attn.register_forward_hook(save_outputs)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (signals, labels, ind) in enumerate(feas1_val_interesting_dataloader):\n",
    "        signal = signals[0].to(device).float()\n",
    "        rris = signals[1].to(device).float()\n",
    "        rri_len = signals[2].to(device).float()\n",
    "\n",
    "        labels = labels.long().detach().numpy()\n",
    "        for i in ind:\n",
    "            if isinstance(i, str):\n",
    "                inds.append(i)\n",
    "            else:\n",
    "                inds.append(i.item())\n",
    "\n",
    "        output = model(signal, rris, rri_len) # rris).detach().to(\"cpu\").numpy()\n",
    "        # plot_ecg(signal[0].cpu().numpy())\n",
    "        # plt.show()\n",
    "\n",
    "attention_hook.remove()\n",
    "# attentions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2032"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(attentions)\n",
    "len(feas1_val_interesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_val_interesting[\"attention\"] = pd.Series(data=attentions, index=inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_hook.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the attention pooling weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 9120])\n",
      "hook\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [170], line 21\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# fft = torch.abs(torch.fft.fft(signals))\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# signals = torch.cat([signals, fft], dim=1)\u001B[39;00m\n\u001B[0;32m     20\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mlong()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m---> 21\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43msignals\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m labels[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28mprint\u001B[39m(attentions\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn [140], line 114\u001B[0m, in \u001B[0;36mTransformerModel.forward\u001B[1;34m(self, src)\u001B[0m\n\u001B[0;32m    111\u001B[0m output \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtranspose(output, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    112\u001B[0m \u001B[38;5;66;03m# output = torch.flatten(output, 1)\u001B[39;00m\n\u001B[1;32m--> 114\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention_pooling\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    116\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder1(output)\n\u001B[0;32m    117\u001B[0m output \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mrelu(output)\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn [139], line 58\u001B[0m, in \u001B[0;36mLearnedAggregation.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x:Tensor):\n\u001B[1;32m---> 58\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcls_q \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgamma_1 \u001B[38;5;241m*\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcls_q\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgamma_2 \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mffn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm(x))\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1215\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n\u001B[0;32m   1214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m*\u001B[39m_global_forward_hooks\u001B[38;5;241m.\u001B[39mvalues(), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[1;32m-> 1215\u001B[0m         hook_result \u001B[38;5;241m=\u001B[39m \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1216\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m hook_result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1217\u001B[0m             result \u001B[38;5;241m=\u001B[39m hook_result\n",
      "Cell \u001B[1;32mIn [166], line 10\u001B[0m, in \u001B[0;36mhook\u001B[1;34m(module, x, y)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m attentions\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhook\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m \u001B[43mattentions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m(y[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# model.transformer_encoder.layers.\n",
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "attentions = None\n",
    "\n",
    "def hook(module, x, y):\n",
    "    global attentions\n",
    "    print(\"hook\")\n",
    "    attentions = y[1].detach().to(\"cpu\").numpy()\n",
    "\n",
    "attention_hook = model.attention_pooling.attn.register_forward_hook(hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (signals, labels, ind) in enumerate(test_dataloader_safer):\n",
    "        print(signals.shape)\n",
    "        signals = torch.transpose(signals.to(device), 0, 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        labels = labels.long().detach().numpy()\n",
    "        output = model(signals).detach().to(\"cpu\").numpy()\n",
    "\n",
    "        if labels[0] == 0:\n",
    "            print(attentions.shape)\n",
    "            fig = make_subplots(2, 1)\n",
    "            fig.add_trace(go.Scatter(y=signals[:, 0].detach().to(\"cpu\").numpy()), row=1, col=1)\n",
    "            for j in range(attentions.shape[-2]):\n",
    "                fig.add_trace(go.Scatter(y=attentions[0, j, :]), row=2, col=1)\n",
    "            fig.show()\n",
    "\n",
    "        if i == 10:\n",
    "            break\n",
    "\n",
    "attention_hook.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the final classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_weight = model.decoder1.weight.data\n",
    "fc2_weight = model.decoder2.weight.data\n",
    "\n",
    "plt.imshow(fc1_weight.cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = feas1_ecg_data_val\n",
    "dataset[\"class_prediction\"] = dataset[\"prediction\"].map(lambda x: np.argmax(x))\n",
    "selection = dataset[(dataset[\"class_prediction\"] == 1) & (dataset[\"class_index\"] == 1) & (dataset[\"noise_probs\"]< 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_signal = np.vstack(selection[\"data\"].values)\n",
    "np_rri = np.vstack(selection[\"rri_feature\"].values)\n",
    "rri_len = selection[\"rri_len\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook\n",
      "torch.Size([17, 192])\n",
      "torch.Size([17, 128, 1])\n",
      "torch.Size([17, 128, 1])\n",
      "torch.Size([17, 3, 1])\n",
      "torch.Size([17, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "signal = torch.tensor(np_signal, dtype=torch.float, device=device)\n",
    "rri = torch.tensor(np_rri, dtype=torch.float, device=device)\n",
    "rri_lens = torch.tensor(rri_len, device=device)\n",
    "\n",
    "encoder_out = None\n",
    "\n",
    "def get_encoding(module, x, y):\n",
    "    global encoder_out\n",
    "    print(\"hook\")\n",
    "    print(x[0].shape)\n",
    "    encoder_out = x[0].detach().to(\"cpu\")\n",
    "\n",
    "encoding_hook = model.decoder1.register_forward_hook(get_encoding)\n",
    "\n",
    "output = model(signal, rri, rri_lens)\n",
    "\n",
    "encoding_hook.remove()\n",
    "\n",
    "# Now recreate the output from just the RRI or ECG and see which makes the biggest impact\n",
    "fc1_weight = model.decoder1.weight.data.to(\"cpu\")\n",
    "fc2_weight = model.decoder2.weight.data.to(\"cpu\")\n",
    "\n",
    "\n",
    "ecg_out = fc1_weight[:, :128] @ torch.unsqueeze(encoder_out[:, :128], dim=-1)\n",
    "rri_out = fc1_weight[:, 128:] @ torch.unsqueeze(encoder_out[:, 128:], dim=-1)\n",
    "\n",
    "print(ecg_out.shape)\n",
    "print(ecg_out.shape)\n",
    "\n",
    "ecg_out = nn.functional.relu(ecg_out)\n",
    "rri_out = nn.functional.relu(rri_out)\n",
    "\n",
    "ecg_out = fc2_weight @ ecg_out\n",
    "rri_out = fc2_weight @ rri_out\n",
    "\n",
    "print(ecg_out.shape)\n",
    "print(ecg_out.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"ECG Signal Outputs\")\n",
    "plt.imshow(ecg_out)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"RRI Sequence Outputs\")\n",
    "plt.imshow(rri_out)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE the encoder outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4078, 2)\n"
     ]
    }
   ],
   "source": [
    "encoder_out = []\n",
    "class_indexes = []\n",
    "inds = []\n",
    "\n",
    "def get_encoding(module, x, y):\n",
    "    encoder_out.append(x[0].detach().to(\"cpu\").numpy())\n",
    "\n",
    "encoding_hook = model.decoder1.register_forward_hook(get_encoding)\n",
    "\n",
    "dataloader = test_dataloader_safer\n",
    "\n",
    "with torch.no_grad():\n",
    "        for i, (signals, labels, ind) in enumerate(dataloader):\n",
    "            signal = signals[0].to(device).float()\n",
    "            rris = signals[1].to(device).float()\n",
    "            rri_len = signals[2].to(device).float()\n",
    "\n",
    "            labels = labels.long().detach().numpy()\n",
    "            class_indexes.append(labels)\n",
    "\n",
    "            output = model(signal, rris, rri_len).detach().to(\"cpu\").numpy()\n",
    "            inds.append(ind.cpu().detach().numpy())\n",
    "\n",
    "encoding_hook.remove()\n",
    "\n",
    "encoder_out = np.concatenate(encoder_out, axis=0)\n",
    "class_indexes = np.concatenate(class_indexes, axis=0)\n",
    "inds = np.concatenate(inds, axis=0)\n",
    "\n",
    "test_dataset_safer[\"encodings\"] = pd.Series(data=[encoder_out[i] for i in range(encoder_out.shape[0])], index=inds)\n",
    "\n",
    "tsne = TSNE(perplexity=30)\n",
    "embeddings = tsne.fit_transform(encoder_out)\n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daniel\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(perplexity=10)\n",
    "embeddings = tsne.fit_transform(encoder_out)\n",
    "\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1], c=class_indexes, marker=\"x\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation for SAFER (patient wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18)\n",
      "0    32499\n",
      "2      707\n",
      "1      218\n",
      "Name: class_index, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_18972\\1392667371.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18)\n",
      "0    30217\n",
      "2      584\n",
      "1       86\n",
      "Name: class_index, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_18972\\1392667371.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18)\n",
      "0    29726\n",
      "2      656\n",
      "1      168\n",
      "Name: class_index, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_18972\\1392667371.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18)\n",
      "0    28603\n",
      "2      687\n",
      "1      113\n",
      "Name: class_index, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_18972\\1392667371.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 18)\n",
      "0    28336\n",
      "2      476\n",
      "1      156\n",
      "Name: class_index, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_18972\\1392667371.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions for the entire feas1 dataset, with the cross validated models\n",
    "\n",
    "feas1_ecg_predictions = []\n",
    "\n",
    "for i in range(5):\n",
    "    model = TransformerModel(3, embed_dim, n_head, 512, 6, n_fft, n_inp_rri, device=device).to(device)\n",
    "    model.load_state_dict(torch.load(f\"TrainedModels/Transformer_29_May_final_cross_validate_{i}_training_curve.pt\", map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    feas1_ecg_data_test = pd.read_pickle(f\"C:/Users/daniel/Documents/feas1_train_set_cross_validate_{i}.pk\")\n",
    "    feas1_ecg_data_test_all = feas1_ecg_data[feas1_ecg_data[\"ptID\"].isin(feas1_ecg_data_test[\"ptID\"])]\n",
    "    print(feas1_ecg_data_test_all[\"class_index\"].value_counts())\n",
    "\n",
    "    feas1_test_dataloader = get_dataloaders(feas1_ecg_data_test_all, 64)\n",
    "\n",
    "    get_predictions(model, feas1_test_dataloader, feas1_ecg_data_test_all)\n",
    "    feas1_ecg_predictions.append(feas1_ecg_data_test_all.drop(\"data\", axis=1))\n",
    "\n",
    "feas1_ecg_predictions = pd.concat(feas1_ecg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_ecg_predictions.to_pickle(\"C:/Users/daniel/Documents/feas1_train_set_cross_validate_all_predictions_even_noisy.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_ecg_predictions = pd.read_pickle(\"C:/Users/daniel/Documents/feas1_train_set_cross_validate_all_predictions_even_noisy.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas1_ecg_predictions[\"noise_prediction\"] = feas1_noise_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5860\n",
       "False    4323\n",
       "Name: noise_prediction, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feas1_ecg_predictions[feas1_ecg_predictions[\"poss_AF_tag\"] == 1][\"noise_prediction\"].dropna() < 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'noise_prediction'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3799\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'noise_prediction'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m (\u001B[43mecg_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mecg_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mposs_AF_tag\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnoise_prediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mvalue_counts()\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3805\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3807\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\Documents\\CambridgeSoftwareProjects\\ecg-signal-quality\\projectEnv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3802\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3804\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3805\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'noise_prediction'"
     ]
    }
   ],
   "source": [
    "(ecg_data[ecg_data[\"poss_AF_tag\"] == 1][\"noise_prediction\"] <= 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data[\"prediction\"] = feas1_ecg_predictions[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_binary_results(conf_mat):\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(conf_mat)\n",
    "\n",
    "    print(f\"Sensitivity: {conf_mat[1, 1] / np.sum(conf_mat[1]):0.3f}\")\n",
    "    print(f\"Specificity: {(conf_mat[0, 0]) / np.sum(conf_mat[0]):0.3f}\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(f\"Normal F1: {F1_ind(conf_mat, 0):0.3f}\")\n",
    "    print(f\"AF F1: {F1_ind(conf_mat, 1):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_num_review(pt_ordered_ecg_groups):\n",
    "    total_num_review = 0\n",
    "    for _, g in pt_ordered_ecg_groups:\n",
    "        total_num_review += (g[\"ECGIsAF\"].cumsum() == 0).sum()\n",
    "    return total_num_review\n",
    "\n",
    "def get_pt_conf_mat(pt_data, pt_has_af_review, ground_truth):\n",
    "    pt_data.loc[:, \"pt_prediction_af\"] = False\n",
    "    pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
    "    pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
    "\n",
    "    return confusion_matrix(ground_truth, pt_data[\"pt_prediction_af\"].astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feas1_pt_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pt_data \u001B[38;5;241m=\u001B[39m \u001B[43mfeas1_pt_data\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'feas1_pt_data' is not defined"
     ]
    }
   ],
   "source": [
    "pt_data = feas1_pt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    2043\n",
      "True       48\n",
      "Name: ECGIsAF, dtype: int64\n",
      "4    2025\n",
      "2      64\n",
      "1       2\n",
      "Name: ptDiag, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\173534505.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  pt_in_dataset = pt_data.loc[ground_truth.index][pt_data[\"ptDiag\"].isin(allowed_pt_diags)]\n"
     ]
    }
   ],
   "source": [
    "pt_data[\"ptDiag\"].value_counts()\n",
    "allowed_pt_diags = [1, 2, 4 ] # [1, 2, 4 ], for feas 1   [1, 3] for feas 2\n",
    "af_pt_diag = 2  # 2 for feas 1, 1 for feas 2\n",
    "\n",
    "pt_data_limited_diag = pt_data[pt_data[\"ptDiag\"].isin(allowed_pt_diags)] # .isin([4, 2, 1])] # limit diagnoses - avoid screening failure and such!   feas2 limitations are [1, 3]\n",
    "\n",
    "dataset = feas1_ecg_predictions[feas1_ecg_predictions[\"noise_prediction\"] < 100].dropna(subset=[\"prediction\"])\n",
    "dataset[\"prob_af\"] = dataset[\"prediction\"].map(lambda x: softmax(x)[1])\n",
    "dataset[\"ECGIsAF\"] = (dataset[\"measDiag\"] == DiagEnum.AF)\n",
    "\n",
    "ground_truth = dataset.groupby(\"ptID\")[\"ECGIsAF\"].any()  # Any patient with at least 1 ECG signal labelled as AF is also AF - some patients were diagnosed with ECGs which were not included in the data?\n",
    "pt_in_dataset = pt_data.loc[ground_truth.index][pt_data[\"ptDiag\"].isin(allowed_pt_diags)]\n",
    "dataset = dataset[dataset[\"ptID\"].isin(pt_in_dataset[\"ptID\"])]\n",
    "ground_truth = dataset.groupby(\"ptID\")[\"ECGIsAF\"].any()  # Any patient with at least 1 ECG signal labelled as AF is also AF - some patients were diagnosed with ECGs which were not included in the data?\n",
    "\n",
    "print(ground_truth.value_counts())\n",
    "print(pt_in_dataset[\"ptDiag\"].value_counts())  # how did these 2 get their AF diagnosis with no AF ECGs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[1897  130]\n",
      " [  14   50]]\n",
      "Sensitivity: 0.781\n",
      "Specificity: 0.936\n",
      "\n",
      "Normal F1: 0.963\n",
      "AF F1: 0.410\n",
      "Max number of ECGs which must be reviewed: 15011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\1812677794.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_in_dataset.loc[:, \"pt_prediction_af\"] = pt_diagnoses\n"
     ]
    }
   ],
   "source": [
    "# compute the number of patients who have at least one of the signals labelled as AF\n",
    "dataset[\"class_prediction\"] = dataset[\"prediction\"].map(np.argmax)\n",
    "dataset[\"pred_af\"] = dataset[\"class_prediction\"] == 1\n",
    "pt_diagnoses = dataset.groupby(\"ptID\")[\"pred_af\"].any()\n",
    "\n",
    "pt_in_dataset.loc[:, \"pt_prediction_af\"] = pt_diagnoses\n",
    "\n",
    "val_patients = pt_in_dataset.dropna(subset=[\"pt_prediction_af\"])\n",
    "pt_conf_mat = confusion_matrix((val_patients[\"ptDiag\"] == af_pt_diag).values, val_patients[\"pt_prediction_af\"].astype(bool))\n",
    "\n",
    "print_binary_results(pt_conf_mat)\n",
    "\n",
    "print(f\"Max number of ECGs which must be reviewed: {val_patients[val_patients['pt_prediction_af'] == 1]['noHQrecs'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[2043    0]\n",
      " [   0   48]]\n",
      "Sensitivity: 1.000\n",
      "Specificity: 1.000\n",
      "\n",
      "Normal F1: 1.000\n",
      "AF F1: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, lets see if the cardiologist reviews only a fixed number of ECGs in order of prob AF.\n",
    "dataset[\"prob_af\"] = dataset[\"prediction\"].map(lambda x: softmax(x)[1])\n",
    "dataset[\"ECGIsAF\"] = (dataset[\"measDiag\"] == DiagEnum.AF)\n",
    "pt_ordered_ecg_groups = dataset.sort_values(\"prob_af\", ascending=False).groupby(\"ptID\")\n",
    "\n",
    "num_ecgs_review = 1000\n",
    "pt_has_af_limited_review = pt_ordered_ecg_groups.head(num_ecgs_review).groupby(\"ptID\")[\"ECGIsAF\"].any()\n",
    "\n",
    "pt_conf_mat = get_pt_conf_mat(pt_in_dataset, pt_has_af_limited_review, ground_truth)\n",
    "print_binary_results(pt_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Plot curve as a function of number of reviews per patient\n",
    "from matplotlib.ticker import MaxNLocator, MultipleLocator\n",
    "\n",
    "num_patients = len(val_patients.index)\n",
    "max_num_reviews = 8\n",
    "num_af_found = np.zeros(max_num_reviews)\n",
    "num_review = np.arange(max_num_reviews)\n",
    "num_review_avg = np.array([get_total_num_review(pt_ordered_ecg_groups.head(n).groupby(\"ptID\")) for n in num_review])/num_patients\n",
    "\n",
    "for i, num_ecgs_review in enumerate(num_review):\n",
    "    if i == 0:\n",
    "        continue\n",
    "        # IDK why but i dont get a decent answer for 0\n",
    "    pt_has_af_limited_review = pt_ordered_ecg_groups.head(num_ecgs_review).groupby(\"ptID\")[\"ECGIsAF\"].any()\n",
    "\n",
    "    pt_conf_mat = get_pt_conf_mat(pt_in_dataset, pt_has_af_limited_review, ground_truth)\n",
    "    num_af_found[i] = pt_conf_mat[1, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=250)\n",
    "ax.plot(num_review_avg, num_af_found)\n",
    "ax.plot([0, num_review_avg.max()], [48, 48], linestyle=\"--\")\n",
    "for x, y, T in zip(num_review_avg, num_af_found, num_review):\n",
    "    ax.annotate(f\"{T}\", (x, y))\n",
    "\n",
    "ax.set_ylabel(\"AF patients detected\")\n",
    "ax.set_xlabel(\"Average ECGs reviewed per patient\")\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.2))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot num reviews per AF diagnosis vs num AF diagnosis\n",
    "total_num_review = np.array([get_total_num_review(pt_ordered_ecg_groups.head(n).groupby(\"ptID\")) for n in num_review]) # num_review * num_patients\n",
    "num_review_per_af = total_num_review[1:]/num_af_found[1:]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=250)\n",
    "ax.plot(num_af_found[1:], num_review_per_af)\n",
    "ax.plot([48, 48], [0, num_review_per_af.max()],  linestyle=\"--\")\n",
    "\n",
    "ax.set_ylabel(\"Reviews per AF patient\")\n",
    "ax.set_xlabel(\"AF patients found\")\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(5))\n",
    "\n",
    "# ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_review_limited = total_num_review\n",
    "num_af_found_limited = num_af_found\n",
    "num_review_per_af_limited = num_review_per_af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=250)\n",
    "ax.plot(num_review, total_num_review)\n",
    "\n",
    "ax.set_ylabel(\"Total reviews\")\n",
    "ax.set_xlabel(r\"Max ECGs reviewed per patient, $n$\")\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(200))\n",
    "\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1412, 2450, 3245, 3884, 4407, 4852, 5221], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  2091,  4182,  6273,  8364, 10455, 12546, 14637])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_review * num_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8591\n",
      "Confusion matrix:\n",
      "[[2043    0]\n",
      " [   2   46]]\n",
      "Sensitivity: 0.958\n",
      "Specificity: 1.000\n",
      "\n",
      "Normal F1: 1.000\n",
      "AF F1: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# What if we only use Zenicor flagged ECGs - The system has much worse sensitivity than Zenicor therefore not much benefit to not sending it through Zenicor first!\n",
    "# This is good actually!\n",
    "\n",
    "dataset_flagged = dataset[(dataset[\"poss_AF_tag\"] == 1)]\n",
    "pt_ordered_ecg_groups = dataset_flagged.sort_values(\"prob_af\", ascending=False).groupby(\"ptID\")\n",
    "\n",
    "num_ecgs_review = 3\n",
    "pt_has_af_limited_review = pt_ordered_ecg_groups.head(num_ecgs_review).groupby(\"ptID\")[\"ECGIsAF\"].any()\n",
    "print(get_total_num_review(pt_ordered_ecg_groups))\n",
    "\n",
    "pt_conf_mat = get_pt_conf_mat(pt_in_dataset, pt_has_af_limited_review, ground_truth)\n",
    "print_binary_results(pt_conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thresholding - set a limit on p(AF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataset[dataset[\"ECGIsAF\"]][\"prob_af\"], alpha=0.7)\n",
    "plt.hist(dataset[~dataset[\"ECGIsAF\"]][\"prob_af\"], alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    80\n",
      "True     39\n",
      "Name: ECGIsAF, dtype: int64\n",
      "Confusion matrix:\n",
      "[[2043    0]\n",
      " [   9   39]]\n",
      "Sensitivity: 0.812\n",
      "Specificity: 1.000\n",
      "\n",
      "Normal F1: 0.998\n",
      "AF F1: 0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "T = 0.5\n",
    "dataset_thresh = dataset[(dataset[\"prob_af\"] > T) & (dataset[\"poss_AF_tag\"] == 1)]\n",
    "pt_ordered_ecg_groups_thresh = dataset_thresh.sort_values(\"prob_af\", ascending=False).groupby(\"ptID\")\n",
    "pt_has_af_thresholded_review = pt_ordered_ecg_groups_thresh[\"ECGIsAF\"].any()\n",
    "print(pt_has_af_thresholded_review.value_counts())\n",
    "\n",
    "pt_conf_mat = get_pt_conf_mat(pt_in_dataset, pt_has_af_thresholded_review, ground_truth)\n",
    "\n",
    "print_binary_results(pt_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = False\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data.loc[:, \"pt_prediction_af\"] = pt_has_af_review\n",
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\46418925.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pt_data[\"pt_prediction_af\"].fillna(False, axis=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Plot curve as a function of number of reviews per patient\n",
    "n_points = 101\n",
    "Ts = np.linspace(0, 1, n_points)\n",
    "num_af_found = np.zeros(n_points)\n",
    "num_reviews = np.zeros(n_points)\n",
    "\n",
    "for i, T in enumerate(Ts):\n",
    "    dataset_thresh = dataset[(dataset[\"prob_af\"] > T) & (dataset[\"poss_AF_tag\"] == 1) & (dataset[\"noise_prediction\"] < 100)]\n",
    "    pt_ordered_ecg_groups_thresh = dataset_thresh.sort_values(\"prob_af\", ascending=False).groupby(\"ptID\")\n",
    "    pt_has_af_thresholded_review = pt_ordered_ecg_groups_thresh[\"ECGIsAF\"].any()\n",
    "\n",
    "    pt_conf_mat = get_pt_conf_mat(pt_in_dataset, pt_has_af_thresholded_review, ground_truth)\n",
    "    num_af_found[i] = pt_conf_mat[1, 1]\n",
    "    num_reviews[i] = get_total_num_review(pt_ordered_ecg_groups_thresh)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=250)\n",
    "ax.plot(num_reviews/len(pt_in_dataset.index), num_af_found)\n",
    "for x, y, T in zip(num_reviews[::20], num_af_found[::20], Ts[::20]):\n",
    "    ax.annotate(f\"{T:.2f}\", (x/len(pt_in_dataset.index), y))\n",
    "\n",
    "ax.plot([0, 4], [48, 48], linestyle=\"--\")\n",
    "\n",
    "ax.set_ylabel(\"AF patients detected\")\n",
    "ax.set_xlabel(\"ECGs reviewed per patient\")\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlim(left=0, right=1.5)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(0.2))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for axis 0 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [45], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mnum_af_found\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(num_reviews[\u001B[38;5;241m15\u001B[39m])\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(Ts[\u001B[38;5;241m15\u001B[39m])\n",
      "\u001B[1;31mIndexError\u001B[0m: index 15 is out of bounds for axis 0 with size 8"
     ]
    }
   ],
   "source": [
    "print(num_af_found[15])\n",
    "print(num_reviews[15])\n",
    "print(Ts[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32.8372093 ,  54.44444444,  70.54347826,  82.63829787,\n",
       "        91.8125    , 101.08333333, 108.77083333])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_num_review_limited\n",
    "# num_af_found_limited\n",
    "num_review_per_af_limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel\\AppData\\Local\\Temp\\ipykernel_51164\\245105500.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  num_review_per_af = total_num_review/num_af_found\n"
     ]
    }
   ],
   "source": [
    "# Plot num reviews per AF diagnosis vs num AF diagnosis\n",
    "total_num_review = num_reviews\n",
    "num_review_per_af = total_num_review/num_af_found\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3.5), dpi=250)\n",
    "ax.plot([48, 48], [0, num_review_per_af_limited.max()],  linestyle=\"--\", color=\"#ff7f0e\")\n",
    "ax.plot(num_af_found_limited[1:], num_review_per_af_limited, color=\"#2ca02c\", label=\"Limited reviews per patient\")\n",
    "ax.plot(num_af_found, num_review_per_af, color=\"#1f77b4\", label=\"Probability threshold\")\n",
    "\n",
    "# ax.legend()\n",
    "\n",
    "ax.set_ylabel(\"Reviews per AF patient\")\n",
    "ax.set_xlabel(\"AF patients found\")\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlim(left=40)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(5))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48., 48., 47.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_af_found[14:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.645833333333336"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_review_per_af[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whats going on with the AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    2086\n",
      "True       55\n",
      "Name: ECGIsAF, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pt_data = SAFERDataset.load_pt_dataset(1)\n",
    "ecg_data = SAFERDataset.load_ecg_csv(1, pt_data, ecg_range=None, ecg_meas_diag=None, feas2_offset=10000, feas2_ecg_offset=200000)\n",
    "\n",
    "ecg_data[\"ECGIsAF\"] = ecg_data[\"measDiag\"] == DiagEnum.AF\n",
    "print(ecg_data.groupby(\"ptID\")[\"ECGIsAF\"].any().value_counts())\n",
    "\n",
    "ecg_data[\"feas\"] = 1\n",
    "ecg_data[\"length\"] = 9120\n",
    "ecg_data[\"rri_len\"] = 20\n",
    "\n",
    "# this removes a number of the AF samples, IDK where the other AF samples are going!\n",
    "pt_data, ecg_data = prepare_safer_data(pt_data, ecg_data)\n",
    "# train_pts, test_pts, val_pts = generate_patient_splits(pt_data, 0.15, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2083\n",
       "True       48\n",
       "Name: ECGIsAF, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_data[\"ECGIsAF\"] = ecg_data[\"measDiag\"] == DiagEnum.AF\n",
    "ecg_data.groupby(\"ptID\")[\"ECGIsAF\"].any().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptID</th>\n",
       "      <th>age</th>\n",
       "      <th>ptDiag</th>\n",
       "      <th>ptDiagRev1</th>\n",
       "      <th>ptDiagRev2</th>\n",
       "      <th>ptDiagRev3</th>\n",
       "      <th>cardRev</th>\n",
       "      <th>measDiag</th>\n",
       "      <th>measDiagRev1</th>\n",
       "      <th>measDiagRev2</th>\n",
       "      <th>...</th>\n",
       "      <th>perhapsAF</th>\n",
       "      <th>measID</th>\n",
       "      <th>data</th>\n",
       "      <th>adc_gain</th>\n",
       "      <th>file_path</th>\n",
       "      <th>class_index</th>\n",
       "      <th>length</th>\n",
       "      <th>ECGIsAF</th>\n",
       "      <th>feas</th>\n",
       "      <th>rri_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/000000/saferF1_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/000000/saferF1_000002</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/000000/saferF1_000003</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/000000/saferF1_000004</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/000000/saferF1_000005</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162511</th>\n",
       "      <td>2141</td>\n",
       "      <td>70.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>162511</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/162000/saferF1_162511</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162512</th>\n",
       "      <td>2141</td>\n",
       "      <td>70.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>162512</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/162000/saferF1_162512</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162513</th>\n",
       "      <td>2141</td>\n",
       "      <td>70.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>162513</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/162000/saferF1_162513</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162514</th>\n",
       "      <td>2141</td>\n",
       "      <td>70.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>162514</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/162000/saferF1_162514</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162515</th>\n",
       "      <td>2141</td>\n",
       "      <td>70.0</td>\n",
       "      <td>DiagEnum.NoAF</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>0</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>DiagEnum.Undecided</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>162515</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ECGs/162000/saferF1_162515</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153451 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ptID   age         ptDiag          ptDiagRev1          ptDiagRev2  \\\n",
       "measID                                                                      \n",
       "1          1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "2          1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "3          1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "4          1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "5          1  71.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "...      ...   ...            ...                 ...                 ...   \n",
       "162511  2141  70.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "162512  2141  70.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "162513  2141  70.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "162514  2141  70.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "162515  2141  70.0  DiagEnum.NoAF  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "\n",
       "                ptDiagRev3  cardRev            measDiag        measDiagRev1  \\\n",
       "measID                                                                        \n",
       "1       DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "2       DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "3       DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "4       DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "5       DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "...                    ...      ...                 ...                 ...   \n",
       "162511  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "162512  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "162513  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "162514  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "162515  DiagEnum.Undecided        0  DiagEnum.Undecided  DiagEnum.Undecided   \n",
       "\n",
       "              measDiagRev2  ...  perhapsAF  measID  data adc_gain  \\\n",
       "measID                      ...                                     \n",
       "1       DiagEnum.Undecided  ...          0       1  None     None   \n",
       "2       DiagEnum.Undecided  ...          0       2  None     None   \n",
       "3       DiagEnum.Undecided  ...          0       3  None     None   \n",
       "4       DiagEnum.Undecided  ...          0       4  None     None   \n",
       "5       DiagEnum.Undecided  ...          0       5  None     None   \n",
       "...                    ...  ...        ...     ...   ...      ...   \n",
       "162511  DiagEnum.Undecided  ...          0  162511  None     None   \n",
       "162512  DiagEnum.Undecided  ...          0  162512  None     None   \n",
       "162513  DiagEnum.Undecided  ...          0  162513  None     None   \n",
       "162514  DiagEnum.Undecided  ...          0  162514  None     None   \n",
       "162515  DiagEnum.Undecided  ...          0  162515  None     None   \n",
       "\n",
       "                         file_path  class_index  length  ECGIsAF  feas  \\\n",
       "measID                                                                   \n",
       "1       ECGs/000000/saferF1_000001            0    9120    False     1   \n",
       "2       ECGs/000000/saferF1_000002            0    9120    False     1   \n",
       "3       ECGs/000000/saferF1_000003            0    9120    False     1   \n",
       "4       ECGs/000000/saferF1_000004            0    9120    False     1   \n",
       "5       ECGs/000000/saferF1_000005            0    9120    False     1   \n",
       "...                            ...          ...     ...      ...   ...   \n",
       "162511  ECGs/162000/saferF1_162511            0    9120    False     1   \n",
       "162512  ECGs/162000/saferF1_162512            0    9120    False     1   \n",
       "162513  ECGs/162000/saferF1_162513            0    9120    False     1   \n",
       "162514  ECGs/162000/saferF1_162514            0    9120    False     1   \n",
       "162515  ECGs/162000/saferF1_162515            0    9120    False     1   \n",
       "\n",
       "        rri_len  \n",
       "measID           \n",
       "1            20  \n",
       "2            20  \n",
       "3            20  \n",
       "4            20  \n",
       "5            20  \n",
       "...         ...  \n",
       "162511       20  \n",
       "162512       20  \n",
       "162513       20  \n",
       "162514       20  \n",
       "162515       20  \n",
       "\n",
       "[153451 rows x 52 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data = ecg_data.loc[feas1_noise_predictions.index][feas1_noise_predictions < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2067\n",
       "True       41\n",
       "Name: ECGIsAF, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_data[\"ECGIsAF\"] = ecg_data[\"measDiag\"] == DiagEnum.AF\n",
    "ecg_data.groupby(\"ptID\")[\"ECGIsAF\"].any().value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
