{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy.io\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from DataHandlers.DiagEnum import DiagEnum\n",
    "import DataHandlers.SAFERDataset\n",
    "import math\n",
    "from ecgdetectors import Detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load SAFER data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feas2_pt_data, feas2_ecg_data = SAFERDataset.load_feas_dataset(2, \"dataframe\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feas2_ecg_data = feas2_ecg_data[feas2_ecg_data[\"measDiag\"].isin([DiagEnum.AF, DiagEnum.NoAF, DiagEnum.CannotExcludePathology])]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load CinC 2020 data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import CinC2020Dataset\n",
    "import importlib\n",
    "importlib.reload(CinC2020Dataset)\n",
    "\n",
    "df = CinC2020Dataset.load_dataset(save_name=\"dataframe\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# At the moment we only select data with length which can be truncated to 3000 samples (10s)\n",
    "\n",
    "def select_length(df):\n",
    "    df_within_range = df[(df[\"length\"] <= 5000) & (df[\"length\"] >= 3000)].copy()\n",
    "    df_within_range[\"data\"] = df_within_range[\"data\"].map(lambda x: x[:3000])\n",
    "    df_within_range[\"length\"] = df_within_range[\"data\"].map(lambda x: x.shape[0])\n",
    "    return df_within_range\n",
    "\n",
    "df = select_length(df)\n",
    "df[\"length\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df[\"heartrate\"].min())\n",
    "print(df[\"heartrate\"].max())\n",
    "\n",
    "plt.hist(df[\"heartrate\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[(df[\"heartrate\"] > 50) & (df[\"heartrate\"] < 100)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[df[\"class_index\"].isin([0, 1])]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[(df[\"heartrate\"] < 50)][\"diag_num\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(df[df[\"diag_num\"].map(lambda x: 427084000 in x)][\"heartrate\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df[\"heartrate\"] < 50][\"diag_num\"].map(lambda x: 426177001 in x).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scratch space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_len = 181\n",
    "d_model = 32\n",
    "\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(500.0) / d_model))\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "pe = pe.unsqueeze(0).transpose(0, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pe.shape\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Heatmap(z=pe[:, 0, :].T))\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Attention pooling\n",
    "\n",
    "class SelfAttentionPooling(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of SelfAttentionPooling\n",
    "    Original Paper: Self-Attention Encoding and Pooling for Speaker Recognition\n",
    "    https://arxiv.org/pdf/2008.01077v1.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttentionPooling, self).__init__()\n",
    "        self.W = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, batch_rep):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            batch_rep : size (N, T, H), N: batch size, T: sequence length, H: Hidden dimension\n",
    "\n",
    "        attention_weight:\n",
    "            att_w : size (N, T, 1)\n",
    "\n",
    "        return:\n",
    "            utter_rep: size (N, H)\n",
    "        \"\"\"\n",
    "        softmax = nn.functional.softmax\n",
    "        att_w = softmax(self.W(batch_rep).squeeze(-1)).unsqueeze(-1)\n",
    "        utter_rep = torch.sum(batch_rep * att_w, dim=1)\n",
    "\n",
    "        return utter_rep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from torch import Tensor\n",
    "\n",
    "class AttentionPool2d(nn.Module):\n",
    "    \"Attention for Learned Aggregation\"\n",
    "    def __init__(self,\n",
    "        ni:int,\n",
    "        bias:bool=True,\n",
    "        norm:Callable[[int], nn.Module]=nn.LayerNorm\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm = norm(ni)\n",
    "        self.q = nn.Linear(ni, ni, bias=bias)\n",
    "        self.vk = nn.Linear(ni, ni*2, bias=bias)\n",
    "        self.proj = nn.Linear(ni, ni)\n",
    "\n",
    "    def forward(self, x:Tensor, cls_q:Tensor):\n",
    "        x = self.norm(x.flatten(2))\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        q = self.q(cls_q.expand(B, N, -1))\n",
    "        k, v = self.vk(x).reshape(B, N, 2, C).permute(2, 0, 1, 3).chunk(2, 0)\n",
    "        k = k[0, :, :, :]\n",
    "        v = v[0, :, :, :]\n",
    "\n",
    "        attn = q @ k.transpose(-2, -1)\n",
    "        attn = nn.functional.softmax(attn, dim=-1)\n",
    "        # Once we have the attention take the mean over the time domain\n",
    "        x = torch.mean((attn @ v), dim=-2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LearnedAggregation(nn.Module):\n",
    "    \"Learned Aggregation from https://arxiv.org/abs/2112.13692\"\n",
    "    def __init__(self,\n",
    "        ni:int,\n",
    "        attn_bias:bool=True,\n",
    "        ffn_expand:int|float=3,\n",
    "        norm:Callable[[int], nn.Module]=nn.LayerNorm,\n",
    "        act_cls:Callable[[None], nn.Module]=nn.GELU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.gamma_1 = nn.Parameter(1e-4 * torch.ones(ni))\n",
    "        self.gamma_2 = nn.Parameter(1e-4 * torch.ones(ni))\n",
    "        self.cls_q = nn.Parameter(torch.zeros(ni))\n",
    "        self.attn = AttentionPool2d(ni, attn_bias, norm)\n",
    "        self.norm = norm(ni)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(ni, int(ni*ffn_expand)),\n",
    "            act_cls(),\n",
    "            nn.Linear(int(ni*ffn_expand), ni)\n",
    "        )\n",
    "        nn.init.trunc_normal_(self.cls_q, std=0.02)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        x = self.cls_q + self.gamma_1 * self.attn(x, self.cls_q)\n",
    "        return x + self.gamma_2 * self.ffn(self.norm(x))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class CNNFeatureExtraction(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_section1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 17, stride=2, padding=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "\n",
    "        self.conv_section2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, 11, stride=2, padding=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, padding=1),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        self.conv_section3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 11, stride=2, padding=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        self.conv_section4 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.BatchNorm1d(128)\n",
    "        )\n",
    "\n",
    "        self.conv_section5 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,  padding=1),\n",
    "            nn.BatchNorm1d(128)\n",
    "        )\n",
    "\n",
    "        self.conv_section6 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2,  padding=1),\n",
    "            nn.BatchNorm1d(128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "         # [1, 1000]\n",
    "        x = self.conv_section1(x)\n",
    "\n",
    "        # [32, 250]\n",
    "        x = self.conv_section2(x)\n",
    "\n",
    "        # [64, 63]\n",
    "        x = self.conv_section3(x)\n",
    "\n",
    "        # [64, 16]\n",
    "        x = self.conv_section4(x)\n",
    "\n",
    "        # [128, 8]\n",
    "        x = self.conv_section5(x)\n",
    "\n",
    "        # [128, 4]\n",
    "        x = self.conv_section6(x)\n",
    "        # [128, 2]\n",
    "\n",
    "        return torch.flatten(x, -2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Borrowed and modified from https://github.com/pytorch/examples/blob/main/word_language_model/model.py\n",
    "\n",
    "# Temporarily leave PositionalEncoding module here. Will be moved somewhere else.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
    "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
    "        Here, we use sine and cosine functions of different frequencies.\n",
    "    .. math:\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "       # >>> pos_encoder = PositionalEncoding(d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=200):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(500.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, inplen, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        try:\n",
    "            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        except BaseException as e:\n",
    "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or '\n",
    "                              'lower.') from e\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.ninp = ninp\n",
    "        # self.attention_pooling = SelfAttentionPooling(ninp)\n",
    "        self.attention_pooling = LearnedAggregation(ninp)\n",
    "        self. layer_norm = nn.LayerNorm(ninp)\n",
    "        # self.spectrogram_bn = nn.BatchNorm2d(1)\n",
    "        self.decoder1 = nn.Linear(ninp, 128)\n",
    "        self.decoder2 = nn.Linear(128, ntoken)\n",
    "        self.n_fft = n_fft\n",
    "\n",
    "        self.cnn_window_size = 1000\n",
    "        self.cnn_stride = 500\n",
    "        self.cnn = CNNFeatureExtraction()\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.zeros_(self.decoder1.bias)\n",
    "        nn.init.zeros_(self.decoder2.bias)\n",
    "        nn.init.uniform_(self.decoder1.weight, -initrange, initrange)\n",
    "        nn.init.uniform_(self.decoder2.weight, -initrange, initrange)\n",
    "\n",
    "    def stft_and_reshape(self, src):\n",
    "        src = torch.transpose(src, 0, 1)\n",
    "        ecg_stfts = torch.stft(src, n_fft=n_fft, return_complex=True)\n",
    "        src = torch.abs(ecg_stfts)\n",
    "\n",
    "        # Layer norm\n",
    "        src = (src - torch.mean(src, dim=1)[:, None, :])/torch.std(src, dim=1)[:, None, :]\n",
    "\n",
    "        # Batch norm\n",
    "        # src = self.spectrogram_bn(torch.unsqueeze(src, dim=1))[:, 0, :, :]\n",
    "\n",
    "        src = torch.permute(src, [2, 0, 1])\n",
    "        src = src[:, :, :self.ninp]\n",
    "\n",
    "        return src\n",
    "\n",
    "    def window(self, src):\n",
    "        src = torch.transpose(src, 0, 1)\n",
    "        src = src.unfold(1, self.cnn_window_size, self.cnn_stride)\n",
    "\n",
    "        return src\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = self.stft_and_reshape(src)\n",
    "        src = self.window(src)\n",
    "        B, N, _ = src.shape\n",
    "        # Unsqueeze for the CNN channel dimension, and flatten time and batch dimension\n",
    "        src = torch.flatten(torch.unsqueeze(src, -2), 0, 1)\n",
    "        src = self.cnn(src)\n",
    "\n",
    "        src = torch.reshape(src, (N, B, -1))\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = torch.transpose(output, 0, 1)\n",
    "        # output = torch.flatten(output, 1)\n",
    "        output = self.attention_pooling(output)\n",
    "\n",
    "        output = self.decoder1(output)\n",
    "        output = nn.functional.relu(output)\n",
    "\n",
    "        output = self.decoder2(output)\n",
    "        # output = self.sigmoid(output)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TransformerModel(2, 256, 4, 1024, 4, 47, 512)\n",
    "for param in model.parameters():"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mapper = CinC2020Dataset.CinC2020DiagMapper()\n",
    "num_unique_classes = len(mapper.diag_desc.index)\n",
    "mapper.diag_desc.index\n",
    "\n",
    "def class_index_map(diag):\n",
    "    if diag == DiagEnum.NoAF:\n",
    "        return 0\n",
    "    elif diag == DiagEnum.AF:\n",
    "        return 1\n",
    "    elif diag == DiagEnum.CannotExcludePathology:\n",
    "        return 2\n",
    "    elif diag == DiagEnum.Undecided:\n",
    "        return 0\n",
    "\n",
    "def one_hot_map(diag_num):\n",
    "    one_hot = np.zeros(num_unique_classes)\n",
    "    one_hot[diag_num] = 1\n",
    "    return one_hot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Onehot encoding\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dataset.index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.dataset.iloc[index]\n",
    "\n",
    "        X = row[\"data\"]\n",
    "        y = row[\"class_index\"]\n",
    "        ind = row.name\n",
    "\n",
    "        return X, y, ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feas2_ecg_data[\"class_index\"] = feas2_ecg_data[\"measDiag\"].map(lambda x: class_index_map(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For SAFER data\n",
    "# Split train and test data according to each patient\n",
    "def make_SAFER_dataloaders(pt_data, ecg_data, test_frac):\n",
    "    pt_data[\"noLQrecs\"] = pt_data[\"noRecs\"] - pt_data[\"noHQrecs\"]  # for Feas1 this might include stuff flagged by zenicor as noisy?\n",
    "    train_patients = []\n",
    "    test_patients = []\n",
    "\n",
    "    for val, df in pt_data.groupby(\"noLQrecs\"):\n",
    "        print(f\"processing {val}\")\n",
    "        print(f\"number of patients {len(df.index)}\")\n",
    "        test = df.sample(frac=test_frac)\n",
    "        test_patients.append(test)\n",
    "        train_patients.append(df[~df[\"ptID\"].isin(test[\"ptID\"])])\n",
    "\n",
    "    train_pt_df = pd.concat(train_patients)\n",
    "    test_pt_df = pd.concat(test_patients)\n",
    "\n",
    "    print(f\"Test high quality: {test_pt_df['noHQrecs'].sum()} low quality: {test_pt_df['noLQrecs'].sum()} \")\n",
    "    print(f\"Train high quality: {train_pt_df['noHQrecs'].sum()} low quality: {train_pt_df['noLQrecs'].sum()} \")\n",
    "\n",
    "    train_dataloader = None\n",
    "    test_dataloader = None\n",
    "\n",
    "    train_dataset = None\n",
    "    test_dataset = None\n",
    "\n",
    "    if not train_pt_df.empty:\n",
    "        # get ECG datasets\n",
    "        train_dataset = ecg_data[ecg_data[\"ptID\"].isin(train_pt_df[\"ptID\"])]\n",
    "        # Normalise\n",
    "        train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "        torch_dataset_train = Dataset(train_dataset)\n",
    "        train_dataloader = DataLoader(torch_dataset_train, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "    if not test_pt_df.empty:\n",
    "        test_dataset = ecg_data[(ecg_data[\"ptID\"].isin(test_pt_df[\"ptID\"])) & (ecg_data[\"measDiag\"] != DiagEnum.Undecided)]\n",
    "        test_dataset[\"data\"] = (test_dataset[\"data\"] - test_dataset[\"data\"].map(lambda x: x.mean()))/test_dataset[\"data\"].map(lambda x: x.std())\n",
    "        torch_dataset_test = Dataset(test_dataset)\n",
    "        test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader, train_dataset, test_dataset\n",
    "\n",
    "train_dataloader, test_dataloader, train_dataset, test_dataset = make_SAFER_dataloaders(feas2_pt_data, feas2_ecg_data, test_frac=1)\n",
    "\n",
    "# Remake the test dataset without any undecided values\n",
    "test_dataset = test_dataset[test_dataset[\"measDiag\"] != DiagEnum.Undecided]\n",
    "torch_dataset_test = Dataset(test_dataset)\n",
    "test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Make dataloaders for CinC data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(df, test_size=0.2, stratify=df[\"class_index\"])\n",
    "test_dataset = test_dataset[test_dataset[\"measDiag\"] != DiagEnum.Undecided]  # Should just remove any errors in loading the dataset\n",
    "\n",
    "torch_dataset_test = Dataset(test_dataset)\n",
    "test_dataloader = DataLoader(torch_dataset_test, batch_size=128, shuffle=True, pin_memory=True)\n",
    "\n",
    "torch_dataset_train = Dataset(train_dataset)\n",
    "train_dataloader = DataLoader(torch_dataset_train, batch_size=128, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset[\"class_index\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove Cannot exclude pathology from the testing set (but possibly still in train)\n",
    "\n",
    "test_dataset = test_dataset[(test_dataset[\"measDiag\"] != DiagEnum.CannotExcludePathology) & (test_dataset[\"measDiag\"] != DiagEnum.HeartBlock)]\n",
    "torch_dataset_test = Dataset(test_dataset)\n",
    "test_dataloader = DataLoader(torch_dataset_test, batch_size=128, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset[\"measDiag\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare for training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using Cuda\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, LambdaLR, SequentialLR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "n_head = 4\n",
    "embed_dim = 384 # int(n_fft/2)\n",
    "\n",
    "model = TransformerModel(2, embed_dim, n_head, 1024, 4, 47).to(device)\n",
    "\n",
    "# Use weightings to handle class imbalance\n",
    "\n",
    "class_counts = torch.tensor(train_dataset[\"class_index\"].value_counts().sort_index().values.astype(np.float32))\n",
    "class_weights = (1/class_counts)\n",
    "class_weights /= torch.sum(class_weights)\n",
    "print(class_weights)\n",
    "\n",
    "\"\"\"\n",
    "c = {i: 0 for i in mapper.diag_desc.index}\n",
    "for _, diags in df[\"diag_num\"].iteritems():\n",
    "    for d in diags:\n",
    "        c[d] += 1\n",
    "\n",
    "class_counts = torch.tensor(list(c.values()))\n",
    "class_weights = (1/class_counts)\n",
    "class_weights /= torch.sum(class_weights)\n",
    "\"\"\"\n",
    "\n",
    "def multiclass_cross_entropy_loss(pred, targets):\n",
    "    return - torch.sum(class_weights[None, :] * targets[None, :] * torch.log(pred))\\\n",
    "           - torch.sum(class_weights[None, :] * (1 - targets[None, :]) * torch.log(1-pred))\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(weight=class_weights) # multiclass_cross_entropy_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "number_warmup_epochs = 3\n",
    "def warmup(current_step: int):\n",
    "    return 1 / (10 ** (float(number_warmup_epochs - current_step)))\n",
    "warmup_scheduler = LambdaLR(optimizer, lr_lambda=warmup)\n",
    "\n",
    "scheduler = SequentialLR(optimizer, [warmup_scheduler, scheduler], [number_warmup_epochs])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Debugging training issues\n",
    "torch.autograd.set_detect_anomaly(True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "model = model.to(device)\n",
    "num_epochs = 30\n",
    "\n",
    "def train(model):\n",
    "    best_test_loss = 100\n",
    "    best_epoch = -1\n",
    "    best_model = copy.deepcopy(model).cpu()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        print(f\"starting epoch {epoch} ...\")\n",
    "        # Train\n",
    "        num_batches = 0\n",
    "        model.train()\n",
    "        for i, (signals, labels, _) in enumerate(train_dataloader):\n",
    "            signals = torch.transpose(signals.to(device), 0, 1).float()\n",
    "            # fft = torch.abs(torch.fft.fft(signals))\n",
    "            # signals = torch.cat([signals, fft], dim=1)\n",
    "\n",
    "            if torch.any(torch.isnan(signals)):\n",
    "                print(\"Signals are nan\")\n",
    "                continue\n",
    "            labels = labels.long()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(signals).to(\"cpu\")\n",
    "            loss = loss_func(output, labels)\n",
    "            if torch.isnan(loss):\n",
    "                raise ValueError\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            num_batches += 1\n",
    "            total_loss += float(loss)\n",
    "\n",
    "        print(f\"Epoch {epoch} finished with average loss {total_loss/num_batches}\")\n",
    "        print(\"Testing ...\")\n",
    "        # Test\n",
    "        num_test_batches = 0\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, (signals, labels, _) in enumerate(test_dataloader):\n",
    "                signals = torch.transpose(signals.to(device), 0, 1).float()\n",
    "                # fft = torch.abs(torch.fft.fft(signals))\n",
    "                # signals = torch.cat([signals, fft], dim=1)\n",
    "                if torch.any(torch.isnan(signals)):\n",
    "                    print(\"Signals are nan\")\n",
    "                    continue\n",
    "\n",
    "                labels = labels.long()\n",
    "                output = model(signals).to(\"cpu\")\n",
    "                loss = loss_func(output, labels)\n",
    "                test_loss += float(loss)\n",
    "                num_test_batches += 1\n",
    "\n",
    "        print(f\"Average test loss: {test_loss/num_test_batches}\")\n",
    "        losses.append([total_loss/num_batches, test_loss/num_test_batches])\n",
    "\n",
    "        if test_loss/num_test_batches < best_test_loss:\n",
    "            best_model = copy.deepcopy(model).cpu()\n",
    "            best_test_loss = test_loss/num_test_batches\n",
    "            best_epoch = epoch\n",
    "        else:\n",
    "            if best_epoch + 5 <= epoch:\n",
    "                return best_model, losses\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return best_model, losses\n",
    "\n",
    "model, losses = train(model)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save a model\n",
    "torch.save(model.state_dict(), \"TrainedModels/Transformer_spectrogram_features_learned_aggregation.pt\")\n",
    "train_dataset.to_pickle(\"TrainedModels/Transformer_spectrogram_features_learned_aggregation_train_set.pk\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = TransformerModel(2, embed_dim, n_head, 1024, 4, 47, n_fft).to(device)\n",
    "model.load_state_dict(torch.load(\"TrainedModels/Transformer_spectrogram_features_learned_aggregation.pt\", map_location=device))\n",
    "\n",
    "# Should load the test data as well"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "test_dataset[\"prediction\"] = None\n",
    "\n",
    "def get_predictions(model, dataloader, dataset):\n",
    "    model.eval()\n",
    "\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    outputs = []\n",
    "    inds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (signals, labels, ind) in enumerate(dataloader):\n",
    "            signals = torch.transpose(signals.to(device), 0, 1).float()\n",
    "            # fft = torch.abs(torch.fft.fft(signals))\n",
    "            # signals = torch.cat([signals, fft], dim=1)\n",
    "            labels = labels.long().detach().numpy()\n",
    "            true_labels.append(labels)\n",
    "\n",
    "            output = model(signals).detach().to(\"cpu\").numpy()\n",
    "\n",
    "            prediction = output # np.argmax(output, axis=-1)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "            for i, o in zip(ind, output):\n",
    "                outputs.append(o)\n",
    "                inds.append(int(i))\n",
    "\n",
    "    dataset[\"prediction\"] = pd.Series(data=outputs, index=inds)\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    true_labels = np.concatenate(true_labels)\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "predictions, true_labels = get_predictions(model, test_dataloader, test_dataset)\n",
    "conf_mat = confusion_matrix(true_labels, np.argmax(predictions, axis=1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions, true_labels = get_predictions(model, test_dataloader, test_dataset)\n",
    "conf_mat = multilabel_confusion_matrix(true_labels, predictions > 0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, c_mat in enumerate(conf_mat):\n",
    "    print(mapper.mapToDesc(i))\n",
    "    print(c_mat)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset[\"class_index\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Same as the below function (as described in CinC)\n",
    "def F1_ind(conf_mat, ind):\n",
    "    return (2 * conf_mat[ind, ind])/(np.sum(conf_mat[ind]) + np.sum(conf_mat[:, ind]))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "print(f\"Sensitivity: {conf_mat[1, 1]/np.sum(conf_mat[1])}\")\n",
    "print(f\"Specificity: {conf_mat[0, 0]/np.sum(conf_mat[0])}\")\n",
    "\n",
    "print(f\"Normal F1: {F1_ind(conf_mat, 0)}\")\n",
    "print(f\"AF F1: {F1_ind(conf_mat, 1)}\")\n",
    "print(f\"Other F1: {F1_ind(conf_mat, 2)}\")\n",
    "# print(f\"Other arrythmia F1: {F1_ind(conf_mat, 1)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset[\"class_prediction\"] = test_dataset[\"prediction\"].map(lambda x: np.argmax(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selection = test_dataset[(test_dataset[\"class_prediction\"] == 0) & (test_dataset[\"class_index\"] == 2)]\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "def plot_ecg(x, fs=300, n_split=1):\n",
    "    sample_len = x.shape[0]\n",
    "    time_axis = np.arange(sample_len)/fs\n",
    "\n",
    "    cuts = np.round(np.linspace(0, sample_len-1, n_split+1)).astype(int)\n",
    "\n",
    "    fig, ax = plt.subplots(n_split, 1, figsize=(12, 5), squeeze=False)\n",
    "    for j in range(n_split):\n",
    "        ax[j][0].plot(time_axis[cuts[j]:cuts[j+1]], x[cuts[j]:cuts[j+1]])\n",
    "        ax[j][0].set_xlabel(\"Time\")\n",
    "        ax[j][0].set_xlim((time_axis[cuts[j]], time_axis[cuts[j+1]]))\n",
    "\n",
    "        t_s = time_axis[cuts[j]]\n",
    "        t_f = time_axis[cuts[j+1]]\n",
    "        time_ticks = np.arange(t_s - t_s%0.2, t_f + (0.2 - t_f%0.2), 0.2)\n",
    "        decimal_labels = ~np.isclose(time_ticks, np.round(time_ticks))\n",
    "        time_labels = np.round(time_ticks).astype(int).astype(str)\n",
    "        time_labels[decimal_labels] = \"\"\n",
    "\n",
    "        ax[j][0].set_xticks(time_ticks, time_labels)\n",
    "\n",
    "\n",
    "        ax[j][0].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "        ax[j][0].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "        ax[j][0].grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "        ax[j][0].grid(which='minor', linestyle='-', linewidth='0.5', color='lightgray')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "c = DiagEnum.CannotExcludePathology\n",
    "\n",
    "for _, ecg in selection.sample(frac=1).iterrows():\n",
    "    print(ecg[[\"measDiag\", \"prediction\", \"diag_num\"]])\n",
    "    plot_ecg(ecg[\"data\"], 300)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect the attention mechanism"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.transformer_encoder.layers.\n",
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "def hook(module, x, y):\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "    fig.add_trace(go.Heatmap(z=x[0][:, 0, :].cpu().numpy()), row=1, col=1)\n",
    "    fig.add_trace(go.Heatmap(z=y[0][:, 0, :].cpu().numpy()), row=2, col=1)\n",
    "    fig.show()\n",
    "\n",
    "attention_hook = model.transformer_encoder.layers[0].self_attn.register_forward_hook(hook)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (signals, labels, ind) in enumerate(test_dataloader):\n",
    "        print(signals.shape)\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=signals[0]))\n",
    "        fig.show()\n",
    "        signals = torch.transpose(signals.to(device), 0, 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        labels = labels.long().detach().numpy()\n",
    "\n",
    "        output = model(signals).detach().to(\"cpu\").numpy()\n",
    "        break\n",
    "\n",
    "attention_hook.remove()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attention_hook.remove()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
