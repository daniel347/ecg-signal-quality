{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import DataHandlers.CinCDataset as CinCDataset\n",
    "import DataHandlers.SAFERDataset as SAFERDataset\n",
    "\n",
    "import importlib\n",
    "importlib.reload(SAFERDataset)\n",
    "importlib.reload(CinCDataset)\n",
    "\n",
    "from DataHandlers.DiagEnum import DiagEnum, feas1DiagToEnum\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"text.usetex\"] = False\n",
    "\n",
    "# A fudge because I moved the files\n",
    "sys.modules[\"SAFERDataset\"] = SAFERDataset\n",
    "sys.modules[\"CinCDataset\"] = CinCDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feas2_pt_data, feas2_ecg_data = SAFERDataset.load_feas_dataset(2, \"dataframe\")\n",
    "feas2_ecg_data = feas2_ecg_data[feas2_ecg_data[\"length\"] == 9120]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feas1_pt_data, feas1_ecg_data = SAFERDataset.load_feas_dataset(1, ecg_meas_diag=[d for d in DiagEnum if d != DiagEnum.Undecided])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load specially cleaned data\n",
    "\n",
    "feas2_ecg_data = pd.read_pickle(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas2\\ECGs\\filtered_dataframe.pk\")\n",
    "feas2_pt_data = pd.read_csv(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas2\\pt_data_anon.csv\")\n",
    "feas2_pt_data[\"ptID\"] += 10000\n",
    "feas2_ecg_data[\"ptID\"] += 10000\n",
    "\n",
    "feas1_ecg_data_clean = pd.read_pickle(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas1\\ECGs\\clean_ecg_dataset.pk\")\n",
    "feas1_pt_data = pd.read_csv(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas1\\pt_data_anon.csv\")\n",
    "print(len(feas1_ecg_data_clean.index))\n",
    "\n",
    "feas2_ecg_data_clean = pd.read_pickle(r\"C:\\Users\\daniel\\Documents\\2022_23_DSiromani\\Feas2\\ECGs\\clean_ecg_dataset.pk\")\n",
    "feas2_ecg_data_clean[\"ptID\"] += 10000\n",
    "print(len(feas2_ecg_data_clean.index))\n",
    "\n",
    "all_clean_data = pd.concat([feas2_ecg_data_clean, feas1_ecg_data_clean], ignore_index=True)\n",
    "all_clean_pt = pd.concat([feas2_pt_data[feas2_pt_data[\"ptID\"].isin(feas2_ecg_data_clean[\"ptID\"])], feas1_pt_data[feas1_pt_data[\"ptID\"].isin(feas1_ecg_data_clean[\"ptID\"])]])\n",
    "\n",
    "all_clean_pt.set_index(\"ptID\", drop=False, inplace=True)\n",
    "all_clean_pt[\"noRecs\"] = all_clean_data[\"ptID\"].value_counts()\n",
    "all_clean_pt[\"noHQrecs\"] = all_clean_pt[\"noRecs\"]\n",
    "all_clean_pt.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.conv_section1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Conv1d(16, 16, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "\n",
    "        self.conv_section2 = nn.Sequential(\n",
    "            nn.Conv1d(16, 16, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Conv1d(16, 16, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "\n",
    "        self.conv_section3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, 9, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, 9, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "\n",
    "        self.conv_section4 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, 9, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, 9, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32)\n",
    "        )\n",
    "\n",
    "        self.conv_section5 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 64, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        self.conv_section6 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 64, 19, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv_section7 = nn.Sequential(\n",
    "            nn.Conv1d(64, 80, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(80),\n",
    "            nn.Conv1d(80, 80, 7, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(80)\n",
    "        )\n",
    "\n",
    "        self.encoder_linear = nn.Linear(5120, z_dim*2)\n",
    "        self.decoder_linear = nn.Linear(z_dim, 5120)\n",
    "\n",
    "        self.decoder_batchnorm = nn.BatchNorm1d(5120)\n",
    "\n",
    "        self.transconv_section1 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(16, 1, 19, padding=9, stride=1),\n",
    "        )\n",
    "\n",
    "        self.transconv_section2 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(16, 16, 20, padding=9, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "        )\n",
    "\n",
    "        self.transconv_section3 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(32, 16, 20, padding=9, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "        )\n",
    "\n",
    "        self.transconv_section4 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(48, 32, 10, padding=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "        )\n",
    "\n",
    "        self.transconv_section5 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 48, 10, padding=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(48),\n",
    "        )\n",
    "\n",
    "        self.transconv_section6 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(64, 64, 8, padding=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        self.transconv_section7 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(80, 64, 7, padding=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def encode(self, x):\n",
    "        # [1, 2048]\n",
    "        x = self.conv_section1(x)\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [16, 1024]\n",
    "        x = self.conv_section2(x) + x\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [32, 512]\n",
    "        x = self.conv_section3(x)\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [32, 256]\n",
    "        x = self.conv_section4(x) + x\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [64, 128]\n",
    "        x = self.conv_section5(x)\n",
    "        x = nn.functional.max_pool1d(x, 2)\n",
    "\n",
    "        # [64, 64]\n",
    "        # x = self.conv_section6(x)\n",
    "\n",
    "        # [64, 64]\n",
    "        x = self.conv_section7(x)\n",
    "\n",
    "        # [80, 64]\n",
    "        x = torch.flatten(x, -2)\n",
    "\n",
    "        # [5120]\n",
    "        x = self.encoder_linear(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z):\n",
    "        # [z_dim]\n",
    "        z = self.decoder_linear(z)\n",
    "        z = self.decoder_batchnorm(z)\n",
    "        z = torch.nn.functional.relu(z)\n",
    "\n",
    "        # [5120]\n",
    "        z = torch.reshape(z, (-1, 80, 64))\n",
    "        # [80, 64]\n",
    "        z = self.transconv_section7(z)\n",
    "        # print(z.shape)\n",
    "        # [64, 64]\n",
    "        z = self.transconv_section6(z)\n",
    "        # print(z.shape)\n",
    "        # [64, 64]\n",
    "        z = self.transconv_section5(z)\n",
    "        # print(z.shape)\n",
    "        # [64, 128]\n",
    "        z = self.transconv_section4(z)\n",
    "        # print(z.shape)\n",
    "        # [48, 256]\n",
    "        z = self.transconv_section3(z)\n",
    "        # print(z.shape)\n",
    "        # [32, 512]\n",
    "        z = self.transconv_section2(z)\n",
    "        # print(z.shape)\n",
    "        # [16, 1024]\n",
    "        z = self.transconv_section1(z)\n",
    "        # print(z.shape)\n",
    "        # [1, 2048]\n",
    "        return z\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        device = x.device\n",
    "\n",
    "        z_dist = self.encode(x)\n",
    "\n",
    "        z = torch.randn((batch_size, self.z_dim)).to(device) * torch.abs(z_dist[:, self.z_dim:]) + z_dist[:, :self.z_dim]\n",
    "\n",
    "        x = self.decode(z)\n",
    "\n",
    "        return x, z_dist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Onehot encoding\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dataset.index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.dataset.iloc[index]\n",
    "\n",
    "        X = row[\"data\"]\n",
    "        y = row[\"class_index\"]\n",
    "        ind = row.name\n",
    "\n",
    "        return X, y, ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_to_segments(dataset, new_len, orig_len, overlap=0):\n",
    "    sections = []\n",
    "\n",
    "    step = int(round(new_len * (1 - overlap)))\n",
    "    num_sections = (orig_len - (new_len - step)) // step\n",
    "    for _, series in dataset.iterrows():\n",
    "        for i in range(num_sections):\n",
    "            section_series = series.copy()\n",
    "            section_series[\"data\"] = section_series[\"data\"][i*step: i*step + new_len]\n",
    "            section_series[\"rec_ind\"] = series.name\n",
    "            section_series[\"rec_pos\"] = i\n",
    "            # Keep all other data (ptid, measDiag etc the same for each section as the source ECG)\n",
    "            sections.append(section_series)\n",
    "\n",
    "    return pd.DataFrame(sections).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For MIT noise stress test database\n",
    "import wfdb\n",
    "import os\n",
    "import scipy.signal\n",
    "\n",
    "noise_stress_test_db = \"mit-bih-noise-stress-test-database\"\n",
    "records = [\"118\", \"119\"]\n",
    "stress_test_files = [\"{}e24\", \"{}e18\", \"{}e12\", \"{}e06\", \"{}e00\", \"{}e_6\"]\n",
    "\n",
    "noise_level = []\n",
    "segments_lists = []\n",
    "\n",
    "# Additionally band pass filter\n",
    "def filter_ecg(x, fs):\n",
    "    b, a = scipy.signal.butter(3, [0.66, 30], 'band', fs=fs)\n",
    "    x = scipy.signal.filtfilt(b, a, x, padlen=150)\n",
    "    x = (x - min(x)) / (max(x) - min(x))\n",
    "    return x\n",
    "\n",
    "for file in stress_test_files:\n",
    "    try:\n",
    "        print(f\"Reading file: {file}\")\n",
    "        data = wfdb.io.rdrecord(os.path.join(noise_stress_test_db, file.format(records[0])))\n",
    "        all_data_v1 = data.p_signal[:,1]\n",
    "        # Resample to 300Hz\n",
    "        fs = 300\n",
    "        all_data_v1 = scipy.signal.resample(all_data_v1, int(all_data_v1.shape[0] * fs/data.fs))\n",
    "        all_data_v1 = filter_ecg(all_data_v1, 300)\n",
    "        # all_data_v1 = adaptive_gain_norm(all_data_v1, 501)\n",
    "\n",
    "        data = wfdb.io.rdrecord(os.path.join(noise_stress_test_db, file.format(records[1])))\n",
    "        all_data_v2 = data.p_signal[:,1]\n",
    "        # Resample to 300Hz\n",
    "        fs = 300\n",
    "        all_data_v2 = scipy.signal.resample(all_data_v2, int(all_data_v2.shape[0] * fs/data.fs))\n",
    "        all_data_v2 = filter_ecg(all_data_v2, 300)\n",
    "\n",
    "        segments = []\n",
    "        noise_boundaries = np.arange(5 * fs, all_data_v1.shape[-1], 240 * fs)\n",
    "        for bound in noise_boundaries:\n",
    "            segments.append(all_data_v1[bound: bound + 120 * fs])\n",
    "\n",
    "        noise_boundaries_2 = np.arange(5 * fs, all_data_v2.shape[-1], 240 * fs)\n",
    "        for bound in noise_boundaries:\n",
    "            segments.append(all_data_v2[bound: bound + 120 * fs])\n",
    "\n",
    "        noise_level.append(file.split(\"e\")[-1])\n",
    "        segments_lists.append(segments)\n",
    "    except ValueError:\n",
    "        print(\"error, scipping file\")\n",
    "        continue\n",
    "\n",
    "segments_lists = np.array(segments_lists)\n",
    "\n",
    "data = np.concatenate([segments_lists[[0, i]].copy() for i in range(1, 6)], axis=1)\n",
    "\n",
    "noise_level = np.array(noise_level[1:])\n",
    "noise_level = np.repeat(noise_level, len(segments_lists[0]))\n",
    "\n",
    "data = np.transpose(data, axes=(1, 2, 0))\n",
    "\n",
    "print(data.shape)\n",
    "print(noise_level.shape)\n",
    "nst_df = pd.DataFrame({\"data\": [data[i] for i in range(data.shape[0])], \"noise_level\": noise_level})\n",
    "print(nst_df.head())\n",
    "\n",
    "pk_path = \"mit-bih-noise-stress-test-database/database_denoising.pk\"\n",
    "nst_df.to_pickle(pk_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "pk_path = \"mit-bih-noise-stress-test-database/database_denoising.pk\"\n",
    "nst_df = pd.read_pickle(pk_path)\n",
    "# normalise\n",
    "nst_df[\"data\"] = (nst_df[\"data\"] - nst_df[\"data\"].map(lambda x: x.mean(axis=0)))/nst_df[\"data\"].map(lambda x: x.std(axis=0))\n",
    "\n",
    "## Train test split here\n",
    "train_dataset = nst_df.sample(frac=0.8)\n",
    "test_dataset = nst_df[~nst_df.index.isin(train_dataset.index)]\n",
    "\n",
    "train_dataset = split_to_segments(train_dataset, 2048, 36000, 0.5)\n",
    "test_dataset = split_to_segments(test_dataset, 2048, 36000, 0.5)\n",
    "\n",
    "class NSTDataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dataset.index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.dataset.iloc[index]\n",
    "\n",
    "        X = row[\"data\"][:, 1]\n",
    "        X_clean = row[\"data\"][:, 0]\n",
    "\n",
    "        return X, X_clean, row.name\n",
    "\n",
    "torch_dataset_train = NSTDataset(train_dataset)\n",
    "torch_dataset_test = NSTDataset(test_dataset)\n",
    "train_dataloader = DataLoader(torch_dataset_train, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for (signals, clean_signals, ind) in test_dataloader:\n",
    "    plt.plot(signals[0])\n",
    "    plt.plot(clean_signals[0])\n",
    "    plt.plot(test_dataset.loc[int(ind[0])][\"data\"][:, 0])\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For SAFER data\n",
    "# Split train and test data according to each patient\n",
    "def make_SAFER_dataloaders(pt_data, ecg_data, test_frac, only_clean_training=True):\n",
    "    pt_data[\"noLQrecs\"] = pt_data[\"noRecs\"] - pt_data[\"noHQrecs\"]  # for Feas1 this might include stuff flagged by zenicor as noisy?\n",
    "    train_patients = []\n",
    "    test_patients = []\n",
    "\n",
    "    for val, df in pt_data.groupby(\"noLQrecs\"):\n",
    "        # print(f\"processing {val}\")\n",
    "        # print(f\"number of patients {len(df.index)}\")\n",
    "        test = df.sample(frac=test_frac)\n",
    "        test_patients.append(test)\n",
    "        train_patients.append(df[~df[\"ptID\"].isin(test[\"ptID\"])])\n",
    "\n",
    "    train_pt_df = pd.concat(train_patients)\n",
    "    test_pt_df = pd.concat(test_patients)\n",
    "\n",
    "    print(f\"Test high quality: {test_pt_df['noHQrecs'].sum()} low quality: {test_pt_df['noLQrecs'].sum()} \")\n",
    "    print(f\"Train high quality: {train_pt_df['noHQrecs'].sum()} low quality: {train_pt_df['noLQrecs'].sum()} \")\n",
    "\n",
    "    train_dataloader = None\n",
    "    test_dataloader = None\n",
    "\n",
    "    train_dataset = None\n",
    "    test_dataset = None\n",
    "\n",
    "    if not train_pt_df.empty:\n",
    "        # get ECG datasets\n",
    "        train_dataset = split_to_segments(ecg_data[ecg_data[\"ptID\"].isin(train_pt_df[\"ptID\"])], 2048, 9120, 0.5)\n",
    "        # Normalise\n",
    "        train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "\n",
    "        if only_clean_training:\n",
    "            torch_dataset_train = Dataset(train_dataset[train_dataset[\"class_index\"] == 0])\n",
    "        else:\n",
    "            torch_dataset_train = Dataset(train_dataset)\n",
    "\n",
    "        train_dataloader = DataLoader(torch_dataset_train, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "    if not test_pt_df.empty:\n",
    "        test_dataset = split_to_segments(ecg_data[ecg_data[\"ptID\"].isin(test_pt_df[\"ptID\"])], 2048, 9120, 0.5)\n",
    "        test_dataset[\"data\"] = (test_dataset[\"data\"] - test_dataset[\"data\"].map(lambda x: x.mean()))/test_dataset[\"data\"].map(lambda x: x.std())\n",
    "        torch_dataset_test = Dataset(test_dataset)\n",
    "        test_dataloader = DataLoader(torch_dataset_test, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader, train_dataset, test_dataset\n",
    "\n",
    "\n",
    "train_dataloader, test_dataloader, train_dataset, test_dataset = make_SAFER_dataloaders(feas2_pt_data, feas2_ecg_data, test_frac=0.2, only_clean_training=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If we want noisy and clean test_data for evaluation, after training and testing on only clean data in training loop\n",
    "_, noisy_test_dataloader, _, noisy_test_dataset = make_SAFER_dataloaders(feas2_pt_data, feas2_ecg_data[~feas2_ecg_data[\"measID\"].isin(train_dataset[\"measID\"])], test_frac=1, only_clean_training=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup dataloaders for only the clean data\n",
    "train_dataloader, test_dataloader, train_dataset, test_dataset = make_SAFER_dataloaders(all_clean_pt, all_clean_data, test_frac=0.2, only_clean_training=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GMM latent space prior - not sure if this does any good"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_gmm_components = 10\n",
    "gmm_means = torch.randn((num_gmm_components, 60))\n",
    "gmm_stds = torch.ones((num_gmm_components, 60))\n",
    "gmm_mixture_weights = (torch.ones(num_gmm_components)/num_gmm_components)\n",
    "\n",
    "def kl_gauss(z_m, z_std, t_m, t_std):\n",
    "    z_var = z_std ** 2\n",
    "    t_var = t_std ** 2\n",
    "\n",
    "    term1 = torch.sum(torch.log(t_var)[None, :] - torch.log(z_var), dim=-1)\n",
    "    term2 = torch.sum(z_var/t_var[None, :], dim=-1) - z_m.shape[-1]\n",
    "    term3 = torch.sum(((z_m - t_m[None, :]) ** 2) * 1/t_var[None, :])\n",
    "\n",
    "    return (1/2) * (term1 + term2 + term3)\n",
    "\n",
    "\n",
    "def gmm_kl_latent_loss(z_m, z_std):\n",
    "\n",
    "    batch_size = z_m.shape[0]\n",
    "    kl_divs = torch.zeros((batch_size, num_gmm_components))\n",
    "    for i in range(num_gmm_components):\n",
    "        kl_divs[:, i] = kl_gauss(z_m, z_std, gmm_means[i], gmm_stds[i])\n",
    "\n",
    "    kl_divs = kl_divs * 1/500\n",
    "\n",
    "    return torch.mean(torch.log(1/torch.matmul(torch.exp(-kl_divs), gmm_mixture_weights)))\n",
    "\n",
    "gmm_kl_latent_loss(torch.zeros((32, 60)), torch.ones((32, 60)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using Cuda\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "z_dim = 128\n",
    "\n",
    "model = CVAE(z_dim).to(device)\n",
    "\n",
    "# Use weightings to avoid\n",
    "\n",
    "# class_counts = torch.tensor(dataset[\"class_index\"].value_counts().values.astype(np.float32))\n",
    "# class_weights = torch.nn.functional.normalize(1.0/class_counts, dim=0)\n",
    "\n",
    "\n",
    "def kl_latent_loss(z_mean, z_std):\n",
    "    # The regularization loss based on kl divergence of the latent distribution from N(0, 1)\n",
    "    vars = z_std ** 2\n",
    "    means = z_mean\n",
    "\n",
    "    return 1/500 * torch.mean( - torch.log(vars) + vars + means ** 2 - 1)\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "loss_func = lambda x, s, z: kl_latent_loss(z[:, :z_dim], z[:, z_dim:]) +  mse_loss(x, s)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.03, momentum=0.8)\n",
    "num_batches = len(train_dataloader)\n",
    "num_test_batches = len(test_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dist(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "triplet_margin = 0.02\n",
    "\n",
    "def triplet_latent_loss(za, zp, zn):\n",
    "    return max(dist(za, zp) - dist(za, zn) + triplet_margin, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train on feas 1 and 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# warning: changing these chunk sizes may reload feas1 data from scratch, which will take ages\n",
    "chunk_size = 20000\n",
    "num_chunks = math.ceil(162515 / chunk_size )\n",
    "\n",
    "def get_feas1_dataloader(chunk_num):\n",
    "    feas1_pt_data, feas1_ecg_data = SAFERDataset.load_feas_dataset(1, f\"dataframe_{chunk_num}.pk\", ecg_range=[chunk_size * chunk_num, chunk_size * (chunk_num + 1)])\n",
    "    train_dataset = split_to_segments(feas1_ecg_data, 2048, 9120, 0.5)\n",
    "    train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "\n",
    "    torch_dataset_train = Dataset(train_dataset)\n",
    "    train_dataloader = DataLoader(torch_dataset_train, batch_size=128, shuffle=True, pin_memory=True)\n",
    "\n",
    "    return train_dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "import copy\n",
    "\n",
    "best_test_loss = 100\n",
    "best_model = copy.deepcopy(model).cpu()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    print(f\"starting epoch {epoch} ...\")\n",
    "    # Train\n",
    "    model.train()\n",
    "\n",
    "    for ds_ind in range(num_chunks + 1):\n",
    "        print(f\"training on dataset: {ds_ind}\")\n",
    "        if ds_ind == 0:\n",
    "            train_dataloader_part = train_dataloader\n",
    "        else:\n",
    "            train_dataloader_part = get_feas1_dataloader(ds_ind-1)\n",
    "\n",
    "        for i, (signals, _, _) in enumerate(train_dataloader_part):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output, latents = model(signals)\n",
    "            loss = loss_func(output, signals, latents)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += float(loss)\n",
    "\n",
    "        print(f\"Total loss {total_loss/num_batches}\")\n",
    "\n",
    "    print(f\"Epoch {epoch} finished with average loss {total_loss/num_batches}\")\n",
    "    print(\"Testing ...\")\n",
    "    # Test\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (signals, _, _)in enumerate(test_dataloader):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "\n",
    "            output, latents = model (signals)\n",
    "            loss = loss_func(output, signals, latents)\n",
    "            test_loss += float(loss)\n",
    "\n",
    "    print(f\"Average test loss: {test_loss/num_test_batches}\")\n",
    "\n",
    "    if test_loss/num_test_batches < best_test_loss:\n",
    "        best_model = copy.deepcopy(model).cpu()\n",
    "        best_test_loss = test_loss/num_test_batches\n",
    "\n",
    "model = best_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train only using feas2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "import copy\n",
    "\n",
    "best_test_loss = 100\n",
    "best_model = copy.deepcopy(model).cpu()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    print(f\"starting epoch {epoch} ...\")\n",
    "    # Train\n",
    "    model.train()\n",
    "    for i, (signals, _, _) in enumerate(train_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, latents = model(signals)\n",
    "        loss = loss_func(output, signals, latents.to(\"cpu\"))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "\n",
    "    print(f\"Epoch {epoch} finished with average loss {total_loss/num_batches}\")\n",
    "    print(\"Testing ...\")\n",
    "    # Test\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (signals, _, _)in enumerate(test_dataloader):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "\n",
    "            output, latents = model (signals)\n",
    "            loss = loss_func(output, signals, latents.to(\"cpu\"))\n",
    "            test_loss += float(loss)\n",
    "\n",
    "    print(f\"Average test loss: {test_loss/num_test_batches}\")\n",
    "\n",
    "    if test_loss/num_test_batches < best_test_loss:\n",
    "        best_model = copy.deepcopy(model).cpu()\n",
    "        best_test_loss = test_loss/num_test_batches\n",
    "\n",
    "model = best_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train using the NST dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "import copy\n",
    "\n",
    "best_test_loss = 100\n",
    "best_model = copy.deepcopy(model).cpu()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    print(f\"starting epoch {epoch} ...\")\n",
    "    # Train\n",
    "    model.train()\n",
    "    for i, (signals, clean_signals, _) in enumerate(train_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        clean_signals = torch.unsqueeze(clean_signals.to(device), 1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, latents = model(signals)\n",
    "        loss = loss_func(output, clean_signals, latents.to(\"cpu\"))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "\n",
    "    print(f\"Epoch {epoch} finished with average loss {total_loss/num_batches}\")\n",
    "    print(\"Testing ...\")\n",
    "    # Test\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (signals, clean_signals, _)in enumerate(test_dataloader):\n",
    "            signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "            clean_signals = torch.unsqueeze(clean_signals.to(device), 1).float()\n",
    "\n",
    "            output, latents = model (signals)\n",
    "            loss = loss_func(output, clean_signals, latents.to(\"cpu\"))\n",
    "            test_loss += float(loss)\n",
    "\n",
    "    print(f\"Average test loss: {test_loss/num_test_batches}\")\n",
    "\n",
    "    if test_loss/num_test_batches < best_test_loss:\n",
    "        best_model = copy.deepcopy(model).cpu()\n",
    "        best_test_loss = test_loss/num_test_batches\n",
    "\n",
    "model = best_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model.to(device)  # if train finished use this to put back on the GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = best_model.to(device)  # if train did not finish use this to take the best intermediate result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save a model\n",
    "torch.save(model.state_dict(), \"TrainedModels/Autoencoder_50_epochs_nst.pt\")\n",
    "train_dataset.to_pickle(\"TrainedModels/Autoencoder_50_epochs_nst_train_set.pk\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_dim = 128\n",
    "model = CVAE(z_dim).to(device)\n",
    "model.load_state_dict(torch.load(\"TrainedModels/Autoencoder_new_6_epochs_all_feas1_feas2.pt\", map_location=device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reload the training and dataset with the model so we don't test on stuff we trained on\n",
    "train_dataset = pd.read_pickle(\"TrainedModels/Autoencoder_new_6_epochs_all_feas1_feas2_train_set.pk\")\n",
    "\n",
    "train_dataset[\"data\"] = (train_dataset[\"data\"] - train_dataset[\"data\"].map(lambda x: x.mean()))/train_dataset[\"data\"].map(lambda x: x.std())\n",
    "torch_dataset_train = Dataset(train_dataset)\n",
    "train_dataloader = DataLoader(torch_dataset_train, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_pt_df = feas2_pt_data[~feas2_pt_data[\"ptID\"].isin(train_dataset[\"ptID\"])]\n",
    "\n",
    "if not test_pt_df.empty:\n",
    "    test_dataset = test_dataset[test_dataset[\"measDiag\"] != DiagEnum.Undecided]\n",
    "    test_dataset = split_to_segments(feas2_ecg_data[feas2_ecg_data[\"ptID\"].isin(test_pt_df[\"ptID\"])], 2048, 9120, 0.5)\n",
    "    test_dataset[\"data\"] = (test_dataset[\"data\"] - test_dataset[\"data\"].map(lambda x: x.mean()))/test_dataset[\"data\"].map(lambda x: x.std())\n",
    "    torch_dataset_test = Dataset(test_dataset)\n",
    "    test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reconstruction for clean samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot test data reconstruction\n",
    "test_dataset[\"reconstruction\"] = None\n",
    "mse_only_loss = lambda truth, pred: torch.mean((truth - pred) ** 2, dim=(1,2))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    r_err = []\n",
    "    inds = []\n",
    "    reconstructions = []\n",
    "\n",
    "    for i, (signals, _, ind) in enumerate(test_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # signals_clean = torch.unsqueeze(signals_clean.to(device), 1).float()\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        output, latents  = model(-signals)\n",
    "        loss = mse_only_loss(output, signals).detach().cpu().numpy()\n",
    "\n",
    "        output = output.detach().cpu().numpy()\n",
    "\n",
    "        for i, o, l in zip(ind, output[:, 0, :], loss):\n",
    "            r_err.append(l)\n",
    "            reconstructions.append(o)\n",
    "            inds.append(int(i))\n",
    "\n",
    "\n",
    "test_dataset[\"r_err\"] = pd.Series(data=r_err, index=inds)\n",
    "test_dataset[\"reconstruction\"] = pd.Series(data=reconstructions, index=inds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df = test_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df[\"reconstruction\"].iloc[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "def plot_ecg_and_reconstruction(x, r, fs=300, n_split=3):\n",
    "    sample_len = x.shape[0]\n",
    "    time_axis = np.arange(sample_len)/fs\n",
    "\n",
    "    cuts = np.round(np.linspace(0, sample_len-1, n_split+1)).astype(int)\n",
    "\n",
    "    fig, ax = plt.subplots(n_split, 1, figsize=(16, 10), squeeze=False)\n",
    "    for j in range(n_split):\n",
    "        ax[j][0].plot(time_axis[cuts[j]:cuts[j+1]], x[cuts[j]:cuts[j+1]])\n",
    "        ax[j][0].plot(time_axis[cuts[j]:cuts[j+1]], r[cuts[j]:cuts[j+1]])\n",
    "        ax[j][0].set_xlabel(\"Time\")\n",
    "        ax[j][0].set_xlim((time_axis[cuts[j]], time_axis[cuts[j+1]]))\n",
    "\n",
    "        t_s = time_axis[cuts[j]]\n",
    "        t_f = time_axis[cuts[j+1]]\n",
    "        time_ticks = np.arange(t_s - t_s%0.2, t_f + (0.2 - t_f%0.2), 0.2)\n",
    "        decimal_labels = ~np.isclose(time_ticks, np.round(time_ticks))\n",
    "        time_labels = np.round(time_ticks).astype(int).astype(str)\n",
    "        time_labels[decimal_labels] = \"\"\n",
    "\n",
    "        ax[j][0].set_xticks(time_ticks, time_labels)\n",
    "\n",
    "        ax[j][0].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        ax[j][0].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "        ax[j][0].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "        ax[j][0].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "        ax[j][0].grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "        ax[j][0].grid(which='minor', linestyle='-', linewidth='0.5', color='lightgray')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for _, ecg in test_df[test_df[\"measDiag\"] == DiagEnum.NoAF].iterrows():\n",
    "    # print(ecg)\n",
    "    print(ecg[[\"ptDiag\", \"measDiag\", \"tag_orig_Poor_Quality\", \"poss_AF_tag\", \"r_err\"]])\n",
    "    plot_ecg_and_reconstruction(ecg[\"data\"], -ecg[\"reconstruction\"], n_split=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_ecg_and_reconstruction_for_classes(xs, rs, titles, fs=300):\n",
    "    fig, ax = plt.subplots(len(xs), 1, figsize=(6, 7))\n",
    "\n",
    "    for j, (x, r, t) in enumerate(zip(xs, rs, titles)):\n",
    "        sample_len = x.shape[0]\n",
    "        time_axis = np.arange(sample_len)/fs\n",
    "\n",
    "        ax[j].plot(time_axis, x)\n",
    "        ax[j].plot(time_axis, r)\n",
    "        ax[j].set_xlabel(\"Time\")\n",
    "        ax[j].set_xlim((time_axis[0], time_axis[-1]))\n",
    "\n",
    "        ax[j].set_xticks(np.arange(time_axis[0], time_axis[-1]+0.2,0.2))\n",
    "        ax[j].set_title(t)\n",
    "\n",
    "        ax[j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        ax[j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "        ax[j].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "        ax[j].yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "\n",
    "        ax[j].grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "        ax[j].grid(which='minor', linestyle='-', linewidth='0.5', color='lightgray')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(\"TMRFigures/cvae_reconst_examples_large_dataset.png\")\n",
    "\n",
    "ecg_ind_list = [3195, 2916, 1563, 1561]  # 2192 # 441 # 315\n",
    "\n",
    "xs = test_df.loc[ecg_ind_list][\"data\"].tolist()\n",
    "rs = test_df.loc[ecg_ind_list][\"reconstruction\"].tolist()\n",
    "titles = test_df.loc[ecg_ind_list].apply(lambda x: f\"{x['measDiag'].name} e = {x['r_err']:.3f}\", axis=1)   # [\"measDiag\"].map(lambda x: x.name).tolist()\n",
    "print(len(titles))\n",
    "\n",
    "plot_ecg_and_reconstruction_for_classes(xs, rs, titles)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Latent space exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try some latent space exploration\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, (signals, _, _) in enumerate(test_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        latent_position = model.encode(signals)\n",
    "        latent_position = latent_position.detach().cpu().numpy()\n",
    "        signals_np = signals.detach().cpu().numpy()\n",
    "\n",
    "        print(latent_position.shape)\n",
    "\n",
    "        break\n",
    "\n",
    "index = 3\n",
    "latent_positions = np.zeros((10, *latent_position.shape), dtype=np.float32)\n",
    "for i in range(10):\n",
    "    latent_positions[i, :, :] += latent_position\n",
    "    latent_positions[i, :, index] = i * 4 - 2\n",
    "\n",
    "signals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for l in latent_positions:\n",
    "        latent = torch.from_numpy(l[:, :60]).to(device)\n",
    "        signal = model.decode(latent)\n",
    "        signals.append(signal.detach().cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interpolate between a noisy and clean ECG!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# noisy 441 # clean 315\n",
    "\n",
    "noisy_latent = test_dataset.loc[441][\"latent_encoding\"][:60]\n",
    "clean_latent = test_dataset.loc[315][\"latent_encoding\"][:60]\n",
    "\n",
    "latent_sequence = np.linspace(noisy_latent, clean_latent, 32)\n",
    "latent_sequence = torch.from_numpy(latent_sequence).to(device)\n",
    "\n",
    "ecgs = model.decode(latent_sequence).detach().cpu().numpy()\n",
    "print(\"plotting\")\n",
    "\n",
    "for ecg in np.flip(ecgs[:, 0, :], axis=0):\n",
    "    plt.plot(ecg)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find the reconstruction error for noisy and clean samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For NST data\n",
    "# test_whole_ecgs_rec_err = test_dataset.groupby(\"rec_ind\").agg({\"r_err\": \"mean\", \"noise_level\": lambda x: x.iloc[0]})\n",
    "# For safer data\n",
    "test_whole_ecgs_rec_err = test_dataset.groupby(\"rec_ind\").agg({\"r_err\": \"mean\" ,\"measDiag\": lambda x: x.iloc[0]})\n",
    "test_whole_ecgs_rec_err"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# A little bit of faff to plot the results from small and large datasets on one axis, for the TMR, not sure it made it into the report in the end\n",
    "test_whole_ecgs_rec_err.to_pickle(\"TrainedModels/Autoecoder_small_dataset.pk\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_not_undecided = test_whole_ecgs_rec_err\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=300)\n",
    "plt.scatter(test_not_undecided[\"measDiag\"].map(lambda x: x.value), test_not_undecided[\"r_err\"], marker='+')\n",
    "plt.xticks([e.value for e in pd.unique(test_not_undecided[\"measDiag\"])], [e.name for e in pd.unique(test_not_undecided[\"measDiag\"])])\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Measurement diagnosis\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"TMRFigures/cvae_reconst_err_large_dataset.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_whole_ecgs_rec_err[\"measDiag\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Safer data\n",
    "\n",
    "test_not_undecided = test_whole_ecgs_rec_err\n",
    "# test_not_undecided_2 = pd.read_pickle(\"TrainedModels/Autoecoder_large_dataset.pk\")\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=300)\n",
    "\n",
    "enum_order = [DiagEnum.NoAF, DiagEnum.AF, DiagEnum.PoorQuality]\n",
    "data = [test_not_undecided[test_not_undecided[\"measDiag\"] == e][\"r_err\"] for e in enum_order]\n",
    "\n",
    "# print(test_not_undecided_2[\"measDiag\"].value_counts())\n",
    "# data_2 = [test_not_undecided_2[test_not_undecided_2[\"measDiag\"] == e][\"r_err\"] for e in enum_order]\n",
    "\n",
    "plt.violinplot(data)    # quantiles=[[0.25, 0.75]]*4, showmedians=True)\n",
    "# plt.violinplot(data_2)\n",
    "plt.xticks([1, 2, 3], [e.name for e in enum_order])\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Measurement diagnosis\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"TMRFigures/cvae_reconst_err_small_dataset.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# NST data\n",
    "\n",
    "test_not_undecided = test_whole_ecgs_rec_err\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=300)\n",
    "\n",
    "noise_levels = np.sort(pd.unique(test_not_undecided[\"noise_level\"]))\n",
    "print(noise_levels)\n",
    "data = [test_not_undecided[test_not_undecided[\"noise_level\"] == e][\"r_err\"] for e in noise_levels]\n",
    "\n",
    "\n",
    "plt.violinplot(data)    # quantiles=[[0.25, 0.75]]*4, showmedians=True)\n",
    "plt.xticks([1, 2, 3, 4, 5])\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Measurement diagnosis\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"TMRFigures/cvae_reconst_err_small_dataset.png\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sample cross validation code for SAFER (not yet applied to anything)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification from the latent space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    inds = []\n",
    "\n",
    "    for i, (signals, _, ind) in enumerate(train_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        latent_position = model.encode(signals)\n",
    "        latent_position = latent_position.detach().cpu().numpy()\n",
    "        signals_np = signals.detach().cpu().numpy()\n",
    "\n",
    "        for i, l in zip(ind, latent_position):\n",
    "            latents.append(l)\n",
    "            inds.append(i)\n",
    "\n",
    "train_dataset[\"latent_encoding\"] = pd.Series(data=latents, index=inds)\n",
    "svc_train_df = train_dataset.dropna(subset=[\"latent_encoding\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_train_df = svc_train_df[svc_train_df[\"measDiag\"] != DiagEnum.Undecided]\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualise the data with scatter plots and T-SNE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_list = list(svc_train_df[\"latent_encoding\"].map(lambda x: x[:60].tolist()).values)\n",
    "latent_df = pd.DataFrame(latent_list, index=svc_train_df.index)\n",
    "print(latent_df.columns)\n",
    "\n",
    "latent_ind = 0\n",
    "\n",
    "# scatter plot\n",
    "for i in range(60):\n",
    "    plt.figure(figsize=(6, 4), dpi=300)\n",
    "    for d in [DiagEnum.NoAF, DiagEnum.PoorQuality, DiagEnum.AF, DiagEnum.CannotExcludePathology]:\n",
    "        plt.scatter(latent_df[svc_train_df[\"measDiag\"] == d][0], latent_df[svc_train_df[\"measDiag\"] == d][i], marker=\"x\", label=d.name)\n",
    "    plt.legend()\n",
    "    plt.ylabel(f\"latent mean {i}\")\n",
    "    plt.xlabel(f\"latent mean 0\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "latent_matrix = np.array(list(svc_train_df[\"latent_encoding\"].map(lambda x: x[:60].tolist()).values))\n",
    "latent_classes = svc_train_df[\"measDiag\"].values\n",
    "\n",
    "print(\"starting tsne\")\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "\n",
    "X_embedded = tsne.fit_transform(latent_matrix)\n",
    "\n",
    "for d in [DiagEnum.NoAF, DiagEnum.PoorQuality, DiagEnum.AF, DiagEnum.CannotExcludePathology]:\n",
    "    plt.scatter(X_embedded[latent_classes == d, 0], X_embedded[latent_classes == d, 1], marker=\"x\", label=d.name)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Group all the segments together"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_train_df = svc_train_df[svc_train_df[\"measDiag\"] != DiagEnum.Undecided]\n",
    "\n",
    "def concatenate_means(x):\n",
    "    mean_series = x.map(lambda x: x[:60])\n",
    "    return np.concatenate(mean_series.tolist())\n",
    "\n",
    "full_ecg_train_df = svc_train_df.groupby(\"rec_ind\").agg({\"latent_encoding\": concatenate_means, \"measDiag\": lambda x: x.iloc[0], \"class_index\": lambda x: x.iloc[0]})\n",
    "full_ecg_train_df.iloc[0][\"latent_encoding\"].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try a T-SNE now all the segments are together\n",
    "\n",
    "latent_matrix = np.array(list(full_ecg_train_df[\"latent_encoding\"].map(lambda x: x.tolist()).values))\n",
    "latent_classes = full_ecg_train_df[\"measDiag\"].values\n",
    "\n",
    "print(\"starting tsne\")\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=30)\n",
    "\n",
    "X_embedded = tsne.fit_transform(latent_matrix)\n",
    "\n",
    "for d in [DiagEnum.NoAF, DiagEnum.PoorQuality, DiagEnum.AF, DiagEnum.CannotExcludePathology]:\n",
    "    plt.scatter(X_embedded[latent_classes == d, 0], X_embedded[latent_classes == d, 1], marker=\"x\", label=d.name)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_matrix = np.vstack(full_ecg_train_df[\"latent_encoding\"].values)\n",
    "targets =  np.array(full_ecg_train_df[\"class_index\"].astype(int).values)\n",
    "\n",
    "print(train_matrix.shape)\n",
    "\n",
    "# class weightings?\n",
    "classifier = SVC()\n",
    "classifier = classifier.fit(train_matrix, targets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset[\"latent_encoding\"] = None\n",
    "inds = []\n",
    "latents = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, (signals, _,  ind) in enumerate(test_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        latent_position = model.encode(signals)\n",
    "        latent_position = latent_position.detach().cpu().numpy()\n",
    "\n",
    "        for i, l in zip(ind, latent_position):\n",
    "            inds.append(int(i))\n",
    "            latents.append(l)\n",
    "\n",
    "test_dataset[\"latent_encoding\"] = pd.Series(data=latents, index=inds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_ecg_test_df = test_dataset.groupby(\"rec_ind\").agg({\"latent_encoding\": concatenate_means, \"measDiag\": lambda x: x.iloc[0], \"class_index\": lambda x: x.iloc[0], \"measID\": lambda x: x.iloc[0]})\n",
    "full_ecg_no_undecided_test_df = full_ecg_test_df[full_ecg_test_df[\"measDiag\"] != DiagEnum.Undecided]\n",
    "\n",
    "test_matrix = np.vstack(full_ecg_no_undecided_test_df[\"latent_encoding\"].values)\n",
    "targets =  np.array(full_ecg_no_undecided_test_df[\"class_index\"].astype(int).values)\n",
    "print(test_matrix.shape)\n",
    "\n",
    "prediction = classifier.predict(test_matrix)\n",
    "\n",
    "full_ecg_no_undecided_test_df[\"prediction\"] = prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(full_ecg_no_undecided_test_df[\"class_index\"].astype(int), full_ecg_no_undecided_test_df[\"prediction\"].astype(int))\n",
    "print(\"Confusion matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "def F1_ind(conf_mat, ind):\n",
    "    return (2 * conf_mat[ind, ind])/(np.sum(conf_mat[ind]) + np.sum(conf_mat[:, ind]))\n",
    "\n",
    "print(f\"Sensitivity: {conf_mat[1, 1]/np.sum(conf_mat[1])}\")\n",
    "print(f\"Specificity: {conf_mat[0, 0]/np.sum(conf_mat[0])}\")\n",
    "\n",
    "print(f\"Normal F1: {F1_ind(conf_mat, 0)}\")\n",
    "print(f\"Noisy F1: {F1_ind(conf_mat, 1)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "false_positives = full_ecg_no_undecided_test_df[(full_ecg_no_undecided_test_df[\"class_index\"] == 0) & (full_ecg_no_undecided_test_df[\"prediction\"] == 1)]\n",
    "\n",
    "for _, ecg in feas2_ecg_data[feas2_ecg_data[\"measID\"].isin(false_positives[\"measID\"])][\"data\"].iteritems():\n",
    "    plot_ecg_and_reconstruction(ecg, ecg)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
