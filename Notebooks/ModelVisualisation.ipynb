{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import types\n",
    "\n",
    "from Models.NoiseCNN import CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"TrainedModels/CNN_AlexNet.pt\"))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_all_layers(model_children, layer_type):\n",
    "  for layer in model_children:\n",
    "    for t in layer_type:\n",
    "        if type(layer) == t:\n",
    "            yield layer\n",
    "    if type(layer) == nn.Sequential:\n",
    "        yield get_all_layers(layer, layer_type)\n",
    "\n",
    "def fill_list_from_generators(gen, list):\n",
    "    for item in gen:\n",
    "        if isinstance(item, types.GeneratorType):\n",
    "            fill_list_from_generators(item, list)\n",
    "        else:\n",
    "            list.append(item)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get all the model children as list\n",
    "model_children = list(model.children())\n",
    "conv_layers = []\n",
    "fill_list_from_generators(get_all_layers(model_children, (nn.Conv1d,)), conv_layers)\n",
    "model_weights = [layer.weight for layer in conv_layers]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# take a look at the conv layers and the respective weights\n",
    "for i, (weight, conv) in enumerate(zip(model_weights, conv_layers)):\n",
    "    # print(f\"WEIGHT: {weight} \\nSHAPE: {weight.shape}\")\n",
    "    print(f\"{i} CONV: {conv} ====> SHAPE: {weight.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Filter Visualisation\n",
    "\n",
    "We can plot the convolution filters of the trained network. The shapes should resemble the snhapes which the filter detects in the input (and passes to the next layer).\n",
    "\n",
    "LAYER_NUM selects the layer of the network to view.\n",
    "\n",
    "IN_CHANNEL_NUM selects the input channel for which to view the filters for"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualize conv layer filters\n",
    "LAYER_NUM = 2\n",
    "IN_CHANNEL_NUM = 0\n",
    "num_filters = model_weights[LAYER_NUM].shape[0]\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i, filter in enumerate(model_weights[LAYER_NUM]):\n",
    "    plt.subplot(num_filters//8 + 1, 8 + 1, i+1)\n",
    "    plt.plot(filter[IN_CHANNEL_NUM, :].detach().cpu())\n",
    "    # plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualise intermediate signals in the CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Onehot encoding\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def generate_onehot(c):\n",
    "    if c == \"N\":\n",
    "        return np.array([1, 0, 0, 0])\n",
    "    if c == \"O\":\n",
    "        return np.array([0, 1, 0, 0])\n",
    "    if c == \"A\":\n",
    "        return np.array([0, 0, 1, 0])\n",
    "    if c == \"~\":\n",
    "        return np.array([0, 0, 0, 1])\n",
    "\n",
    "def generate_index(c):\n",
    "    if c == \"N\":\n",
    "        return 0\n",
    "    if c == \"O\":\n",
    "        return 1\n",
    "    if c == \"A\":\n",
    "        return 2\n",
    "    if c == \"~\":\n",
    "        return 3\n",
    "\n",
    "# dataset[\"onehot\"] = dataset[\"class\"].map(generate_onehot)\n",
    "dataset[\"class_index\"] = dataset[\"class\"].map(generate_index)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.dataset = dataset\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.dataset.index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        row = self.dataset.iloc[index]\n",
    "\n",
    "        X = row[\"data\"][0]\n",
    "        y = row[\"class_index\"]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.15, stratify=dataset[\"class\"])\n",
    "\n",
    "torch_dataset_train = Dataset(train_dataset)\n",
    "torch_dataset_test = Dataset(test_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(torch_dataset_train, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(torch_dataset_test, batch_size=32, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (signals, labels) in enumerate(test_dataloader):\n",
    "        signals = torch.unsqueeze(signals.to(device), 1).float()\n",
    "        # fft = torch.abs(torch.fft.fft(signals))\n",
    "        # signals = torch.cat([signals, fft], dim=1)\n",
    "        labels = labels.detach().numpy()\n",
    "        true_labels.append(labels)\n",
    "\n",
    "        output = model(signals).detach().to(\"cpu\").numpy()\n",
    "        predictions.append(np.argmax(output, axis=-1))\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "true_labels = np.concatenate(true_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
